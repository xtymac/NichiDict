import Foundation
@preconcurrency import GRDB

public protocol DBServiceProtocol: Sendable {
    func searchEntries(query: String, limit: Int) async throws -> [DictionaryEntry]
    func searchReverse(
        query: String,
        limit: Int,
        isEnglishQuery: Bool,
        semanticHint: String?,
        coreHeadwords: Set<String>?
    ) async throws -> [DictionaryEntry]
    func fetchEntry(id: Int) async throws -> DictionaryEntry?
    func validateDatabaseIntegrity() async throws -> Bool
}

public struct DBService: DBServiceProtocol {
    private let dbQueue: DatabaseQueue
    
    public init(dbQueue: DatabaseQueue) {
        self.dbQueue = dbQueue
    }
    
    public func searchEntries(query: String, limit: Int) async throws -> [DictionaryEntry] {
        // Handle empty query
        guard !query.trimmingCharacters(in: .whitespaces).isEmpty else {
            return []
        }

        return try await dbQueue.read { db in
            // Verb stem extraction for better matching
            // If query ends with verb suffix („Çã„ÄÅ„Åè„ÄÅ„Åê„ÄÅ„Åô„ÄÅ„Å§„ÄÅ„Å¨„ÄÅ„Å∂„ÄÅ„ÇÄ„ÄÅ„ÅÜ), also search stem
            var ftsQuery = query + "*"
            var stemQuery: String? = nil

            if query.count >= 2 {
                let verbSuffixes = ["„Çã", "„Åè", "„Åê", "„Åô", "„Å§", "„Å¨", "„Å∂", "„ÇÄ", "„ÅÜ"]
                if verbSuffixes.contains(where: { query.hasSuffix($0) }) {
                    // Extract stem by removing last character
                    let stem = String(query.dropLast())
                    // Only use stem matching if stem is at least 2 characters
                    // This prevents over-matching for single-char stems like "„Åô" from "„Åô„Çã"
                    // which would match Èã≠„ÅÑ („Åô„Çã„Å©„ÅÑ), ÈØ£ („Åô„Çã„ÇÅ), etc.
                    if stem.count >= 2 {
                        stemQuery = stem
                        // Combine queries: search for both "È£ü„Åπ„Çã*" OR "È£ü„Åπ*"
                        ftsQuery = query + "* OR " + stem + "*"
                        print("üîç DBService: Verb detected. Stem: '\(stem)', FTS query: '\(ftsQuery)'")
                    } else {
                        print("üîç DBService: Verb stem too short ('\(stem)'), skipping stem matching")
                    }
                }
            }

            // Simple FTS5 search query with precise ranking
            let sql = """
            SELECT e.*,
                CASE
                    -- Special: For „Åô„Çã query, ÁÇ∫„Çã (canonical suru verb) always comes first
                    WHEN ? = '„Åô„Çã' AND e.headword = 'ÁÇ∫„Çã' THEN 0
                    -- Priority 1: Exact headword match (e.g., „Åô„Çã itself if it exists)
                    WHEN e.headword = ? THEN 1
                    -- Priority 2: Reading exact match (e.g., Êéè„Çã, Âà∑„Çã - homophones, Êº∏„Å® for „ÇÑ„Å£„Å®)
                    -- BOOSTED: This now comes BEFORE prefix matches, so base words appear first
                    WHEN e.reading_hiragana = ? THEN 2
                    -- Priority 3: Headword prefix match (e.g., „Åô„Çã„Å®, „Åô„Çã„Åπ„Åç)
                    WHEN e.headword LIKE ? || '%' THEN 3
                    -- Priority 4: Romaji match
                    WHEN e.reading_romaji = ? THEN 4
                    -- Priority 5: Reading prefix match (e.g., „Åô„Çã„Å®, „Åô„Çã„Åπ„Åç)
                    WHEN e.reading_hiragana LIKE ? || '%' THEN 5
                    ELSE 6
                END AS match_priority,
                -- Compound word detection: penalize unrelated homophones
                -- True compounds use grammatical particles („ÅÆ, „Åß, „Å®, „Å´, „Åå, „Çí, etc.)
                -- e.g., „ÇÑ„Å£„Å®„ÅÆ‰∫ã„Åß (compound) vs „ÇÑ„Å£„Å®„Åì (unrelated noun = pincers)
                CASE
                    -- Check if this is a prefix match (not exact)
                    WHEN e.headword != ? AND e.reading_hiragana != ?
                         AND (e.headword LIKE ? || '%' OR e.reading_hiragana LIKE ? || '%')
                    THEN
                        CASE
                            -- Priority 0: Contains particles ‚Üí true grammatical compound
                            -- Pattern: [query]„ÅÆ, [query]„Åß, [query]„Å®, etc.
                            WHEN e.reading_hiragana LIKE ? || '„ÅÆ%'
                              OR e.reading_hiragana LIKE ? || '„Åß%'
                              OR e.reading_hiragana LIKE ? || '„Å®%'
                              OR e.reading_hiragana LIKE ? || '„Å´%'
                              OR e.reading_hiragana LIKE ? || '„Åå%'
                              OR e.reading_hiragana LIKE ? || '„Çí%'
                              OR e.reading_hiragana LIKE ? || '„Åã„Çâ%'
                              OR e.reading_hiragana LIKE ? || '„Åæ„Åß%'
                            THEN 0
                            -- Priority 1: Short extension (‚â§2 chars) ‚Üí likely semantic compound
                            -- e.g., „ÇÑ„Å£„Å®(3) ‚Üí „ÇÑ„Å£„Å®„Åì„Åï(5) = +2 chars
                            WHEN LENGTH(e.reading_hiragana) - LENGTH(?) <= 2 THEN 1
                            -- Priority 2: Longer extension (3+ chars) ‚Üí likely unrelated
                            -- e.g., „ÇÑ„Å£„Å®(3) ‚Üí „ÇÑ„Å£„Å®„Åã„ÇÅ(5) = +2, but check other signals
                            ELSE 2
                        END
                    ELSE 0  -- Not a prefix match, skip penalty
                END AS compound_priority,
                -- Suru-verb priority: For „Åô„Çã query, prefer actual suru verbs over homophones
                -- This is determined by checking if word_senses contains "suru verb"
                (SELECT CASE
                    WHEN EXISTS (
                        SELECT 1 FROM word_senses ws
                        WHERE ws.entry_id = e.id
                        AND ws.part_of_speech LIKE '%suru verb%'
                    ) THEN 0
                    ELSE 1
                END) AS suru_verb_priority
            FROM dictionary_entries e
            JOIN dictionary_fts fts ON e.id = fts.rowid
            WHERE dictionary_fts MATCH ?
            ORDER BY
                match_priority ASC,
                -- Compound word priority: true grammatical compounds > short compounds > unrelated homophones
                compound_priority ASC,
                -- JLPT existence: words with JLPT levels come before those without
                CASE WHEN e.jlpt_level IS NOT NULL THEN 0 ELSE 1 END ASC,
                -- JLPT level priority: N5 > N4 > N3 > N2 > N1
                -- IMPORTANT: ÁÇ∫„Çã should be N5 (it's the canonical "to do" verb), but JMDict marks it as N3
                -- This is a known data issue - override it here
                CASE
                    WHEN e.headword = 'ÁÇ∫„Çã' THEN 0  -- Override: treat ÁÇ∫„Çã as N5
                    WHEN e.jlpt_level = 'N5' THEN 0
                    WHEN e.jlpt_level = 'N4' THEN 1
                    WHEN e.jlpt_level = 'N3' THEN 2
                    WHEN e.jlpt_level = 'N2' THEN 3
                    WHEN e.jlpt_level = 'N1' THEN 4
                    ELSE 5
                END ASC,
                -- Katakana penalty: Demote katakana loanwords („Åô„Çã„Éº„Å∑, „Åô„Çã„Åü„Çì, etc.)
                -- Only applies to words starting with katakana after the query prefix
                -- e.g., for "„Åô„Çã", penalize "„Åô„Çã„Éº„Å∑" but not "„Åô„Çã„Å®"
                CASE
                    WHEN e.headword GLOB ? || '[„Ç°-„É¥„Éº]*' THEN 1
                    ELSE 0
                END ASC,
                COALESCE(e.frequency_rank, 999999) ASC,
                LENGTH(e.headword) ASC
            LIMIT ?
            """

            var entries = try DictionaryEntry.fetchAll(db, sql: sql, arguments: [
                query, query, query, query, query, query,  // match_priority (6 params)
                query, query, query, query,                 // compound_priority: check if prefix match (4 params)
                query, query, query, query, query, query, query, query,  // compound_priority: particle checks (8 params)
                query,                                      // compound_priority: length check (1 param)
                ftsQuery,                                   // FTS MATCH query
                query,                                      // katakana penalty
                limit                                       // LIMIT
            ])

            // Only find reading-based variants if query is pure hiragana/katakana (reading search)
            // This prevents showing unrelated homonyms when searching with kanji
            // e.g., searching "ÂÖÉÊ∞ó" should not show "ÂéüÂô®", "Ë°°Ê∞ó", etc.
            var existingIds = Set(entries.map { $0.id })
            let isPureKanaQuery = query.unicodeScalars.allSatisfy { scalar in
                // Hiragana range: U+3040 - U+309F
                // Katakana range: U+30A0 - U+30FF
                (0x3040...0x309F).contains(scalar.value) || (0x30A0...0x30FF).contains(scalar.value)
            }

            if isPureKanaQuery {
                // For pure kana queries (e.g., "„Åí„Çì„Åç"), find all kanji variants
                let variantsSql = """
                SELECT DISTINCT e.*,
                    CASE
                        WHEN e.headword = ? THEN 0
                        WHEN e.reading_hiragana = ? THEN 1
                        ELSE 2
                    END AS variant_priority
                FROM dictionary_entries e
                WHERE e.reading_hiragana = ?
                ORDER BY
                    variant_priority ASC,
                    CASE WHEN e.jlpt_level IS NOT NULL THEN 0 ELSE 1 END ASC,
                    CASE
                        WHEN e.jlpt_level = 'N5' THEN 0
                        WHEN e.jlpt_level = 'N4' THEN 1
                        WHEN e.jlpt_level = 'N3' THEN 2
                        WHEN e.jlpt_level = 'N2' THEN 3
                        WHEN e.jlpt_level = 'N1' THEN 4
                        ELSE 5
                    END ASC,
                    COALESCE(e.frequency_rank, 999999) ASC,
                    LENGTH(e.headword) ASC
                """

                let variantEntries = try DictionaryEntry.fetchAll(db, sql: variantsSql, arguments: [query, query, query])

                // Add variants not already in results
                var allEntries = entries
                for variant in variantEntries where !existingIds.contains(variant.id) {
                    allEntries.append(variant)
                    existingIds.insert(variant.id)
                }
                entries = allEntries
            }

            // Add contains matches (e.g., "È†≠„ÅåÂè§„ÅÑ" when searching "Âè§„ÅÑ")
            // Only add if we haven't hit the limit yet
            // Exclude entries already matched by FTS prefix search (both headword and reading)
            // Limit to words not much longer than query to avoid distant compound words
            if entries.count < limit {
                print("üîç DBService: Adding contains matches. Current count: \(entries.count), limit: \(limit)")

                // Calculate max length: query + 3 characters
                // e.g., searching "Â´å„ÅÑ" (2 chars) allows up to 5 chars
                // This filters out long compounds like "Â´å„ÅÑÁÆ∏‰Ωø„ÅÑÊñπ" but keeps "Â´å„ÅÑ„Å™„Åè"
                let maxLength = query.count + 3

                let containsSql = """
                SELECT DISTINCT e.*
                FROM dictionary_entries e
                WHERE (e.headword LIKE '%' || ? || '%' OR e.reading_hiragana LIKE '%' || ? || '%')
                  AND e.headword NOT LIKE ? || '%'
                  AND e.reading_hiragana NOT LIKE ? || '%'
                  AND LENGTH(e.headword) <= ?
                ORDER BY
                    CASE WHEN e.jlpt_level IS NOT NULL THEN 0 ELSE 1 END ASC,
                    CASE
                        WHEN e.jlpt_level = 'N5' THEN 0
                        WHEN e.jlpt_level = 'N4' THEN 1
                        WHEN e.jlpt_level = 'N3' THEN 2
                        WHEN e.jlpt_level = 'N2' THEN 3
                        WHEN e.jlpt_level = 'N1' THEN 4
                        ELSE 5
                    END ASC,
                    COALESCE(e.frequency_rank, 999999) ASC,
                    LENGTH(e.headword) ASC
                LIMIT ?
                """

                let containsEntries = try DictionaryEntry.fetchAll(db, sql: containsSql, arguments: [query, query, query, query, maxLength, limit - entries.count])
                print("üîç DBService: Contains query found \(containsEntries.count) entries (max length: \(maxLength))")

                // Add contains matches not already in results
                var addedCount = 0
                for entry in containsEntries where !existingIds.contains(entry.id) {
                    entries.append(entry)
                    existingIds.insert(entry.id)
                    addedCount += 1
                }
                print("üîç DBService: Added \(addedCount) new contains entries. Total now: \(entries.count)")
            }

            // Add kanji-based matches for compound words (e.g., "ÂÆâÁâ©", "ÂÆâÂ£≤„Çä" when searching "ÂÆâ„ÅÑ")
            // Extract kanji from query and find short words starting with that kanji
            // ONLY match words with similar readings to avoid unrelated words
            if entries.count < limit {
                let kanjiChars = query.unicodeScalars.filter { scalar in
                    // Check if character is in CJK Unified Ideographs range
                    (0x4E00...0x9FFF).contains(scalar.value)
                }

                let hiraganaChars = query.unicodeScalars.filter { scalar in
                    (0x3040...0x309F).contains(scalar.value)  // Hiragana range
                }

                // Only run kanji-based search if query contains BOTH kanji AND hiragana
                // This ensures "ÂÆâ„ÅÑ" triggers it but "ÂÆâÂøÉ" doesn't
                if !kanjiChars.isEmpty && !hiraganaChars.isEmpty {
                    let firstKanji = String(kanjiChars.prefix(1))
                    let readingPrefix = String(hiraganaChars.prefix(2))

                    print("üîç DBService: Adding kanji-based matches for '\(firstKanji)' with reading '\(readingPrefix)*'. Current count: \(entries.count)")

                    // CRITICAL: Filter by reading prefix to exclude unrelated words
                    // e.g., when searching "ÂÆâ„ÅÑ" („ÇÑ„Åô„ÅÑ), only match "ÂÆâÁâ©" („ÇÑ„Åô„ÇÇ„ÅÆ),
                    // NOT "ÂÆâÂøÉ" („ÅÇ„Çì„Åó„Çì) or "ÂÆâÂÖ®" („ÅÇ„Çì„Åú„Çì)
                    let kanjiSql = """
                    SELECT DISTINCT e.*
                    FROM dictionary_entries e
                    WHERE e.headword LIKE ? || '%'
                      AND e.headword != ?
                      AND e.reading_hiragana LIKE ? || '%'
                      AND LENGTH(e.headword) <= 4
                    ORDER BY
                        LENGTH(e.headword) ASC,
                        COALESCE(e.frequency_rank, 999999) ASC
                    LIMIT ?
                    """

                    let kanjiEntries = try DictionaryEntry.fetchAll(db, sql: kanjiSql, arguments: [firstKanji, query, readingPrefix, limit - entries.count])
                    print("üîç DBService: Kanji query found \(kanjiEntries.count) entries")

                    var kanjiAddedCount = 0
                    for entry in kanjiEntries where !existingIds.contains(entry.id) {
                        entries.append(entry)
                        existingIds.insert(entry.id)
                        kanjiAddedCount += 1
                    }
                    print("üîç DBService: Added \(kanjiAddedCount) new kanji-based entries. Total now: \(entries.count)")
                }
            }

            // Load senses for each entry
            for i in 0..<entries.count {
                let senses = try WordSense
                    .filter(Column("entry_id") == entries[i].id)
                    .order(Column("sense_order"))
                    .fetchAll(db)
                entries[i].senses = senses
            }

            // Special handling for words that are usually written in kana but have rare kanji forms
            // Examples: „Åô„Çã‚ÜíÁÇ∫„Çã, „ÇÑ„Å£„Å®‚ÜíÊº∏„Å®, „Åô„Åê‚ÜíÁõ¥„Åê
            // Problem: JMDict often only has the kanji variant, not the common kana form
            // Solution: Create virtual kana entries for common words that should appear first

            // Define words that should have virtual kana entries (usually kana words)
            let usuallyKanaWords: [String: (jlptLevel: String?, isAdverb: Bool)] = [
                "„Åô„Çã": ("N5", false),      // verb
                "„ÇÑ„Å£„Å®": ("N4", true),     // adverb
                "„Åô„Åê": ("N5", true),       // adverb
                "„Åæ„Å†": ("N5", true),       // adverb
                "„ÇÇ„ÅÜ": ("N5", true),       // adverb
                "„Åö„Å£„Å®": ("N4", true),     // adverb
                "„Åü„Åè„Åï„Çì": ("N5", true),   // adverb/na-adj
                "„Å®„Å¶„ÇÇ": ("N5", true),     // adverb
                "„Å°„Çá„Å£„Å®": ("N5", true),   // adverb
                "„Åç„Å£„Å®": ("N4", true),     // adverb
                "„Åù„Å£„Å®": ("N3", true),     // adverb
                "„Å©„ÅÜ„Åû": ("N5", true),     // adverb
                "„Å°„ÇÉ„Çì„Å®": ("N4", true),   // adverb
                "„ÇÑ„Å£„Å±„Çä": ("N4", true),   // adverb
                "„ÇÑ„ÅØ„Çä": ("N4", true),     // adverb
                "„Åù„Çå„Åß": ("N4", false),    // conjunction (rare kanji: ÂÖ∂„Çå„Åß)
            ]

            if let (jlptLevel, _) = usuallyKanaWords[query] {
                // Check if pure hiragana entry already exists
                let hasHiraganaEntry = entries.contains { $0.headword == query }

                if !hasHiraganaEntry {
                    // Find kanji variant to clone from (first entry with matching reading)
                    if let kanjiEntry = entries.first(where: {
                        $0.readingHiragana == query && $0.headword != query
                    }) {
                        print("üîç DBService: Creating virtual hiragana '\(query)' entry from '\(kanjiEntry.headword)'")
                        // Create virtual entry using the REAL entry's ID
                        // This allows fetchEntry to work correctly when user taps the entry
                        // The only difference is the headword (pure kana vs kanji)
                        let virtualEntry = DictionaryEntry(
                            id: kanjiEntry.id,  // Use real ID so fetchEntry works
                            headword: query,  // Pure hiragana
                            readingHiragana: kanjiEntry.readingHiragana,
                            readingRomaji: kanjiEntry.readingRomaji,
                            frequencyRank: kanjiEntry.frequencyRank,
                            pitchAccent: kanjiEntry.pitchAccent,
                            jlptLevel: jlptLevel,
                            createdAt: kanjiEntry.createdAt,
                            senses: kanjiEntry.senses  // Use same definitions
                        )
                        // Insert at beginning
                        entries.insert(virtualEntry, at: 0)
                        print("üîç DBService: Virtual '\(query)' entry created and inserted at position 0")
                    }
                }
            }

            // Merge duplicate entries (same headword + reading)
            // Example: „Åì„ÅÆÈ†É appears twice with different meanings ‚Üí merge into one entry with multiple senses
            let mergedEntries = self.mergeEntriesByHeadwordReading(entries)

            // Final sorting: demote rare kanji variants (uk = usually kana)
            // Priority order: pure kana form > common kanji > rare kanji
            // Example: „ÇÑ„Å£„Å® > [other compounds] > Êº∏„Å® (rare kanji)
            let finalEntries = mergedEntries.sorted { entry1, entry2 in
                let isRare1 = entry1.isRareKanji
                let isRare2 = entry2.isRareKanji

                // Rule 1: Non-rare entries always come before rare ones
                if isRare1 != isRare2 {
                    return !isRare1  // true comes first, so !isRare1 means non-rare first
                }

                // Rule 2: If both are same rarity, preserve SQL order (stable sort)
                return false
            }

            return finalEntries
        }
    }

    public func searchReverse(
        query: String,
        limit: Int,
        isEnglishQuery: Bool,
        semanticHint: String? = nil,
        coreHeadwords: Set<String>? = nil
    ) async throws -> [DictionaryEntry] {
        // Reverse search: English/Chinese ‚Üí Japanese
        print("üóÑÔ∏è DBService.searchReverse: query='\(query)' limit=\(limit) semanticHint=\(semanticHint ?? "nil") coreHeadwords=\(coreHeadwords?.count ?? 0)")
        guard !query.trimmingCharacters(in: .whitespaces).isEmpty else {
            print("üóÑÔ∏è DBService.searchReverse: Empty query, returning []")
            return []
        }

        return try await dbQueue.read { db in
            // Use direct LIKE search for more reliable results
            // This works better for short words like "go", "do", "be" that FTS5 may filter
            let lowerQuery = query.lowercased()
            print("üóÑÔ∏è DBService.searchReverse: lowerQuery='\(lowerQuery)'")

            // Extract semantic keywords from hint for boosting
            let semanticKeywords = semanticHint.map { self.getSemanticKeywordsFromHint($0, baseQuery: lowerQuery) } ?? []
            print("üóÑÔ∏è DBService.searchReverse: semanticKeywords=\(semanticKeywords)")

            // Check if we have Chinese columns (multilingual database)
            let hasChineseColumns = try Bool.fetchOne(db, sql: """
                SELECT COUNT(*) > 0
                FROM pragma_table_info('word_senses')
                WHERE name IN ('definition_chinese_simplified', 'definition_chinese_traditional')
                """) ?? false

            // Build core headwords filter - automatically detect from query
            var coreHeadwordsArray: [String] = []

            // Extract base verb from query (e.g., "to wake up" ‚Üí "wake up", "to go out" ‚Üí "go out")
            if lowerQuery.hasPrefix("to ") {
                let afterTo = String(lowerQuery.dropFirst(3)) // Remove "to "

                // Try full phrase first (e.g., "go out", "wake up")
                coreHeadwordsArray = self.getCoreHeadwordsForQuery(afterTo)

                // If no mapping found for full phrase, try first word only
                if coreHeadwordsArray.isEmpty, let spaceIndex = afterTo.firstIndex(of: " ") {
                    let firstWord = String(afterTo[..<spaceIndex])
                    coreHeadwordsArray = self.getCoreHeadwordsForQuery(firstWord)
                    print("üóÑÔ∏è DBService.searchReverse: No mapping for '\(afterTo)', trying first word '\(firstWord)', core headwords: \(coreHeadwordsArray)")
                } else {
                    print("üóÑÔ∏è DBService.searchReverse: Detected base verb '\(afterTo)', core headwords: \(coreHeadwordsArray)")
                }
            }

            // Merge with any explicitly provided core headwords
            if let providedCoreHeadwords = coreHeadwords {
                coreHeadwordsArray.append(contentsOf: providedCoreHeadwords)
                coreHeadwordsArray = Array(Set(coreHeadwordsArray)) // Remove duplicates
            }

            let sql: String
            var arguments: [DatabaseValueConvertible]

            if hasChineseColumns {
                // Multilingual database with Chinese support
                sql = """
                WITH candidate AS (
                    SELECT
                        e.id,
                        e.headword,
                        e.reading_hiragana,
                        e.reading_romaji,
                        e.frequency_rank,
                        e.pitch_accent,
                        e.created_at,
                        ws.definition_english,
                        ws.definition_chinese_simplified,
                        ws.definition_chinese_traditional,
                        ws.part_of_speech,
                        ws.sense_order,
                        -- Match priority: exact > prefix > word boundary > contains
                        -- Note: Exclude possessive forms (e.g., "one's" when searching "one")
                        CASE
                            WHEN LOWER(ws.definition_english) = ? THEN 0
                            WHEN LOWER(ws.definition_english) = 'to ' || ? THEN 1
                            WHEN LOWER(ws.definition_english) LIKE 'to ' || ? || ';%' THEN 1
                            WHEN LOWER(ws.definition_english) LIKE ? || ' %'
                                 AND LOWER(ws.definition_english) NOT LIKE ? || '''s%' THEN 2
                            WHEN LOWER(ws.definition_english) LIKE ? || ';%' THEN 2
                            WHEN LOWER(ws.definition_english) LIKE '% ' || ? || ' %'
                                 AND LOWER(ws.definition_english) NOT LIKE '%' || ? || '''s%' THEN 3
                            WHEN LOWER(ws.definition_english) LIKE '%; ' || ? || ';%' THEN 3
                            WHEN LOWER(ws.definition_english) LIKE '% ' || ?
                                 AND LOWER(ws.definition_english) NOT LIKE '%' || ? || '''s%' THEN 3
                            WHEN LOWER(ws.definition_english) LIKE '%; ' || ? || '; %' THEN 3
                            ELSE 4
                        END AS match_priority,
                        -- Phrasal penalty: For basic English words, penalize phrasal expressions
                        -- e.g., "after all", "if only", "so that", "but also", "even if"
                        CASE
                            WHEN LOWER(ws.definition_english) LIKE '%after all%' AND ? = 'all' THEN 1
                            WHEN LOWER(ws.definition_english) LIKE '%if only%' AND ? = 'if' THEN 1
                            WHEN LOWER(ws.definition_english) LIKE '%even if%' AND ? = 'if' THEN 1
                            WHEN LOWER(ws.definition_english) LIKE '%so that%' AND ? = 'so' THEN 1
                            WHEN LOWER(ws.definition_english) LIKE '%but also%' AND ? = 'but' THEN 1
                            WHEN LOWER(ws.definition_english) LIKE '%even so%' AND ? = 'so' THEN 1
                            WHEN LOWER(ws.definition_english) LIKE '%and yet%' AND ? = 'yet' THEN 1
                            WHEN LOWER(ws.definition_english) LIKE '%and still%' AND ? = 'still' THEN 1
                            WHEN LOWER(ws.definition_english) LIKE '%even though%' AND ? = 'though' THEN 1
                            ELSE 0
                        END AS phrasal_penalty,
                        -- Semantic boost: Prioritize entries with matching semantic markers
                        -- Example: "treat" + hint "ËØ∑ÂÆ¢" ‚Üí boost "(esp. food and drink)" or "someone to dinner"
                        -- Priority 0: Definition contains semantic keywords from hint (BOOSTED)
                        -- Priority 1: No semantic match (NORMAL)
                        CASE
                            -- Check if definition contains any semantic keywords
                            \(semanticKeywords.isEmpty ? "WHEN 0 THEN 1" : semanticKeywords.enumerated().map { index, _ in
                                "WHEN LOWER(ws.definition_english) LIKE ? THEN 0"
                            }.joined(separator: "\n                            "))
                            ELSE 1
                        END AS semantic_boost,
                        -- Parenthetical penalty: prioritize primary definitions over contextual usage
                        -- Priority 0: Query word appears as PRIMARY definition (not in parentheses or "as a/an" context)
                        -- Priority 1: Query word appears in CONTEXTUAL usage (inside parentheses or "as a/an" usage)
                        -- Examples:
                        --   - "examination; exam; test" ‚Üí Priority 0 (primary)
                        --   - "question (e.g. on a test)" ‚Üí Priority 1 (contextual - inside parentheses)
                        --   - "as a test; tentatively" ‚Üí Priority 1 (contextual - "as a" usage)
                        --   - "inspection (e.g. customs); test" ‚Üí Priority 0 (test is NOT in the parentheses)
                        CASE
                            -- Check for "as a/an [query]" pattern: these are always contextual/secondary meanings
                            -- Examples: "as a test", "as an experiment", "by way of a test"
                            WHEN LOWER(ws.definition_english) LIKE '%as a ' || ? || '%' THEN 1
                            WHEN LOWER(ws.definition_english) LIKE '%as an ' || ? || '%' THEN 1
                            WHEN LOWER(ws.definition_english) LIKE '%by way of a ' || ? || '%' THEN 1
                            WHEN LOWER(ws.definition_english) LIKE '%by way of an ' || ? || '%' THEN 1
                            -- Check if query appears inside parentheses: "(... query ...)"
                            -- Must check for both "(" before AND ")" after the query word
                            WHEN LOWER(ws.definition_english) LIKE '%(' || ? || ')%' THEN 1
                            WHEN LOWER(ws.definition_english) LIKE '%(' || ? || ' %'
                                 AND LOWER(ws.definition_english) LIKE '%(' || ? || '%' || ')%' THEN 1
                            WHEN LOWER(ws.definition_english) LIKE '%(' || ? || ';%'
                                 AND LOWER(ws.definition_english) LIKE '%(' || ? || '%' || ')%' THEN 1
                            WHEN LOWER(ws.definition_english) LIKE '%(' || ? || ',%'
                                 AND LOWER(ws.definition_english) LIKE '%(' || ? || '%' || ')%' THEN 1
                            WHEN LOWER(ws.definition_english) LIKE '% ' || ? || ')%' THEN 1
                            WHEN LOWER(ws.definition_english) LIKE '%;' || ? || ')%' THEN 1
                            WHEN LOWER(ws.definition_english) LIKE '%,' || ? || ')%' THEN 1
                            -- Check for "e.g." pattern: only mark as parenthetical if query is BETWEEN "e.g." and ")"
                            -- Pattern: "(e.g.% query%)" - ensures query is inside the e.g. parentheses
                            WHEN LOWER(ws.definition_english) LIKE '%(e.g.%' || ? || '%' || ')%'
                                 AND LOWER(ws.definition_english) NOT LIKE '%(e.g.%' || ')%' || ? || '%' THEN 1
                            -- Otherwise, it's a primary definition
                            ELSE 0
                        END AS parenthetical_priority,
                        -- Part-of-speech weight: verb=0, noun=1, other=2
                        CASE
                            WHEN ws.part_of_speech LIKE '%verb%' THEN 0
                            WHEN ws.part_of_speech LIKE '%noun%' THEN 1
                            ELSE 2
                        END AS pos_weight,
                        -- Conjunction priority: distinguish causative (Âõ†Êûú) vs adversative (ÈÄÜÊé•) conjunctions
                        -- Priority 0: Causative/sequential conjunctions (È†ÜÊé•): so/therefore/accordingly
                        --             „Å†„Åã„Çâ„ÄÅ„Åù„Çå„Åß„ÄÅ„Åß„Åô„Åã„Çâ„ÄÅÂÖ∂Âá¶„Åß„ÄÅ„Åù„ÇåÊïÖ
                        -- Priority 1: Other conjunctions
                        -- Priority 2: Adversative conjunctions (ÈÄÜÊé•): but/however/nevertheless/still
                        --             „Åß„ÇÇ„ÄÅ„Åó„Åã„Åó„ÄÅ„Åë„Çå„Å©„ÇÇ„ÄÅÊâÄ„Åå (demoted for "so" searches)
                        -- Priority 3: Other parts of speech
                        CASE
                            -- Priority 0: Causative/sequential conjunctions (È†ÜÊé•)
                            WHEN ws.part_of_speech LIKE '%conjunction%'
                                 AND (LOWER(ws.definition_english) LIKE '%therefore%'
                                      OR LOWER(ws.definition_english) LIKE '%accordingly%'
                                      OR LOWER(ws.definition_english) LIKE '%consequently%'
                                      OR LOWER(ws.definition_english) LIKE '%for that reason%'
                                      OR LOWER(ws.definition_english) LIKE '%on those grounds%'
                                      OR LOWER(ws.definition_english) LIKE '%that is why%'
                                      OR LOWER(ws.definition_english) LIKE '%(and) then%')
                            THEN 0
                            -- Priority 2: Adversative conjunctions (ÈÄÜÊé•) - DEMOTE
                            WHEN ws.part_of_speech LIKE '%conjunction%'
                                 AND (LOWER(ws.definition_english) LIKE 'but;%'
                                      OR LOWER(ws.definition_english) = 'but'
                                      OR LOWER(ws.definition_english) LIKE 'however;%'
                                      OR LOWER(ws.definition_english) = 'however'
                                      OR LOWER(ws.definition_english) LIKE '%but;%'
                                      OR LOWER(ws.definition_english) LIKE '%however;%'
                                      OR LOWER(ws.definition_english) LIKE '%nevertheless;%'
                                      OR LOWER(ws.definition_english) LIKE '%even so;%'
                                      OR LOWER(ws.definition_english) LIKE '%still;%'
                                      OR LOWER(ws.definition_english) LIKE '%even though;%'
                                      OR LOWER(ws.definition_english) LIKE '%on the contrary%'
                                      OR LOWER(ws.definition_english) LIKE '%though;%')
                            THEN 2
                            -- Priority 1: Other conjunctions (neutral)
                            WHEN ws.part_of_speech LIKE '%conjunction%' THEN 1
                            -- Priority 3: Other parts of speech
                            ELSE 3
                        END AS conjunction_priority,
                        -- Semantic category priority: prioritize by real-world usage frequency
                        -- Order: ÁùÄ„Çã > Â±•„Åè > Êéõ„Åë„Çã > Á∑†„ÇÅ„Çã > ‰∏ã„Åí„Çã > ÁÇ∫„Çã > Â∑Æ„Åô
                        CASE
                            -- Tier 0: ÁùÄ„Çã - most specific clothing verb (from shoulders down)
                            WHEN ws.definition_english LIKE '%(from the shoulders down)%' THEN 0
                            -- Tier 1: Â±•„Åè - pants/shoes/footwear (high frequency)
                            WHEN ws.definition_english LIKE '%(lower-body%' OR ws.definition_english LIKE '%(footwear%'
                                 OR ws.definition_english LIKE '%(pants%' OR ws.definition_english LIKE '%(shoes%' THEN 1
                            -- Tier 2: Êéõ„Åë„Çã - glasses/necklace/accessories
                            WHEN ws.definition_english LIKE '%(glasses%' OR ws.definition_english LIKE '%(necklace%'
                                 OR ws.definition_english LIKE '%(accessor%' THEN 2
                            -- Tier 3: Á∑†„ÇÅ„Çã, Ë¢´„Çã - belt/necktie/hat
                            WHEN ws.definition_english LIKE '%(belt%' OR ws.definition_english LIKE '%(necktie%'
                                 OR ws.definition_english LIKE '%(tie%' OR ws.definition_english LIKE '%(one''s head)%'
                                 OR ws.definition_english LIKE '%(hat%' THEN 3
                            -- Tier 4: ‰∏ã„Åí„Çã - hanging decoration
                            WHEN ws.definition_english LIKE '%e.g. decoration%' THEN 4
                            -- Tier 5: ÁÇ∫„Çã - abstract/general wear (clothes without specific part)
                            WHEN ws.definition_english LIKE '%(cloth%' OR ws.definition_english LIKE '%(garment%' THEN 5
                            -- Tier 6: Â∑Æ„Åô - sword/samurai terminology (least common)
                            WHEN ws.definition_english LIKE '%(a sword%' OR ws.definition_english LIKE '%(sword%'
                                 OR ws.definition_english LIKE '%at one''s side%' THEN 6
                            ELSE 7
                        END AS semantic_priority,
                        -- Idiom penalty: Demote idioms/proverbs with ratio expressions
                        -- e.g., "in ninety-nine cases out of a hundred" ‚Üí idiom, not direct translation
                        CASE
                            WHEN LOWER(ws.definition_english) LIKE '%out of%' THEN 1
                            ELSE 0
                        END AS idiom_priority
                    FROM dictionary_entries e
                    JOIN word_senses ws ON e.id = ws.entry_id
                    WHERE (
                        -- Word boundary matching: only match complete words, not substrings
                        -- Matches: "ten", "ten;", "; ten", "ten,", etc.
                        -- Does NOT match: "often", "listen", "tenacious"
                        LOWER(ws.definition_english) = ?
                        OR LOWER(ws.definition_english) LIKE ? || ' %'
                        OR LOWER(ws.definition_english) LIKE ? || ';%'
                        OR LOWER(ws.definition_english) LIKE ? || ',%'
                        OR LOWER(ws.definition_english) LIKE ? || '.%'
                        OR LOWER(ws.definition_english) LIKE ? || ')%'
                        OR LOWER(ws.definition_english) LIKE '% ' || ? || ' %'
                        OR LOWER(ws.definition_english) LIKE '% ' || ? || ';%'
                        OR LOWER(ws.definition_english) LIKE '% ' || ? || ',%'
                        OR LOWER(ws.definition_english) LIKE '% ' || ? || '.%'
                        OR LOWER(ws.definition_english) LIKE '% ' || ? || ')%'
                        OR LOWER(ws.definition_english) LIKE '% ' || ?
                        OR LOWER(ws.definition_english) LIKE '%; ' || ?
                        OR LOWER(ws.definition_english) LIKE '%,' || ?
                        OR LOWER(ws.definition_english) LIKE '%(' || ?
                        OR COALESCE(ws.definition_chinese_simplified, '') LIKE '%' || ? || '%'
                        OR COALESCE(ws.definition_chinese_traditional, '') LIKE '%' || ? || '%'
                    )
                    -- Exclude possessive forms (e.g., exclude "one's" when searching "one")
                    AND LOWER(ws.definition_english) NOT LIKE '%' || ? || '''s%'
                    -- Exclude "[word] [number]" patterns for number queries
                    -- Two-tier filtering: strict for one~five (often used as pronouns), lenient for six~twelve
                    AND (
                        -- Not a number query at all
                        ? NOT IN ('one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve')
                        -- Moderate filtering for six~twelve (less used as pronouns, but still filter examples)
                        OR (
                            ? IN ('six', 'seven', 'eight', 'nine', 'ten', 'eleven', 'twelve')
                            AND LOWER(ws.definition_english) NOT LIKE '%' || ? || ' o''clock%'
                            AND LOWER(ws.definition_english) NOT LIKE '%part ' || ? || '%'
                            -- Filter numbers in parentheses (examples): (approx. six feet), (e.g. six months)
                            AND (LOWER(ws.definition_english) NOT LIKE '%(%' OR LOWER(ws.definition_english) NOT LIKE '% ' || ? || ' %')
                            -- Filter time expressions: six months, six years (but keep "six-stringed", "six senses")
                            AND LOWER(ws.definition_english) NOT LIKE '%' || ? || ' months%'
                            AND LOWER(ws.definition_english) NOT LIKE '%' || ? || ' years%'
                            AND LOWER(ws.definition_english) NOT LIKE '%' || ? || ' days%'
                            AND LOWER(ws.definition_english) NOT LIKE '%' || ? || ' weeks%'
                        )
                        -- Lenient filtering for six and above (less commonly used as pronouns)
                        OR (
                            ? IN ('one', 'two', 'three', 'four', 'five')
                            AND LOWER(ws.definition_english) NOT LIKE '%the ' || ? || '%'
                            AND LOWER(ws.definition_english) NOT LIKE '%this ' || ? || '%'
                            AND LOWER(ws.definition_english) NOT LIKE '%that ' || ? || '%'
                            AND LOWER(ws.definition_english) NOT LIKE '%which ' || ? || '%'
                            AND LOWER(ws.definition_english) NOT LIKE '%another ' || ? || '%'
                            AND LOWER(ws.definition_english) NOT LIKE '%any ' || ? || '%'
                            AND LOWER(ws.definition_english) NOT LIKE '%each ' || ? || '%'
                            AND LOWER(ws.definition_english) NOT LIKE '%every ' || ? || '%'
                            AND LOWER(ws.definition_english) NOT LIKE '%between ' || ? || '%'
                            AND LOWER(ws.definition_english) NOT LIKE '%of ' || ? || '%'
                            AND LOWER(ws.definition_english) NOT LIKE '%or ' || ? || '%'
                            AND LOWER(ws.definition_english) NOT LIKE '%part ' || ? || '%'
                            AND LOWER(ws.definition_english) NOT LIKE '%' || ? || ' o''clock%'
                            AND LOWER(ws.definition_english) NOT LIKE '%(%' || ? || '%'
                            AND LOWER(ws.definition_english) NOT LIKE '%' || ? || ' days%'
                            AND LOWER(ws.definition_english) NOT LIKE '%' || ? || ' weeks%'
                            AND LOWER(ws.definition_english) NOT LIKE '%' || ? || ' months%'
                            AND LOWER(ws.definition_english) NOT LIKE '%' || ? || ' years%'
                        )
                    )
                ),
                aggregated AS (
                    SELECT
                        c.id,
                        MIN(c.match_priority) AS match_priority,
                        MIN(c.phrasal_penalty) AS phrasal_penalty,
                        MIN(c.semantic_boost) AS semantic_boost,
                        MIN(c.parenthetical_priority) AS parenthetical_priority,
                        MIN(c.pos_weight) AS pos_weight,
                        MIN(c.conjunction_priority) AS conjunction_priority,
                        MIN(c.semantic_priority) AS semantic_priority,
                        MIN(c.idiom_priority) AS idiom_priority,
                        MIN(c.sense_order) AS first_matching_sense
                    FROM candidate c
                    GROUP BY c.id
                )
                SELECT e.*
                FROM aggregated agg
                JOIN dictionary_entries e ON e.id = agg.id
                ORDER BY
                    -- Priority 1: Core native equivalent (if provided)
                    CASE
                        WHEN \(coreHeadwordsArray.isEmpty ? "0" : "e.headword IN (\(coreHeadwordsArray.map { _ in "?" }.joined(separator: ",")))") THEN 0
                        ELSE 1
                    END,
                    -- Priority 2: JLPT existence (common words with JLPT > obscure words without JLPT)
                    -- e.g., Â£≤„Çå„Çã (N3) before È¨ª„Åê (no JLPT - archaic)
                    CASE
                        WHEN e.jlpt_level IS NOT NULL THEN 0
                        ELSE 1
                    END,
                    -- Priority 3: Phrasal penalty (NEW - for basic English words)
                    -- Demote phrasal expressions like "after all", "if only", "so that"
                    -- This ensures core words with direct translations rank higher
                    -- e.g., ÂÖ®ÈÉ® (all) before Êõ¥„Å´ (after all)
                    agg.phrasal_penalty,
                    -- Priority 4: Semantic boost (NEW - for contextual hints)
                    -- Boost entries with matching semantic markers from user hints
                    -- e.g., "treat" + hint "ËØ∑ÂÆ¢" ‚Üí boost "(esp. food and drink)"
                    -- 0 = boosted (contains semantic keywords), 1 = normal
                    agg.semantic_boost,
                    -- Priority 5: Match quality (word position in definition)
                    -- CRITICAL: Moved BEFORE conjunction_priority for basic English words
                    -- e.g., for "all": ÂÖ®ÈÉ® (def="all; entire") before Êõ¥„Å´ (def contains "after all")
                    agg.match_priority,
                    -- Priority 6: JLPT level priority (N5 > N4 > N3 > N2 > N1)
                    -- CRITICAL: Moved BEFORE conjunction_priority for basic English words
                    -- Prioritizes common vocabulary over grammatical conjunctions
                    -- e.g., ÂÖ®ÈÉ® (N5: all) before Êõ¥„Å´ (N3: furthermore; after all)
                    CASE
                        WHEN e.jlpt_level = 'N5' THEN 0
                        WHEN e.jlpt_level = 'N4' THEN 1
                        WHEN e.jlpt_level = 'N3' THEN 2
                        WHEN e.jlpt_level = 'N2' THEN 3
                        WHEN e.jlpt_level = 'N1' THEN 4
                        ELSE 5
                    END,
                    -- Priority 7: Semantic category (clothes > accessories > shoes/hat > belt > sword)
                    agg.semantic_priority,
                    -- Priority 8: Parenthetical penalty
                    -- Ensure primary definitions (e.g., "test") rank higher than contextual usage (e.g., "question (e.g. on a test)")
                    -- CRITICAL: Must come BEFORE first_matching_sense to distinguish:
                    --   - Ë©¶È®ì (sense #1: "examination; exam; test") vs
                    --   - ÂïèÈ°å (sense #1: "question (e.g. on a test)")
                    agg.parenthetical_priority,
                    -- Priority 9: Conjunction priority (logical conjunctions before conversational transitions)
                    -- For queries like "so", "but", "however", "therefore"
                    -- Prioritize logical conjunctions („Å†„Åã„Çâ„ÄÅ„Åù„Çå„Åß "therefore") over conversational transitions („Åò„ÇÉ„ÅÇ„ÄÅ„Åß„ÅØ "well then")
                    agg.conjunction_priority,
                    -- Priority 10: First matching sense (sense_order: 1st sense > 2nd sense > ...)
                    -- CRITICAL: This must come BEFORE main verb boost to ensure primary meanings rank higher
                    -- e.g., Ë©¶È®ì (sense #1: "test") before ‰∏ÄÁï™ (sense #4: "as a test")
                    agg.first_matching_sense,
                    -- Priority 11: Main verb boost (Âü∫Á°ÄÂä®ËØç‰ºòÂÖà)
                    -- N5 SHORT words (‚â§3 chars) appear before their derivatives
                    -- e.g., ËÅû„Åè (2 chars) before ËÅû„ÅçÂÖ•„Çã (4 chars), È£ü„Åπ„Çã (3 chars) before È£ü„ÅπÊ≠©„Åè (4 chars)
                    -- Note: Using N5 only since frequency data is not yet populated (all entries have freq=201)
                    CASE
                        WHEN e.jlpt_level = 'N5'
                             AND LENGTH(e.headword) <= 3
                        THEN 0
                        ELSE 1
                    END,
                    -- Priority 12: Idiom penalty (direct translation > compound words > idioms)
                    -- e.g., Áôæ before ÁôæÁÇπ before ‰πùÂàÜ‰πùÂéò
                    agg.idiom_priority,
                    -- Priority 13: Frequency (common words first, generalizable across all queries)
                    COALESCE(e.frequency_rank, 999999),
                    -- Priority 14: Part-of-speech (verbs > nouns > other)
                    agg.pos_weight,
                    -- Priority 15: DEMOTE pure katakana (reverse of old logic)
                    CASE
                        WHEN ? = 1
                             AND e.headword != ''
                             AND e.headword GLOB '[„Ç°-„É∂„Éº]*'
                             AND e.headword NOT GLOB '*[„ÅÅ-„Çì‰∏Ä-ÈæØ]*'
                        THEN 1
                        ELSE 0
                    END,
                    -- Tie-breakers
                    e.created_at,
                    e.id
                LIMIT ?
                """
                arguments = [
                    lowerQuery, lowerQuery, lowerQuery,  // match_priority: lines 465-467
                    lowerQuery, lowerQuery,              // match_priority: lines 468-470
                    lowerQuery,                          // match_priority: line 471
                    lowerQuery, lowerQuery,              // match_priority: lines 472-473
                    lowerQuery,                          // match_priority: line 481
                    lowerQuery, lowerQuery,              // match_priority: lines 482-483
                    lowerQuery,                          // match_priority: line 484
                    // phrasal_penalty (9 params - one for each phrasal check)
                    lowerQuery,                    // line 482: 'after all' AND ? = 'all'
                    lowerQuery,                    // line 483: 'if only' AND ? = 'if'
                    lowerQuery,                    // line 484: 'even if' AND ? = 'if'
                    lowerQuery,                    // line 485: 'so that' AND ? = 'so'
                    lowerQuery,                    // line 486: 'but also' AND ? = 'but'
                    lowerQuery,                    // line 487: 'even so' AND ? = 'so'
                    lowerQuery,                    // line 488: 'and yet' AND ? = 'yet'
                    lowerQuery,                    // line 489: 'and still' AND ? = 'still'
                    lowerQuery,                    // line 490: 'even though' AND ? = 'though'
                ]
                // Add semantic keywords for semantic_boost (dynamic count based on keywords)
                arguments.append(contentsOf: semanticKeywords.map { $0 as DatabaseValueConvertible })
                // parenthetical_priority (16 params: 4 for "as a/an" + 12 for parentheses)
                arguments.append(contentsOf: [
                    lowerQuery,                    // line 404: LIKE '%as a ' || ? || '%'
                    lowerQuery,                    // line 405: LIKE '%as an ' || ? || '%'
                    lowerQuery,                    // line 406: LIKE '%by way of a ' || ? || '%'
                    lowerQuery,                    // line 407: LIKE '%by way of an ' || ? || '%'
                    lowerQuery,                    // line 410: LIKE '%(' || ? || ')%'
                    lowerQuery, lowerQuery,        // lines 411-412: LIKE '%(' || ? || ' %' AND LIKE '%(' || ? || '%' || ')%'
                    lowerQuery, lowerQuery,        // lines 413-414: LIKE '%(' || ? || ';%' AND LIKE '%(' || ? || '%' || ')%'
                    lowerQuery, lowerQuery,        // lines 415-416: LIKE '%(' || ? || ',%' AND LIKE '%(' || ? || '%' || ')%'
                    lowerQuery,                    // line 417: LIKE '% ' || ? || ')%'
                    lowerQuery,                    // line 418: LIKE '%;' || ? || ')%'
                    lowerQuery,                    // line 419: LIKE '%,' || ? || ')%'
                    lowerQuery, lowerQuery,        // lines 422-423: LIKE '%(e.g.%' || ? || '%' || ')%' AND NOT LIKE '%(e.g.%' || ')%' || ? || '%'
                    // WHERE clause: Word boundary matching (lines 328-345)
                    lowerQuery,                          // Line 328: = ?
                    lowerQuery,                          // Line 329: LIKE ? || ' %'
                    lowerQuery,                          // Line 330: LIKE ? || ';%'
                    lowerQuery,                          // Line 331: LIKE ? || ',%'
                    lowerQuery,                          // Line 332: LIKE ? || '.%'
                    lowerQuery,                          // Line 333: LIKE ? || ')%'
                    lowerQuery,                          // Line 334: LIKE '% ' || ? || ' %'
                    lowerQuery,                          // Line 335: LIKE '% ' || ? || ';%'
                    lowerQuery,                          // Line 336: LIKE '% ' || ? || ',%'
                    lowerQuery,                          // Line 337: LIKE '% ' || ? || '.%'
                    lowerQuery,                          // Line 338: LIKE '% ' || ? || ')%'
                    lowerQuery,                          // Line 339: LIKE '% ' || ?
                    lowerQuery,                          // Line 340: LIKE '%; ' || ?
                    lowerQuery,                          // Line 341: LIKE '%,' || ?
                    lowerQuery,                          // Line 342: LIKE '%(' || ?
                    query,                               // Line 343: Chinese simplified
                    query,                               // Line 344: Chinese traditional
                    lowerQuery,                          // WHERE clause: NOT LIKE possessive (line 347)
                    // Two-tier number filtering (lines 335-370)
                    lowerQuery,                          // Line 335: number check (NOT IN)
                    lowerQuery,                          // Line 338: six~twelve check (IN)
                    lowerQuery,                          // Line 339: o'clock (six~twelve)
                    lowerQuery,                          // Line 340: part (six~twelve)
                    lowerQuery,                          // Line 342: parentheses filter (six~twelve) - '% [num] %'
                    lowerQuery,                          // Line 344: months (six~twelve)
                    lowerQuery,                          // Line 345: years (six~twelve)
                    lowerQuery,                          // Line 346: days (six~twelve)
                    lowerQuery,                          // Line 347: weeks (six~twelve)
                    lowerQuery,                          // Line 351: one~five check (IN)
                    lowerQuery,                          // Line 345: the [num] (one~five)
                    lowerQuery,                          // Line 346: this [num] (one~five)
                    lowerQuery,                          // Line 347: that [num] (one~five)
                    lowerQuery,                          // Line 348: which [num] (one~five)
                    lowerQuery,                          // Line 349: another [num] (one~five)
                    lowerQuery,                          // Line 350: any [num] (one~five)
                    lowerQuery,                          // Line 351: each [num] (one~five)
                    lowerQuery,                          // Line 352: every [num] (one~five)
                    lowerQuery,                          // Line 353: between [num] (one~five)
                    lowerQuery,                          // Line 354: of [num] (one~five)
                    lowerQuery,                          // Line 355: or [num] (one~five)
                    lowerQuery,                          // Line 356: part [num] (one~five)
                    lowerQuery,                          // Line 357: [num] o'clock (one~five)
                    lowerQuery,                          // Line 358: (... [num] ...) (one~five)
                    lowerQuery,                          // Line 359: [num] days (one~five)
                    lowerQuery,                          // Line 360: [num] weeks (one~five)
                    lowerQuery,                          // Line 361: [num] months (one~five)
                    lowerQuery,                          // Line 362: [num] years (one~five)
                ])
                // Add core headwords if provided
                if !coreHeadwordsArray.isEmpty {
                    arguments.append(contentsOf: coreHeadwordsArray.map { $0 as DatabaseValueConvertible })
                }
                arguments.append(isEnglishQuery ? 1 : 0)  // katakana check
                arguments.append(limit * 2)               // LIMIT
            } else {
                // English-only database (test fixtures)
                sql = """
                WITH candidate AS (
                    SELECT
                        e.id,
                        e.headword,
                        e.reading_hiragana,
                        e.reading_romaji,
                        e.frequency_rank,
                        e.pitch_accent,
                        e.created_at,
                        ws.definition_english,
                        ws.part_of_speech,
                        ws.sense_order,
                        -- Match priority
                        CASE
                            WHEN LOWER(ws.definition_english) = ? THEN 0
                            WHEN LOWER(ws.definition_english) = 'to ' || ? THEN 1
                            WHEN LOWER(ws.definition_english) LIKE 'to ' || ? || ';%' THEN 1
                            WHEN LOWER(ws.definition_english) LIKE ? || ' %' THEN 2
                            WHEN LOWER(ws.definition_english) LIKE ? || ';%' THEN 2
                            WHEN LOWER(ws.definition_english) LIKE '% ' || ? || ' %' THEN 3
                            WHEN LOWER(ws.definition_english) LIKE '%; ' || ? || ';%' THEN 3
                            WHEN LOWER(ws.definition_english) LIKE '% ' || ? THEN 3
                            WHEN LOWER(ws.definition_english) LIKE '%; ' || ? || '; %' THEN 3
                            ELSE 4
                        END AS match_priority,
                        -- Parenthetical penalty: prioritize primary definitions over contextual usage
                        -- Priority 0: Query word appears as PRIMARY definition (not in parentheses or "as a/an" context)
                        -- Priority 1: Query word appears in CONTEXTUAL usage (inside parentheses or "as a/an" usage)
                        -- Examples:
                        --   - "examination; exam; test" ‚Üí Priority 0 (primary)
                        --   - "question (e.g. on a test)" ‚Üí Priority 1 (contextual - inside parentheses)
                        --   - "as a test; tentatively" ‚Üí Priority 1 (contextual - "as a" usage)
                        --   - "inspection (e.g. customs); test" ‚Üí Priority 0 (test is NOT in the parentheses)
                        CASE
                            -- Check for "as a/an [query]" pattern: these are always contextual/secondary meanings
                            -- Examples: "as a test", "as an experiment", "by way of a test"
                            WHEN LOWER(ws.definition_english) LIKE '%as a ' || ? || '%' THEN 1
                            WHEN LOWER(ws.definition_english) LIKE '%as an ' || ? || '%' THEN 1
                            WHEN LOWER(ws.definition_english) LIKE '%by way of a ' || ? || '%' THEN 1
                            WHEN LOWER(ws.definition_english) LIKE '%by way of an ' || ? || '%' THEN 1
                            -- Check if query appears inside parentheses: "(... query ...)"
                            -- Must check for both "(" before AND ")" after the query word
                            WHEN LOWER(ws.definition_english) LIKE '%(' || ? || ')%' THEN 1
                            WHEN LOWER(ws.definition_english) LIKE '%(' || ? || ' %'
                                 AND LOWER(ws.definition_english) LIKE '%(' || ? || '%' || ')%' THEN 1
                            WHEN LOWER(ws.definition_english) LIKE '%(' || ? || ';%'
                                 AND LOWER(ws.definition_english) LIKE '%(' || ? || '%' || ')%' THEN 1
                            WHEN LOWER(ws.definition_english) LIKE '%(' || ? || ',%'
                                 AND LOWER(ws.definition_english) LIKE '%(' || ? || '%' || ')%' THEN 1
                            WHEN LOWER(ws.definition_english) LIKE '% ' || ? || ')%' THEN 1
                            WHEN LOWER(ws.definition_english) LIKE '%;' || ? || ')%' THEN 1
                            WHEN LOWER(ws.definition_english) LIKE '%,' || ? || ')%' THEN 1
                            -- Check for "e.g." pattern: only mark as parenthetical if query is BETWEEN "e.g." and ")"
                            -- Pattern: "(e.g.% query%)" - ensures query is inside the e.g. parentheses
                            WHEN LOWER(ws.definition_english) LIKE '%(e.g.%' || ? || '%' || ')%'
                                 AND LOWER(ws.definition_english) NOT LIKE '%(e.g.%' || ')%' || ? || '%' THEN 1
                            -- Otherwise, it's a primary definition
                            ELSE 0
                        END AS parenthetical_priority,
                        -- Semantic boost: Prioritize entries with matching semantic markers
                        -- Example: "treat" + hint "ËØ∑ÂÆ¢" ‚Üí boost "(esp. food and drink)" or "someone to dinner"
                        -- Priority 0: Definition contains semantic keywords from hint (BOOSTED)
                        -- Priority 1: No semantic match (NORMAL)
                        CASE
                            -- Check if definition contains any semantic keywords
                            \(semanticKeywords.isEmpty ? "WHEN 0 THEN 1" : semanticKeywords.enumerated().map { index, _ in
                                "WHEN LOWER(ws.definition_english) LIKE ? THEN 0"
                            }.joined(separator: "\n                            "))
                            ELSE 1
                        END AS semantic_boost,
                        -- Part-of-speech weight
                        CASE
                            WHEN ws.part_of_speech LIKE '%verb%' THEN 0
                            WHEN ws.part_of_speech LIKE '%noun%' THEN 1
                            ELSE 2
                        END AS pos_weight,
                        -- Semantic category priority: prioritize by real-world usage frequency
                        -- Order: ÁùÄ„Çã > Â±•„Åè > Êéõ„Åë„Çã > Á∑†„ÇÅ„Çã > ‰∏ã„Åí„Çã > ÁÇ∫„Çã > Â∑Æ„Åô
                        CASE
                            -- Tier 0: ÁùÄ„Çã - most specific clothing verb (from shoulders down)
                            WHEN ws.definition_english LIKE '%(from the shoulders down)%' THEN 0
                            -- Tier 1: Â±•„Åè - pants/shoes/footwear (high frequency)
                            WHEN ws.definition_english LIKE '%(lower-body%' OR ws.definition_english LIKE '%(footwear%'
                                 OR ws.definition_english LIKE '%(pants%' OR ws.definition_english LIKE '%(shoes%' THEN 1
                            -- Tier 2: Êéõ„Åë„Çã - glasses/necklace/accessories
                            WHEN ws.definition_english LIKE '%(glasses%' OR ws.definition_english LIKE '%(necklace%'
                                 OR ws.definition_english LIKE '%(accessor%' THEN 2
                            -- Tier 3: Á∑†„ÇÅ„Çã, Ë¢´„Çã - belt/necktie/hat
                            WHEN ws.definition_english LIKE '%(belt%' OR ws.definition_english LIKE '%(necktie%'
                                 OR ws.definition_english LIKE '%(tie%' OR ws.definition_english LIKE '%(one''s head)%'
                                 OR ws.definition_english LIKE '%(hat%' THEN 3
                            -- Tier 4: ‰∏ã„Åí„Çã - hanging decoration
                            WHEN ws.definition_english LIKE '%e.g. decoration%' THEN 4
                            -- Tier 5: ÁÇ∫„Çã - abstract/general wear (clothes without specific part)
                            WHEN ws.definition_english LIKE '%(cloth%' OR ws.definition_english LIKE '%(garment%' THEN 5
                            -- Tier 6: Â∑Æ„Åô - sword/samurai terminology (least common)
                            WHEN ws.definition_english LIKE '%(a sword%' OR ws.definition_english LIKE '%(sword%'
                                 OR ws.definition_english LIKE '%at one''s side%' THEN 6
                            ELSE 7
                        END AS semantic_priority
                    FROM dictionary_entries e
                    JOIN word_senses ws ON e.id = ws.entry_id
                    WHERE LOWER(ws.definition_english) LIKE '%' || ? || '%'
                ),
                aggregated AS (
                    SELECT
                        c.id,
                        MIN(c.match_priority) AS match_priority,
                        MIN(c.parenthetical_priority) AS parenthetical_priority,
                        MIN(c.semantic_boost) AS semantic_boost,
                        MIN(c.pos_weight) AS pos_weight,
                        MIN(c.conjunction_priority) AS conjunction_priority,
                        MIN(c.semantic_priority) AS semantic_priority,
                        MIN(c.sense_order) AS first_matching_sense
                    FROM candidate c
                    GROUP BY c.id
                )
                SELECT e.*
                FROM aggregated agg
                JOIN dictionary_entries e ON e.id = agg.id
                ORDER BY
                    -- Priority 1: Core native equivalent
                    CASE
                        WHEN \(coreHeadwordsArray.isEmpty ? "0" : "e.headword IN (\(coreHeadwordsArray.map { _ in "?" }.joined(separator: ",")))") THEN 0
                        ELSE 1
                    END,
                    -- Priority 2: Semantic boost (contextual hints)
                    -- Boost entries with matching semantic markers from user hints
                    -- 0 = boosted (contains semantic keywords), 1 = normal
                    agg.semantic_boost,
                    -- Priority 3: Semantic category (clothes > accessories > shoes/hat > belt > sword)
                    agg.semantic_priority,
                    -- Priority 4: First matching sense (sense_order: 1st sense > 2nd sense > ...)
                    agg.first_matching_sense,
                    -- Priority 5: Conjunction priority (conjunctions first for linking words)
                    agg.conjunction_priority,
                    -- Priority 6: Part-of-speech
                    agg.pos_weight,
                    -- Priority 7: Parenthetical semantic match
                    agg.parenthetical_priority,
                    -- Priority 8: Common words
                    CASE
                        WHEN e.frequency_rank IS NOT NULL AND e.frequency_rank <= 5000 THEN 0
                        ELSE 1
                    END,
                    -- Priority 9: DEMOTE pure katakana
                    CASE
                        WHEN ? = 1
                             AND e.headword != ''
                             AND e.headword GLOB '[„Ç°-„É∂„Éº]*'
                             AND e.headword NOT GLOB '*[„ÅÅ-„Çì‰∏Ä-ÈæØ]*'
                        THEN 1
                        ELSE 0
                    END,
                    -- Priority 10: Match quality
                    agg.match_priority,
                    -- Priority 11: Frequency
                    COALESCE(e.frequency_rank, 999999),
                    -- Tie-breakers
                    e.created_at,
                    e.id
                LIMIT ?
                """
                arguments = [
                    lowerQuery, lowerQuery, lowerQuery,  // match_priority
                    lowerQuery, lowerQuery,              // match_priority continued
                    lowerQuery, lowerQuery, lowerQuery, lowerQuery,  // match_priority continued
                    // parenthetical_priority (16 params: 4 for "as a/an" + 12 for parentheses)
                    lowerQuery,                    // line 729: LIKE '%as a ' || ? || '%'
                    lowerQuery,                    // line 730: LIKE '%as an ' || ? || '%'
                    lowerQuery,                    // line 731: LIKE '%by way of a ' || ? || '%'
                    lowerQuery,                    // line 732: LIKE '%by way of an ' || ? || '%'
                    lowerQuery,                    // line 735: LIKE '%(' || ? || ')%'
                    lowerQuery, lowerQuery,        // lines 736-737: LIKE '%(' || ? || ' %' AND LIKE '%(' || ? || '%' || ')%'
                    lowerQuery, lowerQuery,        // lines 738-739: LIKE '%(' || ? || ';%' AND LIKE '%(' || ? || '%' || ')%'
                    lowerQuery, lowerQuery,        // lines 740-741: LIKE '%(' || ? || ',%' AND LIKE '%(' || ? || '%' || ')%'
                    lowerQuery,                    // line 742: LIKE '% ' || ? || ')%'
                    lowerQuery,                    // line 743: LIKE '%;' || ? || ')%'
                    lowerQuery,                    // line 744: LIKE '%,' || ? || ')%'
                    lowerQuery, lowerQuery,        // lines 747-748: LIKE '%(e.g.%' || ? || '%' || ')%' AND NOT LIKE '%(e.g.%' || ')%' || ? || '%'
                ]
                // Add semantic keywords for semantic_boost (dynamic count based on keywords)
                arguments.append(contentsOf: semanticKeywords.map { $0 as DatabaseValueConvertible })
                arguments.append(lowerQuery)  // WHERE clause
                // Add core headwords if provided
                if !coreHeadwordsArray.isEmpty {
                    arguments.append(contentsOf: coreHeadwordsArray.map { $0 as DatabaseValueConvertible })
                }
                arguments.append(isEnglishQuery ? 1 : 0)  // katakana check
                arguments.append(limit * 2)               // LIMIT
            }

            let entries = try DictionaryEntry.fetchAll(db, sql: sql, arguments: StatementArguments(arguments))
            print("üóÑÔ∏è DBService.searchReverse: SQL returned \(entries.count) entries before filtering")
            print("üóÑÔ∏è DBService.searchReverse: Core headwords array: \(coreHeadwordsArray)")
            if !entries.isEmpty {
                print("üóÑÔ∏è DBService.searchReverse: First 10 entries from SQL:")
                for (index, entry) in entries.prefix(10).enumerated() {
                    let isCoreWord = coreHeadwordsArray.contains(entry.headword)
                    print("  \(index + 1). \(entry.headword) \(isCoreWord ? "‚úì CORE" : "")")
                }
            }

            // If no results, return empty
            guard !entries.isEmpty else {
                print("üóÑÔ∏è DBService.searchReverse: No results from SQL, returning []")
                return []
            }

            // Apply core word priority boost in Swift (more reliable than SQL dynamic params)
            var sortedEntries = entries
            if !coreHeadwordsArray.isEmpty {
                // Debug: check exact matching
                print("üîç DEBUG: Checking core word matching...")
                for (index, entry) in entries.prefix(10).enumerated() {
                    let headword = entry.headword
                    let isCore = coreHeadwordsArray.contains(headword)
                    print("  Entry \(index + 1): '\(headword)' (length: \(headword.count)) - Core: \(isCore)")
                    if !isCore {
                        // Check for close matches
                        for coreWord in coreHeadwordsArray {
                            if headword.contains(coreWord) || coreWord.contains(headword) {
                                print("    ‚ö†Ô∏è  Close match with core word: '\(coreWord)' (length: \(coreWord.count))")
                            }
                        }
                    }
                }

                sortedEntries = entries.sorted { entry1, entry2 in
                    let index1 = coreHeadwordsArray.firstIndex(of: entry1.headword)
                    let index2 = coreHeadwordsArray.firstIndex(of: entry2.headword)

                    // Both are core words - sort by array position (earlier in array = higher priority)
                    if let idx1 = index1, let idx2 = index2 {
                        return idx1 < idx2
                    }

                    // Only entry1 is core - it comes first
                    if index1 != nil && index2 == nil {
                        return true
                    }

                    // Only entry2 is core - it comes first
                    if index1 == nil && index2 != nil {
                        return false
                    }

                    // Neither is core - maintain SQL order
                    return false  // Stable sort
                }

                print("üóÑÔ∏è DBService.searchReverse: After core word reordering:")
                for (index, entry) in sortedEntries.prefix(10).enumerated() {
                    let isCoreWord = coreHeadwordsArray.contains(entry.headword)
                    print("  \(index + 1). \(entry.headword) \(isCoreWord ? "‚úì CORE" : "")")
                }
            }

            // Load senses and filter STRICTLY to only relevant ones
            var filteredEntries: [DictionaryEntry] = []

            print("üîç DEBUG: Starting filtering process...")
            for (index, var entry) in sortedEntries.enumerated() {
                print("  Processing entry \(index + 1): \(entry.headword)")
                let allSenses = try WordSense
                    .filter(Column("entry_id") == entry.id)
                    .order(Column("sense_order"))
                    .fetchAll(db)

                // IMPORTANT: Core words bypass definition filtering
                // They are included regardless of whether their definition matches the query
                let isCoreWord = coreHeadwordsArray.contains(entry.headword)
                if isCoreWord {
                    entry.senses = allSenses
                    filteredEntries.append(entry)
                    print("    ‚úì Added to filteredEntries (CORE WORD - bypassed filtering, now has \(filteredEntries.count) entries)")
                    continue
                }

                // STRICT filtering: support both exact word matches and multi-word phrases
                let lowerQuery = query.lowercased()
                let relevantSenses = allSenses.filter { sense in
                    let englishDef = sense.definitionEnglish.lowercased()
                    let chineseSimp = sense.definitionChineseSimplified ?? ""

                    // English: support multi-word phrases or exact word matches
                    var exactEnglishMatch: Bool
                    if lowerQuery.contains(" ") {
                        // Multi-word phrase: check if the phrase appears in the definition with word boundaries
                        // Use regex to ensure we match whole phrases only
                        let pattern = "\\b\(NSRegularExpression.escapedPattern(for: lowerQuery))\\b"
                        exactEnglishMatch = englishDef.range(of: pattern, options: .regularExpression) != nil
                    } else {
                        // Single word: exact word match (with word boundaries)
                        let englishWords = englishDef.components(separatedBy: CharacterSet.alphanumerics.inverted)
                            .filter { !$0.isEmpty }
                        exactEnglishMatch = englishWords.contains { $0 == lowerQuery }
                    }

                    // Strict filtering for verb queries: only keep core meanings
                    if exactEnglishMatch && lowerQuery.hasPrefix("to ") {
                        // Extract the base verb from the query (e.g., "to come" -> "come")
                        let baseVerb = String(lowerQuery.dropFirst(3))
                        let expectedPattern = "to \(baseVerb)"

                        // For verb queries, we want strict matching:
                        // 1. Definition must start with "to [verb]"
                        // 2. After "to [verb]", only allow: semicolon, space+parenthesis, or end of string
                        // 3. Exclude compound phrases like "to come out", "to come to", "to come true", etc.
                        // 4. For multi-meaning verbs (e.g., "to come; to go"), check if headword contains the related kanji

                        var isStrictMatch = false
                        var needsKanjiCheck = false

                        // Check if definition starts with our verb pattern
                        if englishDef.hasPrefix(expectedPattern) {
                            let remainingDef = String(englishDef.dropFirst(expectedPattern.count))

                            // Define basic verbs that represent fundamentally different actions
                            let basicVerbs = [
                                "to go", "to be", "to have", "to do",
                                "to eat", "to drink", "to see", "to hear",
                                "to make", "to take", "to give", "to get",
                                "to know", "to think", "to feel", "to want",
                                "to use", "to find", "to work", "to live"
                            ]

                            // Check if the ENTIRE definition contains other basic verbs
                            // (not just the current query verb)
                            let otherBasicVerbs = basicVerbs.filter { $0 != lowerQuery }
                            let hasOtherBasicVerb = otherBasicVerbs.contains { englishDef.contains("; \($0)") }

                            if hasOtherBasicVerb {
                                // Multi-meaning verb - need kanji check
                                needsKanjiCheck = true
                            } else {
                                // Check what comes after "to [verb]"
                                if remainingDef.isEmpty {
                                    // "to come" - exact match
                                    isStrictMatch = true
                                } else if remainingDef.hasPrefix(";") || remainingDef.hasPrefix(" (") {
                                    // "to come; ..." or "to come (...)" - acceptable
                                    isStrictMatch = true
                                }
                                // Otherwise: "to come out", "to come to", etc. - reject
                            }
                        }

                        if !isStrictMatch || needsKanjiCheck {
                            // Not a strict match OR needs kanji check - verify headword contains related Japanese char
                            // OR is a common honorific/humble form
                            let relatedChars = self.getJapaneseCharsForQuery(baseVerb)
                            let containsRelatedChar = relatedChars.contains { entry.headword.contains($0) }

                            // Check if this is a common honorific/humble form (whitelist)
                            let honorificWhitelist = self.getHonorificWhitelistForQuery(baseVerb)
                            let isHonorific = honorificWhitelist.contains(entry.headword)

                            if !containsRelatedChar && !isHonorific {
                                // Not strict match, no related Japanese char, and not honorific - exclude it
                                exactEnglishMatch = false
                            }
                        }
                    }

                    // Chinese: must be exact word in semicolon-separated list
                    let chineseWords = chineseSimp.components(separatedBy: "; ")
                        .map { $0.trimmingCharacters(in: .whitespaces) }
                        .filter { !$0.isEmpty }
                    let exactChineseMatch = chineseWords.contains { $0 == query }

                    return exactEnglishMatch || exactChineseMatch
                }

                // Only include entry if it has at least one relevant sense
                if !relevantSenses.isEmpty {
                    entry.senses = relevantSenses
                    filteredEntries.append(entry)
                    print("    ‚úì Added to filteredEntries (now has \(filteredEntries.count) entries)")
                } else {
                    print("    ‚úó Excluded (no relevant senses)")
                }
            }

            print("üîç DEBUG: Final filteredEntries order:")
            for (index, entry) in filteredEntries.enumerated() {
                let isCore = coreHeadwordsArray.contains(entry.headword)
                print("  \(index + 1). \(entry.headword) \(isCore ? "‚úì CORE" : "")")
            }

            // Convert rare kanji forms to kana in search results
            // Examples: ÂÖ∂„Çå„Åß ‚Üí „Åù„Çå„Åß, Êº∏„Å® ‚Üí „ÇÑ„Å£„Å®, Áü¢„Å£Âºµ„Çä ‚Üí „ÇÑ„Å£„Å±„Çä
            let usuallyKanaWords = [
                "„Åô„Çã", "„ÇÑ„Å£„Å®", "„Åô„Åê", "„Åæ„Å†", "„ÇÇ„ÅÜ", "„Åö„Å£„Å®",
                "„Åü„Åè„Åï„Çì", "„Å®„Å¶„ÇÇ", "„Å°„Çá„Å£„Å®", "„Å©„ÅÜ„Åû", "„Å°„ÇÉ„Çì„Å®",
                "„Åç„Å£„Å®", "„Åù„Å£„Å®", "„ÅØ„Å£„Åç„Çä", "„Åó„Å£„Åã„Çä", "„ÇÜ„Å£„Åè„Çä",
                "„ÇÑ„Å£„Å±„Çä", "„ÇÑ„ÅØ„Çä", "„Åù„Çå„Åß"
            ]

            let convertedEntries = filteredEntries.map { entry -> DictionaryEntry in
                // Check if this is a rare kanji form that should be displayed as kana
                if usuallyKanaWords.contains(entry.readingHiragana) && entry.headword != entry.readingHiragana {
                    print("üîÑ Converting rare kanji '\(entry.headword)' to kana '\(entry.readingHiragana)'")
                    // Create a new entry with kana headword but same ID (for detail view)
                    return DictionaryEntry(
                        id: entry.id,
                        headword: entry.readingHiragana,  // Use kana form
                        readingHiragana: entry.readingHiragana,
                        readingRomaji: entry.readingRomaji,
                        frequencyRank: entry.frequencyRank,
                        pitchAccent: entry.pitchAccent,
                        jlptLevel: entry.jlptLevel,
                        createdAt: entry.createdAt,
                        senses: entry.senses
                    )
                }
                return entry
            }

            print("üóÑÔ∏è DBService.searchReverse: Returning \(convertedEntries.count) filtered entries")
            return convertedEntries
        }
    }

    /// Maps semantic hints to keyword patterns for boosting search results
    /// Returns SQL LIKE patterns that should be matched against definitions
    /// Example: "ËØ∑ÂÆ¢" (invite to dinner) ‚Üí ["%food and drink%", "%someone to%dinner%", "%treating%meal%"]
    private func getSemanticKeywordsFromHint(_ hint: String, baseQuery: String) -> [String] {
        let lowerHint = hint.lowercased()
        let lowerQuery = baseQuery.lowercased()

        // Map Chinese semantic hints to English definition patterns
        let chineseToPatterns: [String: [String]] = [
            "ËØ∑ÂÆ¢": ["%food and drink%", "%someone to%dinner%", "%someone to%meal%", "%treating%"],
            "Ê¨æÂæÖ": ["%entertainment%", "%hospitality%", "%treating%"],
            "ÂÆ¥ËØ∑": ["%banquet%", "%feast%", "%someone to%dinner%"],
        ]

        // Map query-specific semantic hints
        var patterns: [String] = []

        // Check for Chinese hints first
        for (chineseHint, hintPatterns) in chineseToPatterns {
            if lowerHint.contains(chineseHint) {
                patterns.append(contentsOf: hintPatterns)
            }
        }

        // Extract English keywords from parentheses (e.g., "treat (food)" ‚Üí ["food"])
        // Pattern: (word1, word2, word3)
        if let startParen = hint.firstIndex(of: "("),
           let endParen = hint.firstIndex(of: ")"),
           startParen < endParen {
            let insideParens = String(hint[hint.index(after: startParen)..<endParen])
            let keywords = insideParens.split(separator: ",")
                .map { $0.trimmingCharacters(in: .whitespaces).lowercased() }

            // For each keyword, create patterns
            for keyword in keywords where !keyword.isEmpty {
                // Direct match: "(esp. food)" matches definitions with "food"
                patterns.append("%\(keyword)%")
                // Phrase match: "food" also matches "food and drink"
                patterns.append("%\(keyword) and%")
                patterns.append("%\(keyword) or%")
            }
        }

        // Query-specific boosting patterns
        // These are general semantic categories that should be boosted for certain queries
        let querySpecificPatterns: [String: [String]] = [
            "treat": ["%esp.%food%", "%someone to%", "%treating%"],
            "wear": ["%from the shoulders%", "%lower-body%", "%footwear%"],
            "eat": ["%consume%", "%meal%", "%food%"],
            "drink": ["%beverage%", "%liquid%"],
        ]

        if let queryPatterns = querySpecificPatterns[lowerQuery] {
            patterns.append(contentsOf: queryPatterns)
        }

        return Array(Set(patterns))  // Remove duplicates
    }

    /// Returns core/basic words for a given query that should be prioritized
    /// These are the most fundamental, commonly taught words for each concept
    private func getCoreHeadwordsForQuery(_ query: String) -> [String] {
        let lowerQuery = query.lowercased()

        let coreWordsMap: [String: [String]] = [
            // ULTRA-BASIC N5 verbs only (frequency will handle the rest)
            // Movement
            "come": ["Êù•„Çã"],
            "go": ["Ë°å„Åè"],

            // Basic Actions
            "eat": ["È£ü„Åπ„Çã"],
            "drink": ["È£≤„ÇÄ"],
            "see": ["Ë¶ã„Çã"],
            "hear": ["ËÅû„Åè"],
            "speak": ["Ë©±„Åô"],
            "say": ["Ë®Ä„ÅÜ"],
            "read": ["Ë™≠„ÇÄ"],
            "write": ["Êõ∏„Åè"],
            "do": ["„Åô„Çã"],

            // State
            "wake up": ["ÁõÆË¶ö„ÇÅ„Çã", "ÁõÆ„ÇíË¶ö„Åæ„Åô"],  // Keep this one as it's pedagogically important
            "sleep": ["ÂØù„Çã"],
            "get up": ["Ëµ∑„Åç„Çã"],

            // Existence (fundamental copulas)
            "be": ["„ÅÑ„Çã", "„ÅÇ„Çã"],
        ]

        return coreWordsMap[lowerQuery] ?? []
    }

    /// Returns common honorific/humble forms for a given verb query
    /// These words should be included even if they don't contain the core kanji
    private func getHonorificWhitelistForQuery(_ query: String) -> [String] {
        let lowerQuery = query.lowercased()

        let honorificMap: [String: [String]] = [
            // Verbs - Actions
            "eat": ["È†Ç„Åè", "Âè¨„Åó‰∏ä„Åå„Çã", "Âè¨„Åô"],
            "drink": ["È†Ç„Åè", "Âè¨„Åó‰∏ä„Åå„Çã"],
            "come": ["„ÅÑ„Çâ„Å£„Åó„ÇÉ„Çã", "„ÅäÂá∫„Åß„Å´„Å™„Çã", "„Åä„ÅÑ„Åß„Å´„Å™„Çã", "„ÅäË¶ã„Åà„Å´„Å™„Çã"],
            "go": ["„ÅÑ„Çâ„Å£„Åó„ÇÉ„Çã", "„ÅäÂá∫„Åß„Å´„Å™„Çã", "„Åä„ÅÑ„Åß„Å´„Å™„Çã"],
            "be": ["„ÅÑ„Çâ„Å£„Åó„ÇÉ„Çã", "„Åä„Çâ„Çå„Çã"],
            "say": ["‰ª∞„Çã", "„Åä„Å£„Åó„ÇÉ„Çã"],
            "do": ["„Å™„Åï„Çã"],
            "see": ["„ÅîË¶ß„Å´„Å™„Çã"],
            "know": ["„ÅîÂ≠ò„Åò"],
            "give": ["‰∏ã„Åï„Çã", "„Åè„Å†„Åï„Çã"],
            "sleep": ["„Åä‰ºë„Åø„Å´„Å™„Çã"],
        ]

        return honorificMap[lowerQuery] ?? []
    }

    /// Maps English query words to their common Japanese characters
    /// Used for whitelisting compound expressions that contain the core Japanese character
    private func getJapaneseCharsForQuery(_ query: String) -> [String] {
        let lowerQuery = query.lowercased()

        // Map common N5 verbs and nouns to their Japanese characters
        let queryToJapaneseMap: [String: [String]] = [
            // Verbs - Movement
            "come": ["Êù•"],
            "go": ["Ë°å", "ÂæÄ"],
            "go out": ["Âá∫", "Ê∂à"],  // Phrasal verb: go out (depart Âá∫„Åã„Åë„Çã / extinguish Ê∂à„Åà„Çã)
            "return": ["Êàª", "Â∏∞", "Ëøî"],
            "enter": ["ÂÖ•"],
            "exit": ["Âá∫"],
            "leave": ["Âá∫", "Âéª"],
            "arrive": ["ÁùÄ", "Âà∞"],

            // Verbs - Actions
            "eat": ["È£ü"],
            "drink": ["È£≤"],
            "see": ["Ë¶ã"],
            "watch": ["Ë¶ã"],
            "look": ["Ë¶ã"],
            "hear": ["ËÅû"],
            "listen": ["ËÅû"],
            "speak": ["Ë©±", "Ë®Ä"],
            "say": ["Ë®Ä"],
            "talk": ["Ë©±"],
            "read": ["Ë™≠"],
            "write": ["Êõ∏"],
            "buy": ["Ë≤∑"],
            "sell": ["Â£≤"],
            "make": ["‰Ωú", "ÈÄ†"],
            "do": ["ÁÇ∫", "Ë°å"],
            "give": ["‰∏é", "Âëâ"],
            "receive": ["Âèó", "Ë≤∞"],
            "take": ["Âèñ"],
            "put": ["ÁΩÆ"],
            "wear": ["ÁùÄ", "Â±•", "Ë¢´", "Êéõ", "Á∑†"],
            "open": ["Èñã"],
            "close": ["Èñâ"],
            "begin": ["Âßã"],
            "end": ["ÁµÇ"],
            "stop": ["Ê≠¢"],
            "wait": ["ÂæÖ"],
            "meet": ["‰ºö", "ÈÅ≠"],
            "understand": ["Ëß£", "ÂàÜ"],
            "know": ["Áü•"],
            "think": ["ÊÄù", "ËÄÉ"],
            "forget": ["Âøò"],
            "remember": ["Ë¶ö"],

            // Verbs - State
            "be": ["Âú®", "Â±Ö", "Êúâ"],
            "exist": ["Âú®", "Êúâ"],
            "live": ["‰Ωè", "Áîü", "Ê¥ª"],
            "die": ["Ê≠ª"],
            "sleep": ["ÂØù", "Áú†"],
            "wake": ["Ëµ∑", "Ë¶ö"],

            // Nouns - Time
            "day": ["Êó•"],
            "time": ["ÊôÇ"],
            "year": ["Âπ¥"],
            "month": ["Êúà"],
            "week": ["ÈÄ±"],

            // Nouns - People
            "person": ["‰∫∫"],
            "student": ["Áîü"],
            "teacher": ["Â∏´"],

            // Nouns - Places
            "house": ["ÂÆ∂"],
            "school": ["Ê†°"],
            "station": ["ÈßÖ"],

            // Adjectives
            "big": ["Â§ß"],
            "small": ["Â∞è"],
            "new": ["Êñ∞"],
            "old": ["Âè§"],
            "good": ["ËâØ"],
            "bad": ["ÊÇ™"],
        ]

        return queryToJapaneseMap[lowerQuery] ?? []
    }

    public func fetchEntry(id: Int) async throws -> DictionaryEntry? {
        try await dbQueue.read { db in
            // Fetch entry
            guard var entry = try DictionaryEntry.fetchOne(db, id: id) else {
                return nil
            }

            // Fetch senses
            let senses = try WordSense
                .filter(WordSense.Columns.entryId == id)
                .order(WordSense.Columns.senseOrder)
                .fetchAll(db)

            // For each sense, fetch examples using raw SQL
            var sensesWithExamples: [WordSense] = []
            for var sense in senses {
                let sql = """
                SELECT * FROM example_sentences
                WHERE sense_id = ?
                ORDER BY example_order
                """
                let examples = try ExampleSentence.fetchAll(db, sql: sql, arguments: [sense.id])
                sense.examples = examples
                sensesWithExamples.append(sense)
            }

            entry.senses = sensesWithExamples

            // Special handling: If this is a rare kanji entry (usually written in kana),
            // return a virtual entry with pure kana headword
            // This ensures consistency with search results that show virtual entries
            if entry.isRareKanji {
                print("üîç DBService.fetchEntry: Entry '\(entry.headword)' is rare kanji, returning virtual kana entry '\(entry.readingHiragana)'")
                return DictionaryEntry(
                    id: entry.id,
                    headword: entry.readingHiragana,  // Use pure kana
                    readingHiragana: entry.readingHiragana,
                    readingRomaji: entry.readingRomaji,
                    frequencyRank: entry.frequencyRank,
                    pitchAccent: entry.pitchAccent,
                    jlptLevel: entry.jlptLevel,
                    createdAt: entry.createdAt,
                    senses: entry.senses
                )
            }

            return entry
        }
    }
    
    public func validateDatabaseIntegrity() async throws -> Bool {
        try await dbQueue.read { db in
            // Verify required tables exist
            let requiredTables = ["dictionary_entries", "dictionary_fts", "word_senses", "example_sentences"]
            for table in requiredTables {
                let exists = try Bool.fetchOne(db, sql: """
                    SELECT COUNT(*) > 0 FROM sqlite_master
                    WHERE type='table' AND name=?
                    """, arguments: [table])

                guard exists == true else {
                    throw DatabaseError.schemaMismatch("Missing table: \(table)")
                }
            }

            return true
        }
    }

    // MARK: - Helper Functions

    /// Merge entries with the same headword into a single entry with multiple senses
    /// Example: „Åì„ÅÆÈ†É(„Åì„ÅÆ„Åî„Çç) + „Åì„ÅÆÈ†É(„Åì„ÅÆ„Åì„Çç) ‚Üí merge into one entry with numbered senses
    /// Note: We merge by headword only, not reading, to handle pronunciation variants („Åî„Çç/„Åì„Çç)
    private func mergeEntriesByHeadwordReading(_ entries: [DictionaryEntry]) -> [DictionaryEntry] {
        // Group entries by headword only (ignore reading differences like „Åî„Çç vs „Åì„Çç)
        var groups: [String: [DictionaryEntry]] = [:]
        for entry in entries {
            let key = entry.headword
            groups[key, default: []].append(entry)
        }

        // Process each group
        var mergedEntries: [DictionaryEntry] = []
        var processedKeys: Set<String> = []

        for entry in entries {
            let key = entry.headword

            // Skip if we've already processed this group
            guard !processedKeys.contains(key) else {
                continue
            }
            processedKeys.insert(key)

            guard let group = groups[key] else {
                continue
            }

            // If only one entry in group, no merging needed
            if group.count == 1 {
                mergedEntries.append(entry)
                continue
            }

            print("üîó DBService: Merging \(group.count) entries for '\(entry.headword)' (\(entry.readingHiragana))")

            // Pick the "best" entry as the base (prefer JLPT level, then frequency rank)
            let bestEntry = group.sorted { e1, e2 in
                // Prefer entry with JLPT level
                if e1.jlptLevel != nil && e2.jlptLevel == nil {
                    return true
                }
                if e1.jlptLevel == nil && e2.jlptLevel != nil {
                    return false
                }

                // If both have JLPT levels, prefer higher level (N5 > N4 > N3 > N2 > N1)
                if let jlpt1 = e1.jlptLevel, let jlpt2 = e2.jlptLevel {
                    let priority1 = jlptPriority(jlpt1)
                    let priority2 = jlptPriority(jlpt2)
                    if priority1 != priority2 {
                        return priority1 < priority2
                    }
                }

                // Prefer entry with better frequency rank (lower is better)
                if let freq1 = e1.frequencyRank, let freq2 = e2.frequencyRank {
                    return freq1 < freq2
                }
                if e1.frequencyRank != nil && e2.frequencyRank == nil {
                    return true
                }
                if e1.frequencyRank == nil && e2.frequencyRank != nil {
                    return false
                }

                // Default: keep original order
                return false
            }.first!

            // Collect all unique readings (for variants like „Åî„Çç/„Åì„Çç)
            let allReadingsHiragana = Set(group.map { $0.readingHiragana })
            let allReadingsRomaji = Set(group.map { $0.readingRomaji })

            // Combine readings with ¬∑ separator (e.g., "„Åì„ÅÆ„Åî„Çç¬∑„Åì„ÅÆ„Åì„Çç")
            let combinedReadingHiragana = allReadingsHiragana.sorted().joined(separator: "¬∑")
            let combinedReadingRomaji = allReadingsRomaji.sorted().joined(separator: "¬∑")

            // Collect all senses from all entries in the group
            var allSenses: [WordSense] = []
            for groupEntry in group {
                allSenses.append(contentsOf: groupEntry.senses)
            }

            // Renumber senses sequentially (1, 2, 3, ...)
            var renumberedSenses: [WordSense] = []
            for (index, sense) in allSenses.enumerated() {
                let newSense = WordSense(
                    id: sense.id,
                    entryId: sense.entryId,
                    definitionEnglish: sense.definitionEnglish,
                    definitionChineseSimplified: sense.definitionChineseSimplified,
                    definitionChineseTraditional: sense.definitionChineseTraditional,
                    partOfSpeech: sense.partOfSpeech,
                    usageNotes: sense.usageNotes,
                    senseOrder: index + 1,  // Renumber starting from 1
                    examples: sense.examples
                )
                renumberedSenses.append(newSense)
            }

            // Create merged entry with combined readings
            let mergedEntry = DictionaryEntry(
                id: bestEntry.id,
                headword: bestEntry.headword,
                readingHiragana: combinedReadingHiragana,  // Combined readings
                readingRomaji: combinedReadingRomaji,      // Combined romaji
                frequencyRank: bestEntry.frequencyRank,
                pitchAccent: bestEntry.pitchAccent,
                jlptLevel: bestEntry.jlptLevel,
                createdAt: bestEntry.createdAt,
                senses: renumberedSenses
            )

            mergedEntries.append(mergedEntry)
            print("üîó DBService: Merged '\(mergedEntry.headword)' ‚Üí \(renumberedSenses.count) senses")
        }

        return mergedEntries
    }

    /// Get JLPT priority for sorting (lower is better: N5=0, N4=1, N3=2, N2=3, N1=4)
    private func jlptPriority(_ level: String) -> Int {
        switch level {
        case "N5": return 0
        case "N4": return 1
        case "N3": return 2
        case "N2": return 3
        case "N1": return 4
        default: return 5
        }
    }
}
