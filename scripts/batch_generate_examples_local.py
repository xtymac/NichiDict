#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡ç”Ÿæˆä¾‹å¥è„šæœ¬ - æœ¬åœ°AIæ¨¡å‹ç‰ˆæœ¬ï¼ˆOllamaï¼‰

ç‰¹ç‚¹ï¼š
  âœ… å®Œå…¨å…è´¹ï¼ˆä½¿ç”¨æœ¬åœ°Ollamaæ¨¡å‹ï¼‰
  âœ… æ— APIæˆæœ¬
  âœ… é€Ÿåº¦å¿«ï¼ˆæ— ç½‘ç»œå»¶è¿Ÿï¼‰
  âœ… éšç§ä¿æŠ¤ï¼ˆæ•°æ®ä¸ç¦»å¼€æœ¬åœ°ï¼‰

ä½¿ç”¨æ–¹æ³•ï¼š
  # 1. å®‰è£…Ollamaå’Œæ¨¡å‹
  ./setup_local_ai.sh

  # 2. è¿è¡Œæ‰¹é‡ç”Ÿæˆ
  python3 batch_generate_examples_local.py --db dict.sqlite --model qwen2.5:7b
"""

import sqlite3
import json
import time
import argparse
import sys
import os
from datetime import datetime, date
from typing import List, Dict, Optional
import requests

# è¿›åº¦è·Ÿè¸ªæ–‡ä»¶
PROGRESS_FILE = ".batch_generate_progress_local.json"
STATE_FILE = ".batch_generate_state_local.json"

# Ollamaé»˜è®¤ç«¯ç‚¹
OLLAMA_ENDPOINT = "http://localhost:11434/api/generate"


class LocalBatchExampleGenerator:
    """æœ¬åœ°æ‰¹é‡ä¾‹å¥ç”Ÿæˆå™¨ï¼ˆä½¿ç”¨Ollamaï¼‰"""

    def __init__(self,
                 db_path: str,
                 model: str = "qwen2.5:7b",
                 max_rank: int = 5000,
                 batch_size: int = 10,
                 max_examples: int = 3,
                 daily_limit: int = 1000,  # æœ¬åœ°æ¨¡å‹é™åˆ¶æ›´å®½æ¾
                 dry_run: bool = False,
                 ollama_endpoint: str = OLLAMA_ENDPOINT):

        self.db_path = db_path
        self.model = model
        self.max_rank = max_rank
        self.batch_size = batch_size
        self.max_examples = max_examples
        self.daily_limit = daily_limit
        self.dry_run = dry_run
        self.ollama_endpoint = ollama_endpoint

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_entries': 0,
            'processed': 0,
            'skipped': 0,
            'failed': 0,
            'examples_generated': 0,
            'api_calls': 0,
            'start_time': datetime.now().isoformat()
        }

        # åŠ è½½çŠ¶æ€
        self.state = self._load_state()

    def _load_state(self) -> Dict:
        """åŠ è½½ä¸Šæ¬¡è¿è¡ŒçŠ¶æ€"""
        if os.path.exists(STATE_FILE):
            with open(STATE_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {
            'date': str(date.today()),
            'api_calls_today': 0,
            'last_processed_id': 0
        }

    def _save_state(self):
        """ä¿å­˜å½“å‰çŠ¶æ€"""
        with open(STATE_FILE, 'w', encoding='utf-8') as f:
            json.dump(self.state, f, indent=2, ensure_ascii=False)

    def _check_daily_quota(self) -> bool:
        """æ£€æŸ¥ä»Šæ—¥é…é¢ï¼ˆæœ¬åœ°æ¨¡å‹é™åˆ¶æ›´å®½æ¾ï¼‰"""
        today = str(date.today())
        if self.state['date'] != today:
            self.state['date'] = today
            self.state['api_calls_today'] = 0
            self._save_state()

        if self.state['api_calls_today'] >= self.daily_limit:
            print(f"âŒ ä»Šæ—¥è°ƒç”¨å·²è¾¾ä¸Šé™ ({self.daily_limit})")
            return False

        remaining = self.daily_limit - self.state['api_calls_today']
        print(f"âœ… ä»Šæ—¥å‰©ä½™é…é¢: {remaining}/{self.daily_limit}")
        return True

    def _get_entries_without_examples(self) -> List[Dict]:
        """è·å–éœ€è¦ç”Ÿæˆä¾‹å¥çš„è¯æ¡"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()

        query = """
        SELECT
            e.id,
            e.headword,
            e.reading_hiragana,
            e.reading_romaji,
            e.frequency_rank
        FROM dictionary_entries e
        WHERE e.frequency_rank <= ?
          AND e.id > ?
          AND NOT EXISTS (
              SELECT 1
              FROM word_senses ws
              JOIN example_sentences ex ON ws.id = ex.sense_id
              WHERE ws.entry_id = e.id
          )
        ORDER BY e.frequency_rank ASC, e.id ASC
        LIMIT ?
        """

        cursor.execute(query, (self.max_rank, self.state['last_processed_id'], self.batch_size))
        entries = [dict(row) for row in cursor.fetchall()]

        conn.close()
        return entries

    def _get_senses_for_entry(self, entry_id: int) -> List[Dict]:
        """è·å–è¯æ¡çš„æ‰€æœ‰ä¹‰é¡¹"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()

        query = """
        SELECT
            id,
            definition_english,
            definition_chinese_simplified,
            definition_chinese_traditional,
            part_of_speech
        FROM word_senses
        WHERE entry_id = ?
        ORDER BY sense_order ASC
        """

        cursor.execute(query, (entry_id,))
        senses = [dict(row) for row in cursor.fetchall()]

        conn.close()
        return senses

    def _build_prompt(self, entry: Dict, senses: List[Dict]) -> str:
        """æ„å»ºç”Ÿæˆä¾‹å¥çš„Prompt"""
        definitions = []
        for idx, sense in enumerate(senses[:5], 1):
            chinese = sense['definition_chinese_simplified'] or sense['definition_chinese_traditional'] or ""
            definitions.append(f"{idx}. {sense['definition_english']} | JP: {sense['part_of_speech']} | CN: {chinese}")

        definitions_text = "\n".join(definitions)

        return f"""You are an expert Japanese language tutor. Generate natural example sentences for a dictionary entry.

Entry:
- Headword: {entry['headword']}
- Reading: {entry['reading_hiragana']}
- Romaji: {entry['reading_romaji']}
- Core meanings:
{definitions_text}

Requirements:
1. Produce up to {self.max_examples} concise Japanese sentences (<= 25 characters) that demonstrate the typical usage of the word. Each sentence MUST include the headword or its conjugated/inflected form once.
2. Provide context that matches the meanings listed above. Avoid uncommon idioms or archaic grammar.
3. Return JSON ONLY with schema:
   {{"examples":[{{"japanese":"...", "chinese":"...", "english":"..."}}]}}
4. Use Simplified Chinese for the chinese field. Keep english field in natural English.
5. Avoid romaji, avoid placeholders, avoid line breaks inside fields.

Respond with JSON only. No explanations."""

    def _call_ollama_api(self, prompt: str) -> Optional[List[Dict]]:
        """è°ƒç”¨Ollamaæœ¬åœ°APIç”Ÿæˆä¾‹å¥"""
        try:
            response = requests.post(
                self.ollama_endpoint,
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "stream": False,
                    "format": "json"
                },
                timeout=60
            )

            if response.status_code != 200:
                print(f"âŒ Ollama APIé”™è¯¯: {response.status_code}")
                return None

            result = response.json()
            content = result.get('response', '')

            # è§£æJSONå“åº”
            data = json.loads(content)

            # æ›´æ–°è°ƒç”¨è®¡æ•°
            self.state['api_calls_today'] += 1
            self.stats['api_calls'] += 1
            self._save_state()

            return data.get('examples', [])

        except requests.exceptions.ConnectionError:
            print(f"âŒ æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡")
            print(f"   è¯·ç¡®ä¿Ollamaæ­£åœ¨è¿è¡Œ: ollama serve")
            return None
        except json.JSONDecodeError as e:
            print(f"âŒ JSONè§£æå¤±è´¥: {e}")
            return None
        except Exception as e:
            print(f"âŒ è°ƒç”¨å¤±è´¥: {e}")
            return None

    def _insert_examples(self, entry_id: int, senses: List[Dict], examples: List[Dict]):
        """å°†ç”Ÿæˆçš„ä¾‹å¥æ’å…¥æ•°æ®åº“"""
        if self.dry_run:
            print(f"  [DRY-RUN] å°†æ’å…¥ {len(examples)} ä¸ªä¾‹å¥")
            return

        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        try:
            if len(senses) == 1:
                sense_ids = [senses[0]['id']] * len(examples)
            else:
                sense_ids = [senses[i % len(senses)]['id'] for i in range(len(examples))]

            for order, (example, sense_id) in enumerate(zip(examples, sense_ids)):
                cursor.execute("""
                    INSERT INTO example_sentences
                    (sense_id, japanese_text, english_translation, example_order)
                    VALUES (?, ?, ?, ?)
                """, (
                    sense_id,
                    example['japanese'],
                    example['english'],
                    order
                ))

            conn.commit()
            self.stats['examples_generated'] += len(examples)
            print(f"  âœ… æˆåŠŸæ’å…¥ {len(examples)} ä¸ªä¾‹å¥")

        except Exception as e:
            conn.rollback()
            print(f"  âŒ æ•°æ®åº“æ’å…¥å¤±è´¥: {e}")
            raise
        finally:
            conn.close()

    def process_entry(self, entry: Dict) -> bool:
        """å¤„ç†å•ä¸ªè¯æ¡"""
        entry_id = entry['id']
        headword = entry['headword']
        rank = entry['frequency_rank']

        print(f"\nğŸ“– å¤„ç†ä¸­: {headword} (ID={entry_id}, Rank={rank})")

        # è·å–ä¹‰é¡¹
        senses = self._get_senses_for_entry(entry_id)
        if not senses:
            print(f"  âš ï¸  è·³è¿‡: æ— ä¹‰é¡¹")
            self.stats['skipped'] += 1
            return False

        print(f"  ğŸ“ ä¹‰é¡¹æ•°: {len(senses)}")

        # æ„å»ºPrompt
        prompt = self._build_prompt(entry, senses)

        # è°ƒç”¨æœ¬åœ°APIç”Ÿæˆä¾‹å¥
        examples = self._call_ollama_api(prompt)

        if not examples:
            print(f"  âŒ ç”Ÿæˆå¤±è´¥")
            self.stats['failed'] += 1
            return False

        print(f"  ğŸ¯ ç”Ÿæˆäº† {len(examples)} ä¸ªä¾‹å¥:")
        for ex in examples:
            print(f"     â€¢ {ex['japanese']}")

        # æ’å…¥æ•°æ®åº“
        try:
            self._insert_examples(entry_id, senses, examples)
            self.stats['processed'] += 1

            # æ›´æ–°çŠ¶æ€
            self.state['last_processed_id'] = entry_id
            self._save_state()

            return True

        except Exception as e:
            print(f"  âŒ æ’å…¥å¤±è´¥: {e}")
            self.stats['failed'] += 1
            return False

    def run(self):
        """è¿è¡Œæ‰¹é‡ç”Ÿæˆ"""
        print("=" * 60)
        print("ğŸš€ æ‰¹é‡ä¾‹å¥ç”Ÿæˆå™¨å¯åŠ¨ï¼ˆæœ¬åœ°AIæ¨¡å‹ï¼‰")
        print("=" * 60)
        print(f"æ•°æ®åº“: {self.db_path}")
        print(f"æ¨¡å‹: {self.model} (æœ¬åœ°Ollama)")
        print(f"æœ€å¤§é¢‘ç‡æ’å: {self.max_rank}")
        print(f"æ‰¹æ¬¡å¤§å°: {self.batch_size}")
        print(f"æ¯è¯ä¾‹å¥æ•°: {self.max_examples}")
        print(f"æ¯æ—¥é™é¢: {self.daily_limit}")
        print(f"æµ‹è¯•æ¨¡å¼: {'æ˜¯' if self.dry_run else 'å¦'}")
        print("=" * 60)

        # æ£€æŸ¥OllamaæœåŠ¡
        try:
            test_response = requests.get("http://localhost:11434/api/tags", timeout=2)
            if test_response.status_code == 200:
                print("âœ… OllamaæœåŠ¡è¿è¡Œæ­£å¸¸")
            else:
                print("âš ï¸  OllamaæœåŠ¡çŠ¶æ€å¼‚å¸¸")
        except:
            print("âŒ æ— æ³•è¿æ¥åˆ°OllamaæœåŠ¡")
            print("   è¯·è¿è¡Œ: ollama serve")
            return

        # æ£€æŸ¥é…é¢
        if not self._check_daily_quota():
            print("\nâ¸ï¸  å·²è¾¾ä»Šæ—¥é™é¢ï¼Œæ˜å¤©å†æ¥ï¼")
            return

        # è·å–å¾…å¤„ç†è¯æ¡
        print("\nğŸ” æŸ¥è¯¢éœ€è¦ç”Ÿæˆä¾‹å¥çš„è¯æ¡...")
        entries = self._get_entries_without_examples()

        if not entries:
            print("âœ… æ‰€æœ‰è¯æ¡éƒ½å·²æœ‰ä¾‹å¥ï¼")
            return

        self.stats['total_entries'] = len(entries)
        print(f"ğŸ“Š æ‰¾åˆ° {len(entries)} ä¸ªè¯æ¡éœ€è¦ç”Ÿæˆä¾‹å¥\n")

        # å¤„ç†æ¯ä¸ªè¯æ¡
        for idx, entry in enumerate(entries, 1):
            if self.state['api_calls_today'] >= self.daily_limit:
                print(f"\nâ¸ï¸  å·²è¾¾ä»Šæ—¥é™é¢ ({self.daily_limit})ï¼Œåœæ­¢å¤„ç†")
                break

            print(f"\n[{idx}/{len(entries)}]", end=" ")
            self.process_entry(entry)

            # æœ¬åœ°æ¨¡å‹æ— éœ€å¤ªé•¿é—´éš”
            if not self.dry_run and idx < len(entries):
                time.sleep(0.5)

        # æ‰“å°ç»Ÿè®¡
        self._print_stats()

    def _print_stats(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "=" * 60)
        print("ğŸ“Š æ‰¹é‡ç”Ÿæˆç»Ÿè®¡")
        print("=" * 60)
        print(f"æ€»è¯æ¡æ•°: {self.stats['total_entries']}")
        print(f"æˆåŠŸå¤„ç†: {self.stats['processed']} âœ…")
        print(f"è·³è¿‡: {self.stats['skipped']} âš ï¸")
        print(f"å¤±è´¥: {self.stats['failed']} âŒ")
        print(f"ç”Ÿæˆä¾‹å¥æ•°: {self.stats['examples_generated']}")
        print(f"APIè°ƒç”¨æ¬¡æ•°: {self.stats['api_calls']}")
        print(f"ä»Šæ—¥å·²ç”¨é…é¢: {self.state['api_calls_today']}/{self.daily_limit}")
        print(f"ä¸Šæ¬¡å¤„ç†ID: {self.state['last_processed_id']}")
        print(f"ğŸ’° æ€»æˆæœ¬: $0 (æœ¬åœ°æ¨¡å‹ï¼Œå®Œå…¨å…è´¹ï¼)")
        print("=" * 60)

        # ä¿å­˜ç»Ÿè®¡
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = f"batch_generate_log_local_{timestamp}.json"
        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump({
                'stats': self.stats,
                'state': self.state,
                'config': {
                    'db_path': self.db_path,
                    'model': self.model,
                    'max_rank': self.max_rank,
                    'batch_size': self.batch_size,
                    'max_examples': self.max_examples,
                    'using_local_model': True
                }
            }, f, indent=2, ensure_ascii=False)

        print(f"\nğŸ“„ è¯¦ç»†æ—¥å¿—å·²ä¿å­˜: {log_file}")


def main():
    parser = argparse.ArgumentParser(
        description='æ‰¹é‡ç”Ÿæˆè¯å…¸ä¾‹å¥ï¼ˆä½¿ç”¨æœ¬åœ°Ollamaæ¨¡å‹ï¼‰',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # åŸºç¡€ç”¨æ³•
  python3 batch_generate_examples_local.py --db dict.sqlite

  # æŒ‡å®šæ¨¡å‹
  python3 batch_generate_examples_local.py --db dict.sqlite --model qwen2.5:14b

  # æµ‹è¯•æ¨¡å¼
  python3 batch_generate_examples_local.py --db dict.sqlite --dry-run
"""
    )

    parser.add_argument('--db', required=True, help='SQLiteæ•°æ®åº“è·¯å¾„')
    parser.add_argument('--model', default='qwen2.5:7b', help='Ollamaæ¨¡å‹ï¼ˆé»˜è®¤: qwen2.5:7bï¼‰')
    parser.add_argument('--max-rank', type=int, default=5000, help='æœ€å¤§é¢‘ç‡æ’åï¼ˆé»˜è®¤: 5000ï¼‰')
    parser.add_argument('--batch-size', type=int, default=10, help='æ¯æ‰¹å¤„ç†æ•°é‡ï¼ˆé»˜è®¤: 10ï¼‰')
    parser.add_argument('--max-examples', type=int, default=3, help='æ¯è¯ç”Ÿæˆä¾‹å¥æ•°ï¼ˆé»˜è®¤: 3ï¼‰')
    parser.add_argument('--daily-limit', type=int, default=1000, help='æ¯æ—¥è°ƒç”¨é™åˆ¶ï¼ˆé»˜è®¤: 1000ï¼‰')
    parser.add_argument('--dry-run', action='store_true', help='æµ‹è¯•æ¨¡å¼ï¼Œä¸å®é™…æ‰§è¡Œ')
    parser.add_argument('--ollama-endpoint', default=OLLAMA_ENDPOINT, help='Ollama APIç«¯ç‚¹')

    args = parser.parse_args()

    # æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶
    if not os.path.exists(args.db):
        print(f"âŒ é”™è¯¯: æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {args.db}")
        sys.exit(1)

    # åˆ›å»ºç”Ÿæˆå™¨å¹¶è¿è¡Œ
    generator = LocalBatchExampleGenerator(
        db_path=args.db,
        model=args.model,
        max_rank=args.max_rank,
        batch_size=args.batch_size,
        max_examples=args.max_examples,
        daily_limit=args.daily_limit,
        dry_run=args.dry_run,
        ollama_endpoint=args.ollama_endpoint
    )

    try:
        generator.run()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­ï¼Œä¿å­˜è¿›åº¦...")
        generator._print_stats()
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
