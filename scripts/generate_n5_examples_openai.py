#!/usr/bin/env python3
"""
N5ä¾‹å¥ç”Ÿæˆè„šæœ¬ï¼ˆOpenAI GPT-4o-miniï¼‰
æ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼Œä»ä¸Šæ¬¡è¿›åº¦ç»§ç»­
"""

import sqlite3
import json
import os
import sys
import time
from datetime import datetime
from typing import Dict, List, Tuple
from openai import OpenAI

# ==================== é…ç½® ====================

DB_PATH = "../NichiDict/Resources/seed.sqlite"
PROGRESS_FILE = ".n5_progress.json"

# OpenAI APIé…ç½®
API_KEY = os.environ.get('OPENAI_API_KEY')
if not API_KEY:
    print("âŒ é”™è¯¯: è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
    sys.exit(1)
MODEL_NAME = "gpt-4o-mini"
BATCH_SIZE = 5  # æ¯æ‰¹å¤„ç†5ä¸ªsense
EXAMPLES_PER_SENSE = 2  # æ¯ä¸ªsenseç”Ÿæˆ2æ¡ä¾‹å¥

# ==================== è¿›åº¦ç®¡ç† ====================

def load_progress() -> Dict:
    """åŠ è½½è¿›åº¦"""
    if os.path.exists(PROGRESS_FILE):
        with open(PROGRESS_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {
        "completed_sense_ids": [],
        "total_senses": 0,
        "total_examples_generated": 0,
        "started_at": None
    }

def save_progress(progress: Dict):
    """ä¿å­˜è¿›åº¦"""
    with open(PROGRESS_FILE, 'w', encoding='utf-8') as f:
        json.dump(progress, f, indent=2, ensure_ascii=False)

# ==================== æ•°æ®åº“æ“ä½œ ====================

def get_n5_senses_without_examples(completed_ids: List[int]) -> List[Tuple]:
    """è·å–N5çº§åˆ«ä¸­æ²¡æœ‰ä¾‹å¥çš„sense"""
    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    completed_ids_str = ','.join(map(str, completed_ids)) if completed_ids else '0'

    cursor.execute(f"""
        SELECT
            s.id as sense_id,
            d.headword,
            d.reading_hiragana,
            d.reading_romaji,
            s.definition_english,
            COALESCE(s.definition_chinese_simplified, '') as definition_chinese
        FROM word_senses s
        JOIN dictionary_entries d ON s.entry_id = d.id
        WHERE d.jlpt_level = 'N5'
          AND s.id NOT IN (SELECT DISTINCT sense_id FROM example_sentences WHERE sense_id IS NOT NULL)
          AND s.id NOT IN ({completed_ids_str})
        ORDER BY d.frequency_rank DESC NULLS LAST, d.id
    """)

    senses = cursor.fetchall()
    conn.close()
    return senses

def insert_examples(sense_id: int, examples: List[Dict]) -> int:
    """æ’å…¥ä¾‹å¥åˆ°æ•°æ®åº“"""
    if not examples:
        return 0

    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()
    inserted = 0

    try:
        for idx, example in enumerate(examples, 1):
            japanese = example.get("japanese", "")
            chinese = example.get("chinese", "")
            english = example.get("english", "")

            if not japanese or not english:
                continue

            cursor.execute("""
                INSERT INTO example_sentences
                (sense_id, japanese_text, english_translation, chinese_translation, example_order)
                VALUES (?, ?, ?, ?, ?)
            """, (sense_id, japanese, english, chinese if chinese else None, idx))
            inserted += 1

        conn.commit()
    except Exception as e:
        conn.rollback()
        print(f"    âŒ æ•°æ®åº“æ’å…¥å¤±è´¥: {e}")
    finally:
        conn.close()

    return inserted

# ==================== OpenAI ç”Ÿæˆ ====================

def init_openai():
    """åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯"""
    return OpenAI(api_key=API_KEY)

def generate_examples_for_batch(client, batch: List[Tuple]) -> Dict[int, List[Dict]]:
    """ä¸ºä¸€æ‰¹senseç”Ÿæˆä¾‹å¥"""
    results = {}

    for sense in batch:
        sense_id, headword, reading, romaji, def_en, def_cn = sense

        # æ„å»ºæç¤ºè¯ï¼ˆN5çº§åˆ«ï¼‰
        prompt = f"""ä¸ºæ—¥è¯­åˆå­¦è€…ï¼ˆJLPT N5çº§åˆ«ï¼‰ç”Ÿæˆ{EXAMPLES_PER_SENSE}ä¸ªç®€å•çš„ä¾‹å¥ã€‚

è¯æ±‡ä¿¡æ¯ï¼š
- å•è¯ï¼š{headword}
- è¯»éŸ³ï¼š{reading} ({romaji})
- è‹±æ–‡ï¼š{def_en}
{f'- ä¸­æ–‡ï¼š{def_cn}' if def_cn else ''}

è¦æ±‚ï¼š
1. ç”Ÿæˆ{EXAMPLES_PER_SENSE}ä¸ªéå¸¸ç®€å•çš„æ—¥è¯­å¥å­ï¼ˆ15-25ä¸ªå­—ç¬¦ï¼‰
2. å¿…é¡»ä½¿ç”¨N5çº§åˆ«çš„è¯­æ³•ï¼ˆç°åœ¨æ—¶ã€è¿‡å»æ—¶ã€ã§ã™/ã¾ã™ä½“ï¼‰
3. é¿å…å¤æ‚çš„è¯­æ³•ç»“æ„ï¼ˆä¸è¦ç”¨ã¦ã„ã‚‹ã€ã‚ˆã†ã«ã€ãŸã‚ã«ç­‰ï¼‰
4. ä½¿ç”¨æ—¥å¸¸ç”Ÿæ´»åœºæ™¯
5. å¿…é¡»åŒ…å«è¿™ä¸ªè¯æ±‡ï¼š{headword}

è¿”å›JSONæ ¼å¼ï¼š
{{"examples":[
  {{"japanese":"ç®€å•å¥å­1", "chinese":"ä¸­æ–‡ç¿»è¯‘1", "english":"è‹±æ–‡ç¿»è¯‘1"}},
  {{"japanese":"ç®€å•å¥å­2", "chinese":"ä¸­æ–‡ç¿»è¯‘2", "english":"è‹±æ–‡ç¿»è¯‘2"}}
]}}

åªè¿”å›JSONï¼Œä¸è¦å…¶ä»–å†…å®¹ã€‚"""

        try:
            response = client.chat.completions.create(
                model=MODEL_NAME,
                messages=[
                    {"role": "system", "content": "You are a Japanese language expert specializing in beginner-level (N5) content."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=400
            )

            response_text = response.choices[0].message.content.strip()

            # æ¸…ç†JSONï¼ˆç§»é™¤markdownä»£ç å—æ ‡è®°ï¼‰
            if response_text.startswith('```'):
                lines = response_text.split('\n')
                response_text = '\n'.join(lines[1:-1]) if len(lines) > 2 else response_text

            data = json.loads(response_text)
            examples = data.get("examples", [])

            if len(examples) == EXAMPLES_PER_SENSE:
                results[sense_id] = examples
                print(f"    âœ… {headword} ({reading}): {len(examples)} ä¾‹å¥")
            else:
                print(f"    âš ï¸  {headword}: è¿”å›{len(examples)}ä¸ªä¾‹å¥ï¼ˆé¢„æœŸ{EXAMPLES_PER_SENSE}ï¼‰")

        except json.JSONDecodeError as e:
            print(f"    âŒ {headword}: JSONè§£æå¤±è´¥ - {e}")
        except Exception as e:
            print(f"    âŒ {headword}: ç”Ÿæˆå¤±è´¥ - {str(e)[:100]}")

        # çŸ­æš‚å»¶è¿Ÿ
        time.sleep(0.2)

    return results

# ==================== ä¸»æµç¨‹ ====================

def main():
    print("=" * 60)
    print("ğŸ“š N5ä¾‹å¥ç”Ÿæˆè„šæœ¬ï¼ˆOpenAI GPT-4o-miniï¼‰")
    print("=" * 60)

    if not os.path.exists(DB_PATH):
        print(f"âŒ æ•°æ®åº“ä¸å­˜åœ¨: {DB_PATH}")
        sys.exit(1)

    # åŠ è½½è¿›åº¦
    progress = load_progress()

    if not progress["started_at"]:
        progress["started_at"] = datetime.now().isoformat()

    # è·å–å¾…å¤„ç†çš„sense
    print("\nğŸ” æŸ¥è¯¢N5è¯æ¡...")
    senses = get_n5_senses_without_examples(progress["completed_sense_ids"])

    if not senses:
        print("\nğŸ‰ æ‰€æœ‰N5è¯æ¡éƒ½å·²æœ‰ä¾‹å¥ï¼")
        return

    total_senses = len(senses)
    progress["total_senses"] = total_senses

    # æ˜¾ç¤ºä»»åŠ¡ä¿¡æ¯
    print(f"\nğŸ“Š ä»»åŠ¡çŠ¶æ€ï¼š")
    print(f"   - æ€»senseæ•°ï¼š{progress.get('total_senses', total_senses)}")
    print(f"   - å·²å®Œæˆï¼š{len(progress['completed_sense_ids'])}")
    print(f"   - å¾…å¤„ç†ï¼š{total_senses}")
    print(f"   - é¢„è®¡ç”Ÿæˆï¼š{total_senses * EXAMPLES_PER_SENSE} æ¡ä¾‹å¥")

    # ä¼°ç®—æˆæœ¬
    input_tokens = total_senses * 200
    output_tokens = total_senses * 300
    cost = (input_tokens / 1_000_000 * 0.150) + (output_tokens / 1_000_000 * 0.600)
    print(f"   - é¢„è®¡æˆæœ¬ï¼š${cost:.2f} USD")
    print(f"   - é¢„è®¡æ—¶é—´ï¼š{total_senses * (BATCH_SIZE * 0.5 + 0.2) / 60:.1f} åˆ†é’Ÿ")

    # ç¡®è®¤
    print(f"\nâš ï¸  å‡†å¤‡å¼€å§‹ç”Ÿæˆ")
    print(f"   æŒ‰ Ctrl+C å–æ¶ˆï¼Œæˆ–ç­‰ï¿½ï¿½ 3 ç§’è‡ªåŠ¨å¼€å§‹...")
    time.sleep(3)

    # åˆå§‹åŒ–OpenAI
    print("\nğŸ¤– åˆå§‹åŒ– OpenAI API...")
    client = init_openai()

    # æ‰¹é‡å¤„ç†
    print("\nğŸ”„ å¼€å§‹ç”Ÿæˆä¾‹å¥...\n")

    num_batches = (total_senses + BATCH_SIZE - 1) // BATCH_SIZE

    for i in range(0, total_senses, BATCH_SIZE):
        batch = senses[i:i + BATCH_SIZE]
        batch_num = i // BATCH_SIZE + 1

        print(f"ğŸ“¦ æ‰¹æ¬¡ {batch_num}/{num_batches} (sense {i+1}-{min(i+BATCH_SIZE, total_senses)}/{total_senses})")

        # ç”Ÿæˆä¾‹å¥
        examples_by_sense = generate_examples_for_batch(client, batch)

        # ä¿å­˜åˆ°æ•°æ®åº“
        batch_examples = 0
        for sense_id, examples in examples_by_sense.items():
            inserted = insert_examples(sense_id, examples)
            if inserted > 0:
                progress["completed_sense_ids"].append(sense_id)
                progress["total_examples_generated"] += inserted
                batch_examples += inserted

        # ä¿å­˜è¿›åº¦
        save_progress(progress)

        # æ˜¾ç¤ºè¿›åº¦
        completion_pct = len(progress["completed_sense_ids"]) / progress["total_senses"] * 100
        print(f"   ğŸ’¾ å·²ä¿å­˜ {len(examples_by_sense)} ä¸ªè¯æ¡çš„ä¾‹å¥")
        print(f"   ğŸ“ˆ æ€»è¿›åº¦: {completion_pct:.1f}% ({len(progress['completed_sense_ids'])}/{progress['total_senses']})")
        print()

    # å®Œæˆ
    print("=" * 60)
    print("ğŸ‰ N5ä¾‹å¥ç”Ÿæˆå®Œæˆï¼")
    print("=" * 60)
    print(f"âœ… æ€»å…±ç”Ÿæˆï¼š{progress['total_examples_generated']} æ¡ä¾‹å¥")
    print(f"âœ… è¦†ç›–è¯æ¡ï¼š{len(progress['completed_sense_ids'])} ä¸ªsense")
    elapsed = (datetime.now() - datetime.fromisoformat(progress["started_at"])).total_seconds() / 3600
    print(f"âœ… æ€»ç”¨æ—¶ï¼š{elapsed:.1f} å°æ—¶")
    print("=" * 60)

if __name__ == "__main__":
    try:
        main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­ï¼Œè¿›åº¦å·²ä¿å­˜")
        sys.exit(0)
    except Exception as e:
        print(f"\n\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)