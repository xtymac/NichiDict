#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡ç”Ÿæˆä¾‹å¥è„šæœ¬ - Batch Example Generator

ç”¨é€”ï¼šä¸ºé«˜é¢‘è¯æ¡æ‰¹é‡ç”ŸæˆAIä¾‹å¥ï¼Œæå‡ç”¨æˆ·ä½“éªŒ
ç­–ç•¥ï¼š
  1. ä¼˜å…ˆå¤„ç† frequency_rank <= 5000 çš„å¸¸ç”¨è¯
  2. è·³è¿‡å·²æœ‰ä¾‹å¥çš„è¯æ¡
  3. ä½¿ç”¨ä¾¿å®œçš„AIæ¨¡å‹ï¼ˆgpt-4o-miniï¼‰
  4. æ”¯æŒæ–­ç‚¹ç»­ä¼ å’Œé”™è¯¯é‡è¯•
  5. é™åˆ¶æ¯æ—¥APIè°ƒç”¨æ¬¡æ•°

ä½¿ç”¨æ–¹æ³•ï¼š
  python3 batch_generate_examples.py --db path/to/dict.sqlite --api-key YOUR_KEY

  å¯é€‰å‚æ•°ï¼š
    --max-rank 5000              æœ€å¤§é¢‘ç‡æ’åï¼ˆé»˜è®¤5000ï¼‰
    --batch-size 10              æ¯æ‰¹å¤„ç†æ•°é‡ï¼ˆé»˜è®¤10ï¼‰
    --max-examples 3             æ¯ä¸ªè¯ç”Ÿæˆçš„ä¾‹å¥æ•°ï¼ˆé»˜è®¤3ï¼‰
    --daily-limit 100            æ¯æ—¥APIè°ƒç”¨é™åˆ¶ï¼ˆé»˜è®¤100ï¼‰
    --model gpt-4o-mini          OpenAIæ¨¡å‹ï¼ˆé»˜è®¤gpt-4o-miniï¼‰
    --dry-run                    æµ‹è¯•æ¨¡å¼ï¼Œä¸å®é™…å†™å…¥æ•°æ®åº“
"""

import sqlite3
import json
import time
import argparse
import sys
import os
from datetime import datetime, date
from typing import List, Dict, Optional, Tuple
import hashlib

# API å®¢æˆ·ç«¯
try:
    from openai import OpenAI
    HAS_OPENAI = True
except ImportError:
    HAS_OPENAI = False
    print("âš ï¸  è­¦å‘Š: æœªå®‰è£… openai åŒ…ã€‚è¿è¡Œ: pip install openai")

# è¿›åº¦è·Ÿè¸ªæ–‡ä»¶
PROGRESS_FILE = ".batch_generate_progress.json"
STATE_FILE = ".batch_generate_state.json"


class BatchExampleGenerator:
    """æ‰¹é‡ä¾‹å¥ç”Ÿæˆå™¨"""

    def __init__(self,
                 db_path: str,
                 api_key: str,
                 model: str = "gpt-4o-mini",
                 max_rank: int = 5000,
                 batch_size: int = 10,
                 max_examples: int = 3,
                 daily_limit: int = 100,
                 dry_run: bool = False):

        self.db_path = db_path
        self.api_key = api_key
        self.model = model
        self.max_rank = max_rank
        self.batch_size = batch_size
        self.max_examples = max_examples
        self.daily_limit = daily_limit
        self.dry_run = dry_run

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_entries': 0,
            'processed': 0,
            'skipped': 0,
            'failed': 0,
            'examples_generated': 0,
            'api_calls': 0,
            'start_time': datetime.now().isoformat()
        }

        # åŠ è½½çŠ¶æ€
        self.state = self._load_state()

        # é…ç½® OpenAI
        self.client = None
        if HAS_OPENAI and not dry_run:
            self.client = OpenAI(api_key=api_key)

    def _load_state(self) -> Dict:
        """åŠ è½½ä¸Šæ¬¡è¿è¡ŒçŠ¶æ€"""
        if os.path.exists(STATE_FILE):
            with open(STATE_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        return {
            'date': str(date.today()),
            'api_calls_today': 0,
            'last_processed_id': 0
        }

    def _save_state(self):
        """ä¿å­˜å½“å‰çŠ¶æ€"""
        with open(STATE_FILE, 'w', encoding='utf-8') as f:
            json.dump(self.state, f, indent=2, ensure_ascii=False)

    def _check_daily_quota(self) -> bool:
        """æ£€æŸ¥ä»Šæ—¥é…é¢"""
        today = str(date.today())
        if self.state['date'] != today:
            # æ–°çš„ä¸€å¤©ï¼Œé‡ç½®è®¡æ•°
            self.state['date'] = today
            self.state['api_calls_today'] = 0
            self._save_state()

        if self.state['api_calls_today'] >= self.daily_limit:
            print(f"âŒ ä»Šæ—¥APIè°ƒç”¨å·²è¾¾ä¸Šé™ ({self.daily_limit})")
            return False

        remaining = self.daily_limit - self.state['api_calls_today']
        print(f"âœ… ä»Šæ—¥å‰©ä½™é…é¢: {remaining}/{self.daily_limit}")
        return True

    def _get_entries_without_examples(self) -> List[Dict]:
        """è·å–éœ€è¦ç”Ÿæˆä¾‹å¥çš„è¯æ¡"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()

        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æœ‰frequency_rankæ•°æ®
        cursor.execute("SELECT COUNT(*) as cnt FROM dictionary_entries WHERE frequency_rank IS NOT NULL")
        has_rank_data = cursor.fetchone()['cnt'] > 0

        if has_rank_data:
            # æŸ¥è¯¢ï¼šfrequency_rank <= max_rank ä¸”æ²¡æœ‰ä¾‹å¥çš„è¯æ¡
            query = """
            SELECT
                e.id,
                e.headword,
                e.reading_hiragana,
                e.reading_romaji,
                e.frequency_rank
            FROM dictionary_entries e
            WHERE e.frequency_rank <= ?
              AND e.id > ?
              AND NOT EXISTS (
                  SELECT 1
                  FROM word_senses ws
                  JOIN example_sentences ex ON ws.id = ex.sense_id
                  WHERE ws.entry_id = e.id
              )
            ORDER BY e.frequency_rank ASC, e.id ASC
            LIMIT ?
            """
            cursor.execute(query, (self.max_rank, self.state['last_processed_id'], self.batch_size))
        else:
            # æ— frequency_rankæ•°æ®ï¼ŒæŒ‰IDæ’åºå–å‰Nä¸ª
            print(f"âš ï¸  æ•°æ®åº“æ— frequency_rankæ•°æ®ï¼Œä½¿ç”¨IDé¡ºåºï¼ˆå‰{self.max_rank}ä¸ªè¯æ¡ï¼‰")
            query = """
            SELECT
                e.id,
                e.headword,
                e.reading_hiragana,
                e.reading_romaji,
                e.frequency_rank
            FROM dictionary_entries e
            WHERE e.id > ?
              AND e.id <= ?
              AND NOT EXISTS (
                  SELECT 1
                  FROM word_senses ws
                  JOIN example_sentences ex ON ws.id = ex.sense_id
                  WHERE ws.entry_id = e.id
              )
            ORDER BY e.id ASC
            LIMIT ?
            """
            cursor.execute(query, (self.state['last_processed_id'], self.max_rank, self.batch_size))

        entries = [dict(row) for row in cursor.fetchall()]

        conn.close()
        return entries

    def _get_senses_for_entry(self, entry_id: int) -> List[Dict]:
        """è·å–è¯æ¡çš„æ‰€æœ‰ä¹‰é¡¹"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()

        query = """
        SELECT
            id,
            definition_english,
            definition_chinese_simplified,
            definition_chinese_traditional,
            part_of_speech
        FROM word_senses
        WHERE entry_id = ?
        ORDER BY sense_order ASC
        """

        cursor.execute(query, (entry_id,))
        senses = [dict(row) for row in cursor.fetchall()]

        conn.close()
        return senses

    def _build_prompt(self, entry: Dict, senses: List[Dict]) -> str:
        """æ„å»ºç”Ÿæˆä¾‹å¥çš„Prompt"""
        definitions = []
        for idx, sense in enumerate(senses[:5], 1):  # æœ€å¤šå–5ä¸ªä¹‰é¡¹
            chinese = sense['definition_chinese_simplified'] or sense['definition_chinese_traditional'] or ""
            definitions.append(f"{idx}. {sense['definition_english']} | JP: {sense['part_of_speech']} | CN: {chinese}")

        definitions_text = "\n".join(definitions)

        return f"""You are an expert Japanese language tutor. Generate natural example sentences for a dictionary entry.

Entry:
- Headword: {entry['headword']}
- Reading: {entry['reading_hiragana']}
- Romaji: {entry['reading_romaji']}
- Core meanings:
{definitions_text}

Requirements:
1. Produce up to {self.max_examples} concise Japanese sentences (<= 25 characters) that demonstrate the typical usage of the word. Each sentence MUST include the headword or its conjugated/inflected form once.
2. Provide context that matches the meanings listed above. Avoid uncommon idioms or archaic grammar.
3. Return JSON ONLY with schema:
   {{"examples":[{{"japanese":"...", "chinese":"...", "english":"..."}}]}}
4. Use Simplified Chinese for the chinese field. Keep english field in natural English.
5. Avoid romaji, avoid placeholders, avoid line breaks inside fields.

Respond with JSON only."""

    def _call_openai_api(self, prompt: str) -> Optional[List[Dict]]:
        """è°ƒç”¨OpenAI APIç”Ÿæˆä¾‹å¥"""
        if not HAS_OPENAI or not self.client:
            print("âŒ OpenAI å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            return None

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                temperature=0.2,
                response_format={"type": "json_object"},
                messages=[
                    {"role": "system", "content": "Return JSON only. No prose."},
                    {"role": "user", "content": prompt}
                ]
            )

            content = response.choices[0].message.content
            data = json.loads(content)

            # æ›´æ–°APIè°ƒç”¨è®¡æ•°
            self.state['api_calls_today'] += 1
            self.stats['api_calls'] += 1
            self._save_state()

            return data.get('examples', [])

        except Exception as e:
            print(f"âŒ APIè°ƒç”¨å¤±è´¥: {e}")
            return None

    def _insert_examples(self, entry_id: int, senses: List[Dict], examples: List[Dict]):
        """å°†ç”Ÿæˆçš„ä¾‹å¥æ’å…¥æ•°æ®åº“"""
        if self.dry_run:
            print(f"  [DRY-RUN] å°†æ’å…¥ {len(examples)} ä¸ªä¾‹å¥")
            return

        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()

        try:
            # ä¸ºæ¯ä¸ªä¹‰é¡¹åˆ†é…ä¾‹å¥
            # ç­–ç•¥ï¼šå¦‚æœåªæœ‰1ä¸ªä¹‰é¡¹ï¼Œæ‰€æœ‰ä¾‹å¥å½’å®ƒï¼›å¦åˆ™å¹³å‡åˆ†é…
            if len(senses) == 1:
                sense_ids = [senses[0]['id']] * len(examples)
            else:
                # å¾ªç¯åˆ†é…
                sense_ids = [senses[i % len(senses)]['id'] for i in range(len(examples))]

            for order, (example, sense_id) in enumerate(zip(examples, sense_ids)):
                cursor.execute("""
                    INSERT INTO example_sentences
                    (sense_id, japanese_text, english_translation, example_order)
                    VALUES (?, ?, ?, ?)
                """, (
                    sense_id,
                    example['japanese'],
                    example['english'],
                    order
                ))

            conn.commit()
            self.stats['examples_generated'] += len(examples)
            print(f"  âœ… æˆåŠŸæ’å…¥ {len(examples)} ä¸ªä¾‹å¥")

        except Exception as e:
            conn.rollback()
            print(f"  âŒ æ•°æ®åº“æ’å…¥å¤±è´¥: {e}")
            raise
        finally:
            conn.close()

    def process_entry(self, entry: Dict) -> bool:
        """å¤„ç†å•ä¸ªè¯æ¡"""
        entry_id = entry['id']
        headword = entry['headword']
        rank = entry['frequency_rank'] or 'N/A'

        print(f"\nğŸ“– å¤„ç†ä¸­: {headword} (ID={entry_id}, Rank={rank})")

        # è·å–ä¹‰é¡¹
        senses = self._get_senses_for_entry(entry_id)
        if not senses:
            print(f"  âš ï¸  è·³è¿‡: æ— ä¹‰é¡¹")
            self.stats['skipped'] += 1
            return False

        print(f"  ğŸ“ ä¹‰é¡¹æ•°: {len(senses)}")

        # æ„å»ºPrompt
        prompt = self._build_prompt(entry, senses)

        # è°ƒç”¨APIç”Ÿæˆä¾‹å¥
        examples = self._call_openai_api(prompt)

        if not examples:
            print(f"  âŒ ç”Ÿæˆå¤±è´¥")
            self.stats['failed'] += 1
            return False

        print(f"  ğŸ¯ ç”Ÿæˆäº† {len(examples)} ä¸ªä¾‹å¥:")
        for ex in examples:
            print(f"     â€¢ {ex['japanese']}")

        # æ’å…¥æ•°æ®åº“
        try:
            self._insert_examples(entry_id, senses, examples)
            self.stats['processed'] += 1

            # æ›´æ–°çŠ¶æ€
            self.state['last_processed_id'] = entry_id
            self._save_state()

            return True

        except Exception as e:
            print(f"  âŒ æ’å…¥å¤±è´¥: {e}")
            self.stats['failed'] += 1
            return False

    def run(self):
        """è¿è¡Œæ‰¹é‡ç”Ÿæˆ"""
        print("=" * 60)
        print("ğŸš€ æ‰¹é‡ä¾‹å¥ç”Ÿæˆå™¨å¯åŠ¨")
        print("=" * 60)
        print(f"æ•°æ®åº“: {self.db_path}")
        print(f"æ¨¡å‹: {self.model}")
        print(f"æœ€å¤§é¢‘ç‡æ’å: {self.max_rank}")
        print(f"æ‰¹æ¬¡å¤§å°: {self.batch_size}")
        print(f"æ¯è¯ä¾‹å¥æ•°: {self.max_examples}")
        print(f"æ¯æ—¥é™é¢: {self.daily_limit}")
        print(f"æµ‹è¯•æ¨¡å¼: {'æ˜¯' if self.dry_run else 'å¦'}")
        print("=" * 60)

        # æ£€æŸ¥é…é¢
        if not self._check_daily_quota():
            print("\nâ¸ï¸  å·²è¾¾ä»Šæ—¥é™é¢ï¼Œæ˜å¤©å†æ¥ï¼")
            return

        # è·å–å¾…å¤„ç†è¯æ¡
        print("\nğŸ” æŸ¥è¯¢éœ€è¦ç”Ÿæˆä¾‹å¥çš„è¯æ¡...")
        entries = self._get_entries_without_examples()

        if not entries:
            print("âœ… æ‰€æœ‰è¯æ¡éƒ½å·²æœ‰ä¾‹å¥ï¼")
            return

        self.stats['total_entries'] = len(entries)
        print(f"ğŸ“Š æ‰¾åˆ° {len(entries)} ä¸ªè¯æ¡éœ€è¦ç”Ÿæˆä¾‹å¥\n")

        # å¤„ç†æ¯ä¸ªè¯æ¡
        for idx, entry in enumerate(entries, 1):
            # æ£€æŸ¥é…é¢
            if self.state['api_calls_today'] >= self.daily_limit:
                print(f"\nâ¸ï¸  å·²è¾¾ä»Šæ—¥é™é¢ ({self.daily_limit})ï¼Œåœæ­¢å¤„ç†")
                break

            print(f"\n[{idx}/{len(entries)}]", end=" ")
            self.process_entry(entry)

            # APIé€Ÿç‡é™åˆ¶ï¼šé¿å…è§¦å‘é™æµ
            if not self.dry_run and idx < len(entries):
                time.sleep(1)  # æ¯ä¸ªè¯·æ±‚é—´éš”1ç§’

        # æ‰“å°ç»Ÿè®¡
        self._print_stats()

    def _print_stats(self):
        """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
        print("\n" + "=" * 60)
        print("ğŸ“Š æ‰¹é‡ç”Ÿæˆç»Ÿè®¡")
        print("=" * 60)
        print(f"æ€»è¯æ¡æ•°: {self.stats['total_entries']}")
        print(f"æˆåŠŸå¤„ç†: {self.stats['processed']} âœ…")
        print(f"è·³è¿‡: {self.stats['skipped']} âš ï¸")
        print(f"å¤±è´¥: {self.stats['failed']} âŒ")
        print(f"ç”Ÿæˆä¾‹å¥æ•°: {self.stats['examples_generated']}")
        print(f"APIè°ƒç”¨æ¬¡æ•°: {self.stats['api_calls']}")
        print(f"ä»Šæ—¥å·²ç”¨é…é¢: {self.state['api_calls_today']}/{self.daily_limit}")
        print(f"ä¸Šæ¬¡å¤„ç†ID: {self.state['last_processed_id']}")
        print("=" * 60)

        # ä¿å­˜ç»Ÿè®¡åˆ°æ–‡ä»¶
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_file = f"batch_generate_log_{timestamp}.json"
        with open(log_file, 'w', encoding='utf-8') as f:
            json.dump({
                'stats': self.stats,
                'state': self.state,
                'config': {
                    'db_path': self.db_path,
                    'model': self.model,
                    'max_rank': self.max_rank,
                    'batch_size': self.batch_size,
                    'max_examples': self.max_examples
                }
            }, f, indent=2, ensure_ascii=False)

        print(f"\nğŸ“„ è¯¦ç»†æ—¥å¿—å·²ä¿å­˜: {log_file}")


def main():
    parser = argparse.ArgumentParser(
        description='æ‰¹é‡ç”Ÿæˆè¯å…¸ä¾‹å¥',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # åŸºç¡€ç”¨æ³•ï¼ˆä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„API keyï¼‰
  python3 batch_generate_examples.py --db dict.sqlite

  # æŒ‡å®šAPI keyå’Œå‚æ•°
  python3 batch_generate_examples.py --db dict.sqlite --api-key sk-xxx \\
    --max-rank 3000 --batch-size 20 --daily-limit 200

  # æµ‹è¯•æ¨¡å¼ï¼ˆä¸å®é™…è°ƒç”¨APIå’Œå†™å…¥æ•°æ®åº“ï¼‰
  python3 batch_generate_examples.py --db dict.sqlite --dry-run
"""
    )

    parser.add_argument('--db', required=True, help='SQLiteæ•°æ®åº“è·¯å¾„')
    parser.add_argument('--api-key', help='OpenAI API Keyï¼ˆå¯é€‰ï¼Œé»˜è®¤ä»ç¯å¢ƒå˜é‡OPENAI_API_KEYè¯»å–ï¼‰')
    parser.add_argument('--model', default='gpt-4o-mini', help='OpenAIæ¨¡å‹ï¼ˆé»˜è®¤: gpt-4o-miniï¼‰')
    parser.add_argument('--max-rank', type=int, default=5000, help='æœ€å¤§é¢‘ç‡æ’åï¼ˆé»˜è®¤: 5000ï¼‰')
    parser.add_argument('--batch-size', type=int, default=10, help='æ¯æ‰¹å¤„ç†æ•°é‡ï¼ˆé»˜è®¤: 10ï¼‰')
    parser.add_argument('--max-examples', type=int, default=3, help='æ¯è¯ç”Ÿæˆä¾‹å¥æ•°ï¼ˆé»˜è®¤: 3ï¼‰')
    parser.add_argument('--daily-limit', type=int, default=100, help='æ¯æ—¥APIè°ƒç”¨é™åˆ¶ï¼ˆé»˜è®¤: 100ï¼‰')
    parser.add_argument('--dry-run', action='store_true', help='æµ‹è¯•æ¨¡å¼ï¼Œä¸å®é™…æ‰§è¡Œ')

    args = parser.parse_args()

    # è·å–API Key
    api_key = args.api_key or os.getenv('OPENAI_API_KEY')
    if not api_key and not args.dry_run:
        print("âŒ é”™è¯¯: éœ€è¦æä¾› OpenAI API Key")
        print("   æ–¹æ³•1: --api-key YOUR_KEY")
        print("   æ–¹æ³•2: è®¾ç½®ç¯å¢ƒå˜é‡ OPENAI_API_KEY")
        sys.exit(1)

    # æ£€æŸ¥æ•°æ®åº“æ–‡ä»¶
    if not os.path.exists(args.db):
        print(f"âŒ é”™è¯¯: æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {args.db}")
        sys.exit(1)

    # åˆ›å»ºç”Ÿæˆå™¨å¹¶è¿è¡Œ
    generator = BatchExampleGenerator(
        db_path=args.db,
        api_key=api_key or "",
        model=args.model,
        max_rank=args.max_rank,
        batch_size=args.batch_size,
        max_examples=args.max_examples,
        daily_limit=args.daily_limit,
        dry_run=args.dry_run
    )

    try:
        generator.run()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ç”¨æˆ·ä¸­æ–­ï¼Œä¿å­˜è¿›åº¦...")
        generator._print_stats()
    except Exception as e:
        print(f"\nâŒ å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


if __name__ == '__main__':
    main()
