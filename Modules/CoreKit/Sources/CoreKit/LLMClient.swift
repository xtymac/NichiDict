//
//  LLMClient.swift
//  CoreKit
//
//  Created by Mac on 2025/10/06.
//

import Foundation
import CryptoKit

// MARK: - å…¬å…±æ¨¡å‹ï¼šAI è¿”å›ç»“æ„ï¼ˆè¯å…¸æ ¼å¼ï¼‰
public struct LLMDictEntry: Codable, Hashable {
    public let headword: String           // è¦‹å‡ºã—èªï¼ˆæ—¥è¯­è¯æ¡ï¼‰
    public let reading: String            // èª­ã¿ï¼ˆå‡åï¼‰
    public let romaji: String?            // ãƒ­ãƒ¼ãƒå­—ï¼ˆHepburnï¼‰
    public let partOfSpeech: String       // å“è©ï¼ˆå‹•è©ãƒ»åè©ãƒ»å½¢å®¹å‹•è© ç­‰ï¼‰
    public let accent: String?            // ã‚¢ã‚¯ã‚»ãƒ³ãƒˆï¼ˆéŸ³è°ƒï¼‰
    public let senses: [LLMSense]         // ç¾©é …ï¼ˆæœ€å¤š3æ¡ï¼‰
    public let grammar: LLMGrammar?       // æ–‡æ³•ãƒ»ç”¨æ³•
    public let examples: [LLMExample]?    // ç”¨ä¾‹ï¼ˆå¯é€‰ï¼‰
    public let related: LLMRelated?       // é–¢é€£èª
    public var jlptLevel: String?         // JLPTçº§åˆ«ï¼ˆä»æœ¬åœ°æ•°æ®åº“æŸ¥è¯¢åè¡¥å……ï¼‰

    public init(headword: String, reading: String, romaji: String?, partOfSpeech: String,
                accent: String?, senses: [LLMSense], grammar: LLMGrammar?,
                examples: [LLMExample]?, related: LLMRelated?, jlptLevel: String? = nil) {
        self.headword = headword
        self.reading = reading
        self.romaji = romaji
        self.partOfSpeech = partOfSpeech
        self.accent = accent
        self.senses = senses
        self.grammar = grammar
        self.examples = examples
        self.related = related
        self.jlptLevel = jlptLevel
    }
}

public struct LLMSense: Codable, Hashable {
    public let definition: String    // æ—¥è¯­é‡Šä¹‰
    public let chinese: String       // ä¸­æ–‡è¯‘æ–‡
    public let english: String       // è‹±æ–‡è¯‘æ–‡

    public init(definition: String, chinese: String, english: String) {
        self.definition = definition
        self.chinese = chinese
        self.english = english
    }
}

public struct LLMGrammar: Codable, Hashable {
    public let conjugation: [String]?  // æ´»ç”¨å½¢å¼
    public let collocation: [String]?  // å¸¸è§æ­é…
    public let honorific: String?      // æ•¬è¯­å½¢å¼

    public init(conjugation: [String]?, collocation: [String]?, honorific: String?) {
        self.conjugation = conjugation
        self.collocation = collocation
        self.honorific = honorific
    }
}

public struct LLMRelated: Codable, Hashable {
    public let synonym: String?    // ç±»ä¹‰è¯
    public let antonym: String?    // åä¹‰è¯
    public let derived: String?    // æ´¾ç”Ÿè¯

    public init(synonym: String?, antonym: String?, derived: String?) {
        self.synonym = synonym
        self.antonym = antonym
        self.derived = derived
    }
}

public struct LLMExample: Codable, Hashable, Sendable {
    public let japanese: String    // æ—¥è¯­ä¾‹å¥
    public let chinese: String?    // ä¸­æ–‡ç¿»è¯‘ï¼ˆå¯é€‰ï¼Œä»…ä¸­æ–‡ç”¨æˆ·ç”Ÿæˆï¼‰
    public let english: String     // è‹±æ–‡ç¿»è¯‘

    public init(japanese: String, chinese: String? = nil, english: String) {
        self.japanese = japanese
        self.chinese = chinese
        self.english = english
    }
}

// æŸ¥è¯¢ç»“æœç±»å‹
public enum LLMQueryType: String, Codable {
    case word           // å•è¯æŸ¥è¯¢
    case sentence       // å¥å­è§£æ
    case notFound       // æœªæ”¶å½•
}

public struct LLMResult: Codable, Hashable {
    public let queryType: LLMQueryType        // æŸ¥è¯¢ç±»å‹
    public let entries: [LLMDictEntry]?       // è¯æ¡ï¼ˆæœ€å¤štop_kä¸ªï¼Œå¥å­æŸ¥è¯¢æ—¶å¯é€‰ï¼‰
    public let sentenceAnalysis: LLMSentenceAnalysis?  // å¥å­è§£æï¼ˆä»…å¥å­æŸ¥è¯¢ï¼‰

    public init(queryType: LLMQueryType, entries: [LLMDictEntry]?, sentenceAnalysis: LLMSentenceAnalysis?) {
        self.queryType = queryType
        self.entries = entries
        self.sentenceAnalysis = sentenceAnalysis
    }
}

public struct LLMSentenceAnalysis: Codable, Hashable {
    public let original: String                     // åŸå¥
    public let translation: LLMTranslation          // ç¿»è¯‘ï¼ˆä¸­è‹±ï¼‰
    public let wordBreakdown: [LLMWordBreakdown]?   // é€è¯è§£æï¼ˆå¯é€‰ï¼‰
    public let grammarPoints: [LLMGrammarPoint]?    // è¯­æ³•ç‚¹ï¼ˆå¯é€‰ï¼‰
    public let examples: [LLMExample]?              // ä¾‹å¥ï¼ˆå¯é€‰ï¼‰

    public init(original: String, translation: LLMTranslation,
                wordBreakdown: [LLMWordBreakdown]?, grammarPoints: [LLMGrammarPoint]?,
                examples: [LLMExample]? = nil) {
        self.original = original
        self.translation = translation
        self.wordBreakdown = wordBreakdown
        self.grammarPoints = grammarPoints
        self.examples = examples
    }
}

public struct LLMTranslation: Codable, Hashable {
    public let chinese: String    // ä¸­æ–‡ç¿»è¯‘
    public let english: String    // è‹±æ–‡ç¿»è¯‘

    public init(chinese: String, english: String) {
        self.chinese = chinese
        self.english = english
    }
}

public struct LLMWordBreakdown: Codable, Hashable {
    public let word: String            // è¯
    public let reading: String?        // è¯»éŸ³ï¼ˆå¯é€‰ï¼Œå¦‚æ ‡ç‚¹ç¬¦å·å¯èƒ½ä¸ºnullï¼‰
    public let meaning: String         // è¯ä¹‰
    public let grammaticalRole: String // è¯­æ³•ä½œç”¨

    public init(word: String, reading: String?, meaning: String, grammaticalRole: String) {
        self.word = word
        self.reading = reading
        self.meaning = meaning
        self.grammaticalRole = grammaticalRole
    }
}

public struct LLMGrammarPoint: Codable, Hashable {
    public let pattern: String         // æ–‡æ³•æ¨¡å¼
    public let reading: String         // è¯»éŸ³
    public let meaning: String         // å«ä¹‰
    public let explanation: String     // è¯¦ç»†è¯´æ˜

    public init(pattern: String, reading: String, meaning: String, explanation: String) {
        self.pattern = pattern
        self.reading = reading
        self.meaning = meaning
        self.explanation = explanation
    }
}

// MARK: - Provider å®šç¾©
public enum LLMProvider {
    case openAI(model: String)      // ä¾‹: "gpt-4o-mini" / "gpt-4.1-mini"
    case anthropic(model: String)   // ä¾‹: "claude-3-haiku"
    case gemini(model: String)      // ä¾‹: "gemini-2.0-flash-exp" / "gemini-1.5-flash"
}

// MARK: - éŒ¯èª¤
public enum LLMError: Error, LocalizedError {
    case notConfigured
    case emptyResponse
    case httpError(Int, String)
    case decodeFailed(String)
    case quotaExceeded

    public var errorDescription: String? {
        switch self {
        case .notConfigured: return "LLM å°šæœªé…ç½® API Key / Provider"
        case .emptyResponse: return "LLM ç©ºå›æ‡‰"
        case .httpError(let code, let msg): return "LLM è«‹æ±‚éŒ¯èª¤ (\(code)): \(msg)"
        case .decodeFailed(let msg): return "è§£æå¤±æ•—: \(msg)"
        case .quotaExceeded: return "ä»Šæ—¥ AI æ¬¡æ•¸å·²ç”¨å®Œ"
        }
    }
}

// MARK: - å®¢æˆ¶ç«¯
@MainActor
public final class LLMClient {

    public static let shared = LLMClient()

    private init() {}

    private var apiKey: String?
    private var provider: LLMProvider?

    // ç°¡å–®é…é¡æ§åˆ¶ï¼ˆè©¦ç”¨æœŸä¿è­·ï¼‰
    private let dailyLimitKey = "ai_daily_limit"
    private let dailyDateKey  = "ai_daily_date"

    // å…§å­˜ + ç£ç›¤ç·©å­˜
    private let memCache = NSCache<NSString, NSData>()
    private lazy var diskCacheDir: URL = {
        let url = FileManager.default.urls(for: .cachesDirectory, in: .userDomainMask)[0]
            .appendingPathComponent("LLMCache", isDirectory: true)
        try? FileManager.default.createDirectory(at: url, withIntermediateDirectories: true)
        return url
    }()

    // MARK: é…ç½®
    public func configure(apiKey: String, provider: LLMProvider) {
        self.apiKey = apiKey
        self.provider = provider
    }

    // å¯é¸ï¼šèª¿æ•´æ¯æ—¥ä¸Šé™ï¼ˆé»˜èª 50 æ¬¡ï¼‰
    public var dailyLimit: Int = 50

    // Clear all caches (for debugging or when language changes)
    public func clearAllCaches() {
        print("ğŸ—‘ï¸ Clearing all AI caches...")
        memCache.removeAllObjects()

        // Clear disk cache
        do {
            let files = try FileManager.default.contentsOfDirectory(at: diskCacheDir, includingPropertiesForKeys: nil)
            for file in files {
                try? FileManager.default.removeItem(at: file)
            }
            print("âœ… All caches cleared (\(files.count) disk files removed)")
        } catch {
            print("âš ï¸ Error clearing disk cache: \(error)")
        }
    }

    // MARK: å°å¤–ä¸»æ–¹æ³•
    @discardableResult
    public func translateExplain(sentence: String,
                                 locale: String = "zh",
                                 useCache: Bool = true,
                                 onPartialResult: (@Sendable (String) -> Void)? = nil) async throws -> LLMResult {

        guard let _ = apiKey, let provider = provider else {
            throw LLMError.notConfigured
        }

        // å‘½ä¸­å¿«å–
        let key = cacheKey(sentence: sentence, provider: provider, locale: locale)
        print("ğŸ”‘ Cache key calculation:")
        print("   - sentence: \(sentence)")
        print("   - provider: \(providerIdentifier(provider))")
        print("   - locale: \(locale)")
        print("   - version: v3")
        print("   - resulting key: \(key)")

        if useCache, let cached: LLMResult = loadCache(for: key) {
            print("âœ… Cache HIT - returning cached result")
            print("   âš ï¸ If content is wrong language, the app may need a clean restart")
            return cached
        }
        print("âŒ Cache MISS - will request AI")

        // é…é¡åˆ¤æ–·
        try checkDailyQuota()

        // çµ„è£æç¤ºï¼ˆè¦æ±‚è¿”å› JSONï¼‰
        let prompt = buildPrompt(sentence: sentence, locale: locale)
        print("ğŸ“¤ Sending AI request with locale: \(locale)")
        print("ğŸ“ Prompt length: \(prompt.count) characters")

        // ç™¼é€è«‹æ±‚ï¼ˆæ·»åŠ æ€§èƒ½ç›‘æ§ï¼‰
        let startTime = Date()
        let result: LLMResult
        switch provider {
        case .openAI(let model):
            result = try await requestOpenAI(model: model, prompt: prompt)
        case .anthropic(let model):
            result = try await requestAnthropic(model: model, prompt: prompt)
        case .gemini(let model):
            // å¦‚æœæä¾›äº†å›è°ƒï¼Œä½¿ç”¨æµå¼å“åº”
            if let callback = onPartialResult {
                result = try await requestGeminiStreaming(model: model, prompt: prompt, onPartialResult: callback)
            } else {
                result = try await requestGemini(model: model, prompt: prompt)
            }
        }
        let duration = Date().timeIntervalSince(startTime)
        print("âœ… AI response received in \(String(format: "%.2f", duration))s")

        // å¯«å…¥å¿«å– + è¨ˆæ•¸
        saveCache(result, for: key)
        increaseDailyCount()

        return result
    }

    public func generateExamples(for entry: DictionaryEntry,
                                 senses providedSenses: [WordSense]? = nil,
                                 locale: String = Locale.current.identifier,
                                 maxExamples: Int = 3,
                                 useCache: Bool = true) async throws -> [LLMExample] {
        guard let _ = apiKey, let provider = provider else {
            throw LLMError.notConfigured
        }

        let senses = (providedSenses ?? entry.senses).filter { !$0.definitionEnglish.isEmpty }
        guard !senses.isEmpty else {
            return []
        }

        // Extract existing offline examples to avoid duplication
        let existingExamples = senses.flatMap { $0.examples.map { $0.japaneseText } }
        print("ğŸ“ Found \(existingExamples.count) existing offline examples for \(entry.headword)")
        if !existingExamples.isEmpty {
            print("   Existing: \(existingExamples.prefix(3).joined(separator: " | "))")
        }

        let key = cacheKeyForExamples(
            entryID: entry.id,
            provider: provider,
            locale: locale,
            maxExamples: maxExamples,
            senses: senses
        )

        if useCache, let cached: ExampleResponse = loadCache(for: key) {
            return cached.examples
        }

        try checkDailyQuota()

        let prompt = buildExamplePrompt(
            entry: entry,
            senses: senses,
            locale: locale,
            maxExamples: maxExamples,
            existingExamples: existingExamples
        )

        let responseData: Data
        switch provider {
        case .openAI(let model):
            responseData = try await requestOpenAIContent(model: model, prompt: prompt)
        case .anthropic(let model):
            responseData = try await requestAnthropicContent(model: model, prompt: prompt)
        case .gemini(let model):
            responseData = try await requestGeminiContent(model: model, prompt: prompt)
        }

        let response: ExampleResponse
        do {
            response = try JSONDecoder().decode(ExampleResponse.self, from: responseData)
        } catch {
            let raw = String(data: responseData, encoding: .utf8) ?? ""
            throw LLMError.decodeFailed("ä¾‹å¥è§£æå¤±è´¥: \(error.localizedDescription)\n\(raw.prefix(200))")
        }

        saveCache(response, for: key)
        increaseDailyCount()

        return response.examples
    }

    // MARK: Prompt
    private func buildPrompt(sentence: String, locale: String) -> String {
        // Detect user's primary language from locale
        let isChineseUser = locale.hasPrefix("zh")
        let primaryLanguage = isChineseUser ? "Chinese (Simplified)" : "English"
        let secondaryLanguage = isChineseUser ? "English" : "Chinese (Simplified)"

        print("ğŸŒ Building prompt for locale: \(locale)")
        print("ğŸŒ Primary language: \(primaryLanguage)")
        print("ğŸŒ Secondary language: \(secondaryLanguage)")

        return """
        You are a professional Japanese dictionary system. Map user input (Chinese/English/Japanese) to the most appropriate Japanese dictionary entries.

        âš ï¸ CRITICAL LANGUAGE REQUIREMENT âš ï¸
        The user's system language is: \(primaryLanguage)
        YOU MUST write ALL explanations, meanings, grammatical roles, and descriptions in \(primaryLanguage).
        DO NOT use \(secondaryLanguage) for explanatory content.

        Specifically:
        - In "wordBreakdown" array: "meaning" and "grammaticalRole" MUST be in \(primaryLanguage)
        - In "grammarPoints" array: "meaning" and "explanation" MUST be in \(primaryLanguage)
        - Only the "translation" object should contain both languages

        Example: If primaryLanguage is English, write "money" not "é’±", write "noun" not "åè¯"

        CRITICAL: You MUST return valid JSON that EXACTLY matches the schema below. Do not add any text before or after the JSON.

        ## Step 1: Determine Query Type
        - If input contains periods/question marks/exclamation marks OR has many spaces OR length>12 with multiple word forms â†’ queryType: "sentence"
        - Otherwise â†’ queryType: "word"
        - If cannot identify â†’ queryType: "notFound"

        ## Step 2: Response Rules
        - Primary language: Japanese definitions
        - User's primary language: \(primaryLanguage) (use this for main explanations in "meaning", "explanation", and "grammaticalRole" fields)
        - User's secondary language: \(secondaryLanguage) (use this for the corresponding field)
        - Provide translations in both \(primaryLanguage) and \(secondaryLanguage)
        - No redundancy: merge same meanings/POS/definitions
        - Max 3 senses per entry, 2-3 examples per word
        - For sentence analysis: provide 2-3 similar example sentences in the "examples" array
        - Useã€Œ(æ¨å®š)ã€for uncertain information
        - For Chinese/English input (e.g., "noon", "eat"), map to Japanese entries (e.g., ã€Œæ­£åˆã€ã€Œæ˜¼ã€ã€Œé£Ÿã¹ã‚‹ã€ã€Œé£Ÿã†ã€)
        - **CRITICAL FOR SENTENCE MODE**: If input is in English/Chinese, FIRST translate to Japanese, then analyze the Japanese sentence
        - **In sentence mode, "original" field MUST be the Japanese sentence** (translated if needed)
        - **wordBreakdown MUST break down the JAPANESE words**, not the input language
        - IMPORTANT: In wordBreakdown, use \(primaryLanguage) for "meaning" and "grammaticalRole" fields
        - IMPORTANT: In grammarPoints, use \(primaryLanguage) for "meaning" and "explanation" fields

        ## Step 3: JSON Schema - Word Mode (MUST FOLLOW EXACTLY)
        {
          "queryType": "word",
          "entries": [
            {
              "headword": "é£Ÿã¹ã‚‹",
              "reading": "ãŸã¹ã‚‹",
              "romaji": "taberu",
              "partOfSpeech": "ä¸€æ®µå‹•è©ãƒ»ä»–å‹•",
              "accent": "ãŸã¹â†˜ã‚‹ï¼»1ï¼½",
              "senses": [
                {
                  "definition": "å£ã«å…¥ã‚Œã¦å™›ã¿ã€é£²ã¿è¾¼ã‚€",
                  "chinese": "åƒï¼›è¿›é£Ÿ",
                  "english": "to eat"
                },
                {
                  "definition": "è³‡æºã‚„æ™‚é–“ã‚’å¤§é‡ã«æ¶ˆè²»ã™ã‚‹",
                  "chinese": "è€—è´¹",
                  "english": "to consume"
                }
              ],
              "grammar": {
                "conjugation": ["é£Ÿã¹ã¾ã™", "é£Ÿã¹ãªã„", "é£Ÿã¹ãŸ", "é£Ÿã¹ã¦"],
                "collocation": ["ã‚’é£Ÿã¹ã‚‹", "å¤–ã§é£Ÿã¹ã‚‹", "åé£Ÿã‚’ã™ã‚‹"],
                "honorific": "å¬ã—ä¸ŠãŒã‚‹ï¼ˆå°Šæ•¬ï¼‰ã€ã„ãŸã ãï¼ˆè¬™è­²ï¼‰"
              },
              "examples": [
                {
                  "japanese": "æœã”ã¯ã‚“ã‚’é£Ÿã¹ã‚‹ã€‚",
                  "chinese": "æˆ‘åƒæ—©é¥­ã€‚",
                  "english": "I eat breakfast."
                }
              ],
              "related": {
                "synonym": "å–«ã™ã‚‹ï¼ˆæ›¸ï¼‰ï¼ã„ãŸã ãï¼ˆè¬™ï¼‰",
                "antonym": "æ–­é£Ÿã™ã‚‹",
                "derived": null
              }
            }
          ]
        }

        ## 4) å¥å­è§£ææ¨¡å¼ JSON ç»“æ„
        Example for \(primaryLanguage) users:
        {
          "queryType": "sentence",
          "sentenceAnalysis": {
            "original": "ä»Šæ—¥ã¯é›¨ãŒé™ã‚Šãã†ã§ã™ã€‚",
            "translation": {
              "chinese": "\(isChineseUser ? "ä»Šå¤©å¥½åƒè¦ä¸‹é›¨ã€‚" : "It looks like it will rain today.")",
              "english": "\(isChineseUser ? "It looks like it will rain today." : "ä»Šå¤©å¥½åƒè¦ä¸‹é›¨ã€‚")"
            },
            "wordBreakdown": [
              {
                "word": "ä»Šæ—¥",
                "reading": "ãã‚‡ã†",
                "meaning": "\(primaryLanguage == "English" ? "today" : "ä»Šå¤©")",
                "grammaticalRole": "\(primaryLanguage == "English" ? "time noun" : "æ™‚é–“åè©")"
              },
              {
                "word": "ã¯",
                "reading": "ã¯",
                "meaning": "\(primaryLanguage == "English" ? "(topic marker)" : "ï¼ˆä¸»é¢˜æ ‡è®°ï¼‰")",
                "grammaticalRole": "\(primaryLanguage == "English" ? "particle" : "ä¿‚åŠ©è©")"
              },
              {
                "word": "é›¨",
                "reading": "ã‚ã‚",
                "meaning": "\(primaryLanguage == "English" ? "rain" : "é›¨")",
                "grammaticalRole": "\(primaryLanguage == "English" ? "noun" : "åè©")"
              }
            ],
            "grammarPoints": [
              {
                "pattern": "ãã†ã§ã™",
                "reading": "ãã†ã§ã™",
                "meaning": "\(primaryLanguage == "English" ? "looks like; seems" : "æ ·æ€æ¨æµ‹")",
                "explanation": "\(primaryLanguage == "English" ? "Expresses conjecture based on visual appearance or situation" : "è¡¨ç¤ºæ ¹æ®å¤–è§‚æˆ–æ ·å­è¿›è¡Œæ¨æµ‹")"
              }
            ],
            "examples": [
              {
                "japanese": "æ˜æ—¥ã¯æ™´ã‚Œãã†ã§ã™ã€‚",
                "chinese": "æ˜å¤©å¥½åƒä¼šæ™´å¤©ã€‚",
                "english": "It looks like it will be sunny tomorrow."
              },
              {
                "japanese": "ã“ã®æœ¬ã¯é¢ç™½ãã†ã§ã™ã€‚",
                "chinese": "è¿™æœ¬ä¹¦çœ‹èµ·æ¥å¾ˆæœ‰è¶£ã€‚",
                "english": "This book looks interesting."
              }
            ]
          }
        }

        CRITICAL: Use \(primaryLanguage) for "meaning", "grammaticalRole", and "explanation" fields in wordBreakdown and grammarPoints!

        ## 5) æœªåéŒ²æ¨¡å¼ JSON ç»“æ„ - IMPORTANT: Provide internet-based explanation
        When queryType is "notFound", you should:
        1. Use your knowledge (including internet sources) to provide the best explanation
        2. If it's a real Japanese word/phrase not in the dictionary, explain its meaning, usage, and origin
        3. If it's a typo or non-existent word, suggest corrections and explain why
        4. Provide definitions in BOTH Japanese and user's language (\(primaryLanguage))

        Example for a word not in dictionary:
        {
          "queryType": "notFound",
          "entries": [
            {
              "headword": "{input as-is}",
              "reading": "{inferred reading in hiragana}",
              "romaji": "{romaji if applicable}",
              "partOfSpeech": "{inferred part of speech, or 'æœªåéŒ²èª' if unknown}",
              "accent": null,
              "senses": [
                {
                  "definition": "{Japanese explanation based on your knowledge}",
                  "chinese": "{Chinese translation if primaryLanguage is Chinese}",
                  "english": "{English explanation if primaryLanguage is English}"
                }
              ],
              "grammar": null,
              "examples": [
                {
                  "japanese": "{example sentence if known}",
                  "chinese": "{Chinese translation}",
                  "english": "{English translation}"
                }
              ],
              "related": {
                "synonym": "{similar words if any}",
                "antonym": null,
                "derived": "{possible corrections or related forms}"
              }
            }
          ]
        }

        CRITICAL for notFound mode:
        - DO NOT just return "æœªæ”¶å½•/Not found" - provide actual explanations from your knowledge
        - If it's internet slang, explain its origin and meaning
        - If it's a proper noun, explain what it refers to
        - If it's a typo, suggest the correct form in "derived" field
        - Use \(primaryLanguage) for all explanations

        ## MANDATORY REQUIREMENTS
        âš ï¸ CRITICAL - Your response MUST be valid JSON ONLY. No explanations, no markdown, no prefix/suffix.
        âš ï¸ CRITICAL - Use ENGLISH punctuation ONLY in JSON structure: colons (:), commas (,), quotes ("). NEVER use Chinese punctuation (ï¼šã€ï¼Œã€ã€‚).
        âš ï¸ CRITICAL - ALL fields marked as required MUST be present. Use null for optional fields if empty.
        âš ï¸ CRITICAL - Field names must match EXACTLY (case-sensitive): "headword", "reading", "romaji", "partOfSpeech", "accent", "senses", "grammar", "examples", "related"

        Quality Rules:
        - Forbidden: duplicate senses, empty definitions, kanji variants only, verbose explanations
        - Required: Each sense has Japanese definition + Chinese + English translation; natural, common examples
        - For multiple candidates: sort by modern usage frequency (common > literary > dialect), max 3 entries
        - sentenceAnalysis field is REQUIRED when queryType is "sentence", but should be null for "word" or "notFound"
        - entries field is REQUIRED for all queryType values

        EXAMPLE 1 - Word Query "go":
        {
          "queryType": "word",
          "entries": [
            {
              "headword": "è¡Œã",
              "reading": "ã„ã",
              "romaji": "iku",
              "partOfSpeech": "äº”æ®µå‹•è©ãƒ»è‡ªå‹•",
              "accent": "ã„â†—ãï¼»0ï¼½",
              "senses": [
                {
                  "definition": "ã‚ã‚‹å ´æ‰€ã‹ã‚‰åˆ¥ã®å ´æ‰€ã¸ç§»å‹•ã™ã‚‹",
                  "chinese": "å»ï¼›å‰å¾€",
                  "english": "to go"
                }
              ],
              "grammar": {
                "conjugation": ["è¡Œãã¾ã™", "è¡Œã‹ãªã„", "è¡Œã£ãŸ", "è¡Œã£ã¦"],
                "collocation": ["ã¸è¡Œã", "ã«è¡Œã", "å­¦æ ¡ã«è¡Œã"],
                "honorific": "ã„ã‚‰ã£ã—ã‚ƒã‚‹ï¼ˆå°Šæ•¬ï¼‰ã€å‚ã‚‹ï¼ˆè¬™è­²ï¼‰"
              },
              "examples": [
                {
                  "japanese": "å­¦æ ¡ã«è¡Œãã€‚",
                  "chinese": "å»å­¦æ ¡ã€‚",
                  "english": "I go to school."
                }
              ],
              "related": {
                "synonym": "å‚ã‚‹ï¼ã„ã‚‰ã£ã—ã‚ƒã‚‹",
                "antonym": "æ¥ã‚‹",
                "derived": null
              }
            }
          ],
          "sentenceAnalysis": null
        }

        EXAMPLE 2 - Sentence Query:
        {
          "queryType": "sentence",
          "entries": [],
          "sentenceAnalysis": {
            "original": "ä»Šæ—¥ã¯é›¨ãŒé™ã‚Šãã†ã§ã™ã€‚",
            "translation": {
              "chinese": "ä»Šå¤©å¥½åƒè¦ä¸‹é›¨ã€‚",
              "english": "It looks like it will rain today."
            },
            "wordBreakdown": [
              {
                "word": "ä»Šæ—¥",
                "reading": "ãã‚‡ã†",
                "meaning": "ä»Šå¤©",
                "grammaticalRole": "æ™‚é–“åè©"
              }
            ],
            "grammarPoints": [
              {
                "pattern": "ãã†ã§ã™",
                "reading": "ãã†ã§ã™",
                "meaning": "æ ·æ€æ¨æµ‹",
                "explanation": "è¡¨ç¤ºæ ¹æ®å¤–è§‚æˆ–æ ·å­è¿›è¡Œæ¨æµ‹"
              }
            ]
          }
        }

        ========================================
        FINAL REMINDER FOR THIS REQUEST:
        - User system language: \(primaryLanguage)
        - ALL "meaning" fields in wordBreakdown: MUST be in \(primaryLanguage)
        - ALL "grammaticalRole" fields in wordBreakdown: MUST be in \(primaryLanguage)
        - ALL "meaning" fields in grammarPoints: MUST be in \(primaryLanguage)
        - ALL "explanation" fields in grammarPoints: MUST be in \(primaryLanguage)

        If \(primaryLanguage) is "English": use "money" not "é’±", use "noun" not "åè©", use "particle" not "åŠ©è©"
        If \(primaryLanguage) is "Chinese (Simplified)": use "é’±" not "money", use "åè©" not "noun"
        ========================================

        User Query: \(sentence)

        Response (JSON only, no other text):
        """
    }

    private func buildExamplePrompt(entry: DictionaryEntry,
                                    senses: [WordSense],
                                    locale: String,
                                    maxExamples: Int,
                                    existingExamples: [String] = []) -> String {
        let definitions = senses.prefix(5)
            .enumerated()
            .map { index, sense in
                let chinese = sense.definitionChineseSimplified ?? sense.definitionChineseTraditional ?? ""
                return "\(index + 1). \(sense.definitionEnglish) | JP: \(sense.partOfSpeech) | CN: \(chinese)"
            }
            .joined(separator: "\n")

        // Determine if user is Chinese speaker
        let isChineseUser = locale.hasPrefix("zh")

        // Build schema and instructions based on user's language
        let jsonSchema: String
        let translationInstruction: String

        if isChineseUser {
            // Chinese users: generate both chinese and english
            let chineseType = locale.lowercased().contains("hant") ? "Traditional Chinese" : "Simplified Chinese"
            jsonSchema = """
            {"examples":[{"japanese":"...", "chinese":"...", "english":"..."}]}
            """
            translationInstruction = """
            4. Use \(chineseType) for the chinese field. Keep english field in natural English.
            """
        } else {
            // Non-Chinese users: only generate english (no chinese field)
            jsonSchema = """
            {"examples":[{"japanese":"...", "english":"..."}]}
            """
            translationInstruction = """
            4. Keep english field in natural English. Do NOT include a chinese field.
            """
        }

        // Build existing examples warning if any
        let existingExamplesWarning: String
        if !existingExamples.isEmpty {
            let examplesList = existingExamples.map { "  - \($0)" }.joined(separator: "\n")
            existingExamplesWarning = """

            âš ï¸ CRITICAL: The following example sentences ALREADY EXIST for this word.
            You MUST generate COMPLETELY DIFFERENT examples with DIFFERENT sentence patterns:
            \(examplesList)

            Requirements for NEW examples:
            - Use DIFFERENT grammar structures (e.g., if existing uses 'ã¯ã€œã§ã™', try 'ã‚’ã€œã™ã‚‹', 'ãŒã€œã‚ã‚‹', questions, negative forms, etc.)
            - Use DIFFERENT verb forms and particles
            - Use DIFFERENT contexts and scenarios
            - Must be clearly distinguishable from existing examples
            - Ensure variety in sentence endings (avoid repeating ã§ã™/ã¾ã™/ã  if already used)
            """
        } else {
            existingExamplesWarning = ""
        }

        return """
        You are an expert Japanese language tutor. Generate natural example sentences for a dictionary entry.

        Entry:
        - Headword: \(entry.headword)
        - Reading: \(entry.readingHiragana)
        - Romaji: \(entry.readingRomaji)
        - Core meanings:
        \(definitions)\(existingExamplesWarning)

        Requirements:
        1. Produce up to \(maxExamples) natural Japanese sentences (15-35 characters) that demonstrate typical usage in daily life. Each sentence MUST include the headword or its conjugated/inflected form once.
        2. Keep sentences simple and practical. Avoid uncommon idioms or archaic grammar.
        3. Ensure variety in grammar patterns: use different sentence types (declarative, question, negative, past tense, polite/casual forms, etc.)
        4. Return JSON ONLY with schema:
           \(jsonSchema)
        \(translationInstruction)
        6. Avoid romaji, avoid placeholders, avoid line breaks inside fields.

        Respond with JSON only.
        """
    }

    // MARK: OpenAI è«‹æ±‚
    private func requestOpenAI(model: String, prompt: String) async throws -> LLMResult {
        let content = try await requestOpenAIContent(model: model, prompt: prompt)

        // æ¸…æ´— JSONï¼šæ›¿æ¢ä¸­æ–‡æ ‡ç‚¹ä¸ºè‹±æ–‡æ ‡ç‚¹
        let cleanedContent = sanitizeJSON(content)

        do {
            return try JSONDecoder().decode(LLMResult.self, from: cleanedContent)
        } catch let primaryError {
            // Log the actual response for debugging
            let responseText = String(data: cleanedContent, encoding: .utf8) ?? "Unable to decode response"
            print("âš ï¸ Primary JSON Decode Failed. Attempting fallback parsing...")
            print("ğŸ“„ Response was: \(responseText)")
            print("âŒ Error: \(primaryError)")

            // FALLBACK: Try to parse partial/malformed JSON
            if let fallbackResult = tryFallbackParsing(content: cleanedContent, originalQuery: prompt) {
                print("âœ… Fallback parsing succeeded")
                return fallbackResult
            }

            throw LLMError.decodeFailed("AIè¿”å›æ ¼å¼é”™è¯¯ã€‚\nåŸå§‹å“åº”: \(responseText.prefix(200))...\né”™è¯¯: \(primaryError.localizedDescription)")
        }
    }

    private func requestOpenAIContent(model: String, prompt: String) async throws -> Data {
        guard let apiKey = apiKey else { throw LLMError.notConfigured }

        let url = URL(string: "https://api.openai.com/v1/chat/completions")!
        var req = URLRequest(url: url)
        req.httpMethod = "POST"
        req.timeoutInterval = 30  // 30ç§’è¶…æ—¶ï¼ˆé€‚åº”çœŸæœºç½‘ç»œç¯å¢ƒï¼‰
        req.setValue("application/json", forHTTPHeaderField: "Content-Type")
        req.setValue("Bearer \(apiKey)", forHTTPHeaderField: "Authorization")

        let body: [String: Any] = [
            "model": model,
            "response_format": ["type": "json_object"],
            "temperature": 0.2,
            "messages": [
                ["role": "system", "content": "Return JSON only. No prose."],
                ["role": "user", "content": prompt]
            ]
        ]
        req.httpBody = try JSONSerialization.data(withJSONObject: body)

        let (data, resp) = try await URLSession.shared.data(for: req)
        guard let http = resp as? HTTPURLResponse else { throw LLMError.emptyResponse }
        guard (200..<300).contains(http.statusCode) else {
            let msg = String(data: data, encoding: .utf8) ?? ""
            throw LLMError.httpError(http.statusCode, msg)
        }

        struct Choice: Decodable { let message: Msg }
        struct Msg: Decodable { let content: String }
        struct OpenAIResp: Decodable { let choices: [Choice] }

        let decoded = try JSONDecoder().decode(OpenAIResp.self, from: data)
        guard let content = decoded.choices.first?.message.content.data(using: .utf8) else {
            throw LLMError.emptyResponse
        }
        return content
    }

    // MARK: Anthropic è«‹æ±‚ï¼ˆClaudeï¼‰
    private func requestAnthropic(model: String, prompt: String) async throws -> LLMResult {
        let content = try await requestAnthropicContent(model: model, prompt: prompt)

        // æ¸…æ´— JSONï¼šæ›¿æ¢ä¸­æ–‡æ ‡ç‚¹ä¸ºè‹±æ–‡æ ‡ç‚¹
        let cleanedContent = sanitizeJSON(content)

        do {
            return try JSONDecoder().decode(LLMResult.self, from: cleanedContent)
        } catch let primaryError {
            let responseText = String(data: cleanedContent, encoding: .utf8) ?? "Unable to decode response"
            print("âš ï¸ Primary JSON Decode Failed (Anthropic). Attempting fallback parsing...")
            print("ğŸ“„ Response was: \(responseText)")
            print("âŒ Error: \(primaryError)")

            if let fallbackResult = tryFallbackParsing(content: cleanedContent, originalQuery: prompt) {
                print("âœ… Fallback parsing succeeded")
                return fallbackResult
            }

            throw LLMError.decodeFailed("AIè¿”å›æ ¼å¼é”™è¯¯ (Anthropic)ã€‚\nåŸå§‹å“åº”: \(responseText.prefix(200))...\né”™è¯¯: \(primaryError.localizedDescription)")
        }
    }

    private func requestAnthropicContent(model: String, prompt: String) async throws -> Data {
        guard let apiKey = apiKey else { throw LLMError.notConfigured }

        let url = URL(string: "https://api.anthropic.com/v1/messages")!
        var req = URLRequest(url: url)
        req.httpMethod = "POST"
        req.timeoutInterval = 10  // 10ç§’è¶…æ—¶
        req.setValue("application/json", forHTTPHeaderField: "Content-Type")
        req.setValue(apiKey, forHTTPHeaderField: "x-api-key")
        req.setValue("2023-06-01", forHTTPHeaderField: "anthropic-version")

        let body: [String: Any] = [
            "model": model,
            "max_tokens": 512,
            "temperature": 0.2,
            "messages": [
                ["role": "user", "content": [
                    ["type":"text", "text":"è«‹åªè¼¸å‡º JSONã€‚\n\(prompt)"]
                ]]
            ]
        ]
        req.httpBody = try JSONSerialization.data(withJSONObject: body)

        let (data, resp) = try await URLSession.shared.data(for: req)
        guard let http = resp as? HTTPURLResponse else { throw LLMError.emptyResponse }
        guard (200..<300).contains(http.statusCode) else {
            let msg = String(data: data, encoding: .utf8) ?? ""
            throw LLMError.httpError(http.statusCode, msg)
        }

        struct Block: Decodable { let text: String? }
        struct Message: Decodable { let content: [Block] }
        let decoded = try JSONDecoder().decode(Message.self, from: data)
        let jsonText = decoded.content.compactMap { $0.text }.joined()
        guard let jsonData = jsonText.data(using: .utf8) else { throw LLMError.emptyResponse }
        return jsonData
    }

    // MARK: Gemini è«‹æ±‚ï¼ˆGoogleï¼‰

    // éæµå¼è¯·æ±‚ï¼ˆä¿ç•™ç”¨äºå…¼å®¹æ€§ï¼‰
    private func requestGemini(model: String, prompt: String) async throws -> LLMResult {
        let content = try await requestGeminiContent(model: model, prompt: prompt)

        // æ¸…æ´— JSONï¼šæ›¿æ¢ä¸­æ–‡æ ‡ç‚¹ä¸ºè‹±æ–‡æ ‡ç‚¹
        let cleanedContent = sanitizeJSON(content)

        do {
            let result = try JSONDecoder().decode(LLMResult.self, from: cleanedContent)
            return result
        } catch let primaryError {
            // å¤‡ç”¨è§£æ
            let responseText = String(data: cleanedContent, encoding: .utf8) ?? "æ— æ³•è§£ç "
            print("âš ï¸ Gemini JSONè§£æå¤±è´¥")
            print("========== FULL GEMINI RESPONSE ==========")
            print(responseText)
            print("==========================================")

            // æ‰“å°è¯¦ç»†çš„è§£ç é”™è¯¯
            if let decodingError = primaryError as? DecodingError {
                print("ğŸ” Decoding Error Details:")
                switch decodingError {
                case .keyNotFound(let key, let context):
                    print("   Missing key: \(key.stringValue)")
                    print("   Context: \(context.debugDescription)")
                    print("   Coding path: \(context.codingPath.map { $0.stringValue }.joined(separator: " -> "))")
                case .valueNotFound(let type, let context):
                    print("   Value not found for type: \(type)")
                    print("   Context: \(context.debugDescription)")
                    print("   Coding path: \(context.codingPath.map { $0.stringValue }.joined(separator: " -> "))")
                case .typeMismatch(let type, let context):
                    print("   Type mismatch for: \(type)")
                    print("   Context: \(context.debugDescription)")
                    print("   Coding path: \(context.codingPath.map { $0.stringValue }.joined(separator: " -> "))")
                case .dataCorrupted(let context):
                    print("   Data corrupted")
                    print("   Context: \(context.debugDescription)")
                    print("   Coding path: \(context.codingPath.map { $0.stringValue }.joined(separator: " -> "))")
                @unknown default:
                    print("   Unknown decoding error: \(decodingError)")
                }
            }

            throw LLMError.decodeFailed("AIè¿”å›æ ¼å¼é”™è¯¯ (Gemini)ã€‚\nåŸå§‹å“åº”: \(responseText.prefix(200))...\né”™è¯¯: \(primaryError.localizedDescription)")
        }
    }

    // æµå¼è¯·æ±‚ï¼ˆé€æ­¥è¿”å›ç»“æœï¼‰
    private func requestGeminiStreaming(
        model: String,
        prompt: String,
        onPartialResult: @escaping @Sendable (String) -> Void
    ) async throws -> LLMResult {
        guard let apiKey = apiKey else { throw LLMError.notConfigured }

        print("ğŸ”µ Gemini Streaming: Starting request to \(model)")
        print("ğŸ“ Prompt length: \(prompt.count) characters")
        let requestStartTime = Date()

        // Gemini Streaming API endpoint
        let url = URL(string: "https://generativelanguage.googleapis.com/v1beta/models/\(model):streamGenerateContent?key=\(apiKey)&alt=sse")!
        var req = URLRequest(url: url)
        req.httpMethod = "POST"
        req.timeoutInterval = 30
        req.setValue("application/json", forHTTPHeaderField: "Content-Type")

        let body: [String: Any] = [
            "contents": [[
                "parts": [[
                    "text": "You must respond with valid JSON only, no markdown code blocks.\n\n\(prompt)"
                ]]
            ]],
            "generationConfig": [
                "temperature": 0.2,
                "maxOutputTokens": 2048,  // Needs to be large enough for full sentence analysis
                "responseMimeType": "application/json"
            ]
        ]
        req.httpBody = try JSONSerialization.data(withJSONObject: body)

        print("ğŸŒ Sending streaming request to Gemini...")
        // ä½¿ç”¨ URLSession çš„ bytes æµå¼æ¥æ”¶
        let (bytes, response) = try await URLSession.shared.bytes(for: req)

        let networkTime = Date().timeIntervalSince(requestStartTime)
        print("âœ… Network connection established in \(String(format: "%.2f", networkTime))s")

        guard let http = response as? HTTPURLResponse else { throw LLMError.emptyResponse }
        guard (200..<300).contains(http.statusCode) else {
            throw LLMError.httpError(http.statusCode, "Streaming request failed")
        }

        var accumulatedText = ""
        var eventData = ""
        var chunkCount = 0
        let firstChunkTime = Date()

        print("ğŸ“¡ Waiting for first chunk from Gemini...")
        // é€è¡Œè¯»å– SSE (Server-Sent Events) æµ
        for try await line in bytes.lines {
            if line.hasPrefix("data: ") {
                eventData = String(line.dropFirst(6)) // ç§»é™¤ "data: " å‰ç¼€

                // è§£ææ¯ä¸ªäº‹ä»¶
                if let data = eventData.data(using: .utf8),
                   let json = try? JSONSerialization.jsonObject(with: data) as? [String: Any],
                   let candidates = json["candidates"] as? [[String: Any]],
                   let firstCandidate = candidates.first,
                   let content = firstCandidate["content"] as? [String: Any],
                   let parts = content["parts"] as? [[String: Any]],
                   let firstPart = parts.first,
                   let text = firstPart["text"] as? String {

                    accumulatedText += text
                    chunkCount += 1

                    if chunkCount == 1 {
                        let ttfb = Date().timeIntervalSince(requestStartTime)
                        print("âš¡ï¸ First chunk received in \(String(format: "%.2f", ttfb))s (TTFB)")
                    }

                    // è°ƒç”¨å›è°ƒï¼Œé€šçŸ¥ UI æ›´æ–°
                    await MainActor.run {
                        onPartialResult(accumulatedText)
                    }

                    if chunkCount % 5 == 0 {  // æ¯5ä¸ªchunkæ‰“å°ä¸€æ¬¡
                        print("ğŸ“¦ Chunk #\(chunkCount): \(accumulatedText.count) chars total")
                    }
                }
            }
        }

        let duration = Date().timeIntervalSince(requestStartTime)
        print("âœ… Streaming complete: \(chunkCount) chunks, \(accumulatedText.count) chars in \(String(format: "%.2f", duration))s")

        // è§£ææœ€ç»ˆçš„å®Œæ•´ JSON
        guard let jsonData = accumulatedText.data(using: .utf8) else {
            throw LLMError.emptyResponse
        }

        let cleanedContent = sanitizeJSON(jsonData)

        do {
            let result = try JSONDecoder().decode(LLMResult.self, from: cleanedContent)
            return result
        } catch let primaryError {
            let responseText = String(data: cleanedContent, encoding: .utf8) ?? "æ— æ³•è§£ç "
            print("âš ï¸ Gemini Streaming JSONè§£æå¤±è´¥")
            print("========== FULL GEMINI STREAMING RESPONSE ==========")
            print(responseText)
            print("===================================================")

            // æ‰“å°è¯¦ç»†çš„è§£ç é”™è¯¯
            if let decodingError = primaryError as? DecodingError {
                print("ğŸ” Decoding Error Details:")
                switch decodingError {
                case .keyNotFound(let key, let context):
                    print("   Missing key: \(key.stringValue)")
                    print("   Context: \(context.debugDescription)")
                    print("   Coding path: \(context.codingPath.map { $0.stringValue }.joined(separator: " -> "))")
                case .valueNotFound(let type, let context):
                    print("   Value not found for type: \(type)")
                    print("   Context: \(context.debugDescription)")
                    print("   Coding path: \(context.codingPath.map { $0.stringValue }.joined(separator: " -> "))")
                case .typeMismatch(let type, let context):
                    print("   Type mismatch for: \(type)")
                    print("   Context: \(context.debugDescription)")
                    print("   Coding path: \(context.codingPath.map { $0.stringValue }.joined(separator: " -> "))")
                case .dataCorrupted(let context):
                    print("   Data corrupted")
                    print("   Context: \(context.debugDescription)")
                    print("   Coding path: \(context.codingPath.map { $0.stringValue }.joined(separator: " -> "))")
                @unknown default:
                    print("   Unknown decoding error: \(decodingError)")
                }
            }

            throw LLMError.decodeFailed("AIè¿”å›æ ¼å¼é”™è¯¯ (Gemini Streaming)ã€‚\nåŸå§‹å“åº”: \(responseText.prefix(200))...\né”™è¯¯: \(primaryError.localizedDescription)")
        }
    }

    private func requestGeminiContent(model: String, prompt: String) async throws -> Data {
        guard let apiKey = apiKey else { throw LLMError.notConfigured }

        print("ğŸ”µ Gemini API: Starting request to \(model)")
        let requestStartTime = Date()

        // Gemini API endpoint
        let url = URL(string: "https://generativelanguage.googleapis.com/v1beta/models/\(model):generateContent?key=\(apiKey)")!
        var req = URLRequest(url: url)
        req.httpMethod = "POST"
        req.timeoutInterval = 30  // 30ç§’è¶…æ—¶
        req.setValue("application/json", forHTTPHeaderField: "Content-Type")

        let body: [String: Any] = [
            "contents": [[
                "parts": [[
                    "text": "You must respond with valid JSON only, no markdown code blocks.\n\n\(prompt)"
                ]]
            ]],
            "generationConfig": [
                "temperature": 0.2,
                "maxOutputTokens": 2048,  // Needs to be large enough for full sentence analysis
                "responseMimeType": "application/json"  // å¼ºåˆ¶ JSON è¾“å‡º
            ]
        ]
        req.httpBody = try JSONSerialization.data(withJSONObject: body)

        print("ğŸ”µ Gemini API: Request prepared, sending...")
        let (data, resp) = try await URLSession.shared.data(for: req)
        let networkDuration = Date().timeIntervalSince(requestStartTime)
        print("ğŸ”µ Gemini API: Network response received in \(String(format: "%.2f", networkDuration))s")
        guard let http = resp as? HTTPURLResponse else { throw LLMError.emptyResponse }
        guard (200..<300).contains(http.statusCode) else {
            let msg = String(data: data, encoding: .utf8) ?? ""
            throw LLMError.httpError(http.statusCode, msg)
        }

        // è§£æ Gemini å“åº”æ ¼å¼
        struct Part: Decodable { let text: String }
        struct Content: Decodable { let parts: [Part] }
        struct Candidate: Decodable {
            let content: Content
            let finishReason: String?
        }
        struct GeminiResponse: Decodable { let candidates: [Candidate] }

        let decoded = try JSONDecoder().decode(GeminiResponse.self, from: data)
        guard let firstCandidate = decoded.candidates.first,
              let jsonText = firstCandidate.content.parts.first?.text else {
            throw LLMError.emptyResponse
        }

        // Check if response was complete
        if let finishReason = firstCandidate.finishReason {
            print("ğŸ” Gemini finishReason: \(finishReason)")
            if finishReason != "STOP" && finishReason != "FINISH" {
                print("âš ï¸ Warning: Response may be incomplete (finishReason: \(finishReason))")
            }
        }

        print("ğŸ“ JSON text length: \(jsonText.count) characters")

        guard let jsonData = jsonText.data(using: .utf8) else { throw LLMError.emptyResponse }
        return jsonData
    }

    private struct ExampleResponse: Codable {
        let examples: [LLMExample]
    }

    // MARK: Fallback Parsing
    /// Attempt to parse partial or malformed JSON responses
    private func tryFallbackParsing(content: Data, originalQuery: String) -> LLMResult? {
        guard String(data: content, encoding: .utf8) != nil else {
            return nil
        }

        // Try to parse as generic JSON first
        guard let jsonObj = try? JSONSerialization.jsonObject(with: content) as? [String: Any] else {
            return nil
        }

        // Extract queryType
        guard let queryTypeStr = jsonObj["queryType"] as? String,
              let queryType = LLMQueryType(rawValue: queryTypeStr) else {
            // No valid queryType - create a minimal notFound result
            return createMinimalNotFoundResult(query: originalQuery)
        }

        switch queryType {
        case .word, .notFound:
            // Try to extract entries
            if let entriesArray = jsonObj["entries"] as? [[String: Any]] {
                let parsedEntries = entriesArray.compactMap { entryDict -> LLMDictEntry? in
                    return parseEntryDict(entryDict)
                }

                if !parsedEntries.isEmpty {
                    return LLMResult(
                        queryType: queryType,
                        entries: parsedEntries,
                        sentenceAnalysis: nil
                    )
                }
            }

            // Fallback: create minimal entry
            return createMinimalNotFoundResult(query: originalQuery)

        case .sentence:
            // For sentence analysis, require proper structure
            // Don't fallback for sentences - they're too complex
            return nil
        }
    }

    /// Create a minimal "not found" result when parsing fails
    private func createMinimalNotFoundResult(query: String) -> LLMResult {
        let minimalEntry = LLMDictEntry(
            headword: query,
            reading: "(æ¨å®š)",
            romaji: nil,
            partOfSpeech: "æœªåéŒ²èª",
            accent: nil,
            senses: [
                LLMSense(
                    definition: "è¾æ›¸ã«åéŒ²ã•ã‚Œã¦ã„ãªã„èª",
                    chinese: "è¯å…¸ä¸­æœªæ”¶å½•",
                    english: "Not found in dictionary"
                )
            ],
            grammar: nil,
            examples: nil,
            related: nil
        )

        return LLMResult(
            queryType: .notFound,
            entries: [minimalEntry],
            sentenceAnalysis: nil
        )
    }

    /// Parse a single entry dictionary with lenient field checking
    private func parseEntryDict(_ dict: [String: Any]) -> LLMDictEntry? {
        // Required fields with defaults
        guard let headword = dict["headword"] as? String else { return nil }

        let reading = dict["reading"] as? String ?? "(ä¸æ˜)"
        let romaji = dict["romaji"] as? String
        let partOfSpeech = dict["partOfSpeech"] as? String ?? "æœªåˆ†é¡"
        let accent = dict["accent"] as? String

        // Parse senses (required, at least one)
        var senses: [LLMSense] = []
        if let sensesArray = dict["senses"] as? [[String: Any]] {
            senses = sensesArray.compactMap { senseDict in
                guard let definition = senseDict["definition"] as? String,
                      let chinese = senseDict["chinese"] as? String,
                      let english = senseDict["english"] as? String else {
                    return nil
                }
                return LLMSense(definition: definition, chinese: chinese, english: english)
            }
        }

        // If no valid senses, use default
        if senses.isEmpty {
            senses = [LLMSense(
                definition: "å®šç¾©ãªã—",
                chinese: "æ— å®šä¹‰",
                english: "No definition available"
            )]
        }

        // Parse optional grammar
        var grammar: LLMGrammar? = nil
        if let grammarDict = dict["grammar"] as? [String: Any] {
            grammar = LLMGrammar(
                conjugation: grammarDict["conjugation"] as? [String],
                collocation: grammarDict["collocation"] as? [String],
                honorific: grammarDict["honorific"] as? String
            )
        }

        // Parse optional examples
        var examples: [LLMExample]? = nil
        if let examplesArray = dict["examples"] as? [[String: Any]] {
            let parsedExamples = examplesArray.compactMap { exDict -> LLMExample? in
                guard let jp = exDict["japanese"] as? String,
                      let cn = exDict["chinese"] as? String,
                      let en = exDict["english"] as? String else {
                    return nil
                }
                return LLMExample(japanese: jp, chinese: cn, english: en)
            }
            examples = parsedExamples.isEmpty ? nil : parsedExamples
        }

        // Parse optional related
        var related: LLMRelated? = nil
        if let relatedDict = dict["related"] as? [String: Any] {
            related = LLMRelated(
                synonym: relatedDict["synonym"] as? String,
                antonym: relatedDict["antonym"] as? String,
                derived: relatedDict["derived"] as? String
            )
        }

        return LLMDictEntry(
            headword: headword,
            reading: reading,
            romaji: romaji,
            partOfSpeech: partOfSpeech,
            accent: accent,
            senses: senses,
            grammar: grammar,
            examples: examples,
            related: related
        )
    }

    // MARK: ç°¡æ˜“é…é¡
    private func checkDailyQuota() throws {
        let today = Self.dayString(Date())
        let defaults = UserDefaults.standard
        if defaults.string(forKey: dailyDateKey) != today {
            defaults.set(today, forKey: dailyDateKey)
            defaults.set(0, forKey: dailyLimitKey)
        }
        let used = defaults.integer(forKey: dailyLimitKey)
        if used >= dailyLimit {
            throw LLMError.quotaExceeded
        }
    }

    private func increaseDailyCount() {
        let defaults = UserDefaults.standard
        let used = defaults.integer(forKey: dailyLimitKey)
        defaults.set(used + 1, forKey: dailyLimitKey)
    }

    private static func dayString(_ date: Date) -> String {
        let f = DateFormatter()
        f.calendar = Calendar(identifier: .gregorian)
        f.dateFormat = "yyyy-MM-dd"
        return f.string(from: date)
    }

    // MARK: å¿«å–
    private func cacheKey(sentence: String, provider: LLMProvider, locale: String) -> String {
        // v3: Enhanced notFound mode with internet-based explanations (2025-10-22)
        let raw = "\(sentence)|\(providerIdentifier(provider))|\(locale)|v3"
        let digest = Insecure.MD5.hash(data: raw.data(using: .utf8)!)
        return digest.map { String(format: "%02hhx", $0) }.joined()
    }

    private func cacheKeyForExamples(entryID: Int,
                                     provider: LLMProvider,
                                     locale: String,
                                     maxExamples: Int,
                                     senses: [WordSense]) -> String {
        let senseFingerprint = senses
            .map { sense in
                [
                    sense.definitionEnglish,
                    sense.definitionChineseSimplified ?? "",
                    sense.definitionChineseTraditional ?? "",
                    sense.partOfSpeech
                ].joined(separator: "|")
            }
            .joined(separator: ";")

        let raw = "examples|\(entryID)|\(senseFingerprint)|\(locale)|\(maxExamples)|\(providerIdentifier(provider))|v1"
        let digest = Insecure.MD5.hash(data: raw.data(using: .utf8)!)
        return digest.map { String(format: "%02hhx", $0) }.joined()
    }

    private func cacheURL(for key: String) -> URL {
        diskCacheDir.appendingPathComponent("\(key).json")
    }

    private func saveCache<T: Encodable>(_ value: T, for key: String) {
        let encoder = JSONEncoder()
        if let data = try? encoder.encode(value) {
            memCache.setObject(data as NSData, forKey: key as NSString)
            try? data.write(to: cacheURL(for: key), options: .atomic)
        }
    }

    private func loadCache<T: Decodable>(for key: String) -> T? {
        if let data = memCache.object(forKey: key as NSString) as Data? {
            return try? JSONDecoder().decode(T.self, from: data)
        }
        let url = cacheURL(for: key)
        if let data = try? Data(contentsOf: url) {
            memCache.setObject(data as NSData, forKey: key as NSString)
            return try? JSONDecoder().decode(T.self, from: data)
        }
        return nil
    }

    private func providerIdentifier(_ provider: LLMProvider) -> String {
        switch provider {
        case .openAI(let model):
            return "openai:\(model)"
        case .anthropic(let model):
            return "anthropic:\(model)"
        case .gemini(let model):
            return "gemini:\(model)"
        }
    }

    /// æ¸…æ´— JSON æ•°æ®ï¼šå°†ä¸­æ–‡æ ‡ç‚¹æ›¿æ¢ä¸ºè‹±æ–‡æ ‡ç‚¹
    /// Sanitize JSON data: replace Chinese punctuation with English punctuation
    private func sanitizeJSON(_ data: Data) -> Data {
        guard var jsonString = String(data: data, encoding: .utf8) else {
            print("âš ï¸ Unable to decode JSON string")
            return data
        }

        var replacementCount = 0

        // åœ¨ JSON ç»“æ„å±‚é¢ï¼ˆå­—æ®µåã€å†’å·ã€é€—å·ï¼‰æ›¿æ¢ä¸­æ–‡æ ‡ç‚¹ä¸ºè‹±æ–‡æ ‡ç‚¹
        // ä½†ä¿ç•™å­—ç¬¦ä¸²å€¼å†…éƒ¨çš„æ ‡ç‚¹ï¼ˆé¿å…ç ´åæ—¥è¯­/ä¸­æ–‡æ–‡æœ¬å†…å®¹ï¼‰

        var insideString = false
        var escaped = false
        var result = ""

        for char in jsonString {
            if escaped {
                // è½¬ä¹‰å­—ç¬¦åçš„å­—ç¬¦ï¼Œç›´æ¥æ·»åŠ 
                result.append(char)
                escaped = false
                continue
            }

            if char == "\\" {
                // è½¬ä¹‰å­—ç¬¦
                escaped = true
                result.append(char)
                continue
            }

            if char == "\"" {
                // å¼•å·åˆ‡æ¢å­—ç¬¦ä¸²çŠ¶æ€
                insideString.toggle()
                result.append(char)
                continue
            }

            // åœ¨å­—ç¬¦ä¸²å¤–éƒ¨ï¼ˆJSON ç»“æ„éƒ¨åˆ†ï¼‰æ›¿æ¢ä¸­æ–‡æ ‡ç‚¹
            if !insideString {
                switch char {
                case "ï¼š":
                    result.append(":")
                    replacementCount += 1
                case "ï¼Œ":
                    result.append(",")
                    replacementCount += 1
                case "ã€‚":
                    result.append(".")
                    replacementCount += 1
                case "ï½›":
                    result.append("{")
                    replacementCount += 1
                case "ï½":
                    result.append("}")
                    replacementCount += 1
                case "ï¼»":
                    result.append("[")
                    replacementCount += 1
                case "ï¼½":
                    result.append("]")
                    replacementCount += 1
                default:
                    result.append(char)
                }
            } else {
                // åœ¨å­—ç¬¦ä¸²å†…éƒ¨ï¼Œä¿ç•™åŸæ ·ï¼ˆåŒ…æ‹¬ä¸­æ–‡æ ‡ç‚¹ï¼‰
                result.append(char)
            }
        }

        if replacementCount > 0 {
            print("ğŸ§¹ JSON Sanitized: Replaced \(replacementCount) Chinese punctuation marks")
            print("ğŸ“ Original: \(jsonString.prefix(200))...")
            print("ğŸ“ Cleaned:  \(result.prefix(200))...")
        }

        return result.data(using: .utf8) ?? data
    }
}
